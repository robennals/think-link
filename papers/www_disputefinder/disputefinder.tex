%\documentclass{article}
\documentclass{www2010-submission}
\usepackage{times}
%\usepackage{uist}
\usepackage{url}
\usepackage{graphics}
\usepackage{color}
%
%\newcommand{\want}[1]{{[\color{blue} WANT: #1]}}
%\newcommand{\todo}[1]{{[\color{blue} TODO: #1]}}
%\newcommand{\idea}[1]{{[\color{blue} IDEA: #1]}}
%\newcommand{\node}[1]{{[\color{blue} NOTE: #1]}}

\newcommand{\want}[1]{}
\newcommand{\todo}[1]{}
\newcommand{\idea}[1]{}
\newcommand{\node}[1]{}


\begin{document}

\toappear

\bibliographystyle{plain}

\title{Highlighting Disputed Information on the Web}

%%
%% Note on formatting authors at different institutions, as shown below:
%% Change width arg (currently 7cm) to parbox commands as needed to
%% accommodate widest lines, taking care not to overflow the 17.8cm line width.
%% Add or delete parboxes for additional authors at different institutions. 
%% If additional authors won't fit in one row, you can add a "\\"  at the
%% end of a parbox's closing "}" to have the next parbox start a new row.
%% Be sure NOT to put any blank lines between parbox commands!
%%

\numberofauthors{5}

\author{
	Author list to be determined
}

%\author{
%\alignauthor Rob Ennals\\
%       \affaddr{Intel Labs Berkeley}\\
%       \affaddr{2150 Shattuck Ave}\\
%       \affaddr{Berkeley, CA, USA}\\
%       \email{robert.ennals@intel.com}
%\alignauthor Beth Trushkowsky\\
%       \affaddr{Computer Science Division}\\
%       \affaddr{University of California at Berkeley}\\
%       \affaddr{Berkeley, CA, USA}\\
%       \email{trush@berkeley.edu}
%\alignauthor John Mark Agosta\\
%       \affaddr{Intel Labs Santa Clara}\\
%       \affaddr{2200 Mission College Blvd}\\
%       \affaddr{Santa Clara, CA, USA}\\
%       \email{john.m.agosta@intel.com}
%}
%
%\additionalauthors{Additional authors: Tad Hirsch (Intel Research PaPR, email: {\texttt{tad.hirsch@intel.com}}) and Tye Rattenbury (Intel Research PaPR), email: {\texttt{tye.rattenbury@intel.com}})}


\maketitle

%RULE: Don't cite media reports unless I have to - some reviewers don't like it


\abstract

We describe Dispute Finder, a browser extension that alerts a user when information they read online is disputed by a source that they might trust. Dispute Finder examines the text on the page that the user is browsing and highlights any phrases that appear to entail claims in its database of known disputed claims. If a user clicks on a highlighted phrase then Dispute Finder will show the user a summary of articles that support other points of view.

Dispute Finder builds it's database of disputed claims by crawling web sites that already maintain lists of disputed claims, and by allowing users to enter claims that they believe are disputed. Dispute Finder identifies instances of disputed claims by running a simple textual entailment algorithm inside the browser extension, referring to a cached local copy of a subset of our claim database.

Performing these tasks well is a hard problem, and we do not yet claim to have an implementation that is good enough to be compelling for most users. We do however believe that Dispute Finder attacks an interesting problem that, if addressed well, could significantly improve the utility of the web.

\category{H.4.m}{Information Systems}{Miscellaneous}
\category{H.4.2}{Information Systems}{Decision Support}
\category{H.5.2}{User Interfaces}{Graphical User Interfaces}

\terms{Design, Human Factors}

\keywords{Sensemaking, Annotation, Argumentation, Web, CSCW}


\tolerance=400 
  % makes some lines with lots of white space, but 	
  % tends to prevent words from sticking out in the margin

\section{INTRODUCTION}

\todo{update screenshots}

The web contains a huge amount of information, but some of this information is factually incorrect~\cite{Neumann2003,Resnik1998,Zhou2004} and some sites present only one side of a contentious issue~\cite{Herman2002}. 
If a user is to gain a broad understanding of a topic then they will need to either spend time looking for alternative points of view, or restrict themselves to sources that they believe they can trust to provide accurate and balanced information.
Even if a user tries to be careful, they can still be caught out by claims that they had not realized were disputed.
\todo{word this better}\todo{update all screenshots}

In this paper we describe Dispute Finder, a service that informs a user when information they read online is disputed by a source that they might trust. Our hope is that Dispute Finder will make it easier for a user to gain a broad view of a topic that they are interested in.

If a user has installed the Dispute Finder browser extension then it will highlight snippets of text on the web that make claims that Dispute Finder believes are disputed (Figure~\ref{highlight}). 
When a user clicks on a highlighted snippet, Dispute Finder will present a list of articles that present alternative points of view, each of which is from a source we believe the user is likely to trust (Figure~\ref{claimview}). 

Dispute Finder consists of a database, an API, and a firefox browser extension. The database contains information about the disputed claims that are known to be made on web sites, and hints about how to tell when a web page is making such a claim. The API allows an external client to determine whether particular content is making a disputed cliam. The firefox extension uses the API to determine whether the web pages a user browses make disputed claims. The API could also be used by other services that present users with potentially-disputed content, such as search engines, news readers, email programs, or content management systems.

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=6cm]{../screenshots/v2_highlight_shadow.png}
	\caption{Dispute Finder highlights snippets that make disputed claims}
	\label{highlight}
	\end{center}
\end{figure}

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=8cm]{../screenshots/v2_popup_dim2.png}
	\caption{Click on a snippet to investigate evidence for the claim it makes}
	\label{claimview}
	\end{center}
\end{figure}

There are several design decisions that must be made when building a system such as this, which we will address in the remainder of the paper. In particular:

\begin{description}
\item[What claims are disputed?] In order to highlight claims as being disputed, we need to know what claims these are. To be useful, the set of known disputed claims needs to be both large (so people see some benefit) and accurate (so that people don't get annoyed by things that aren't actually disputed. We currently use a combination of crowdsourcing from users, and mining web sites such as Snopes and Politifact that already maintain lists of disputed claims. There are also other interesting alternative approaches that may be worth exploring. 

\item[What disputed claims should we tell the user about?] In some sense almost everything is disputed by someone. If we highlighted everything that was disputed by anyone then the tool would be too noisy to be useful. The challenge is to determine when the other point of view is something the user might take seriously. We do not yet have a large enough database of disputed claims for this to be a serious problem, but we believe that there may be interesting solutions.

\item[How do we tell that a snippet is making a disputed claim?] If a user is reading a web page that might contain disputed claims, then how do we determine which sentences are making disputed claims? We have experimented with several different approaches, each of which has different advantages and disadvantages. One can ask users to mark snippets individually. One can build a search tool that allows a user to find and mark similar snippets in bulk. One can provide an interface that allows a user to train a machine learning classifier to recognize snippets. One can use a textual entailment algorithm to recognize phrases that seem to have a similar meaning to the claim. We found advantages and disadvantages of all these approaches.

\item[How do we add highlights to the pages a user browses?] If a user is reading web pages, how should we augment that experience with information about disputed claims? Using a browser extension allows us to examine all content the user browses, but limits us to users who are prepared to install a browser extension~\cite{nolike-extension?}. Using a proxy~\cite{proxy?} has similar adoption problems to a browser extension, and is likely to break some web sites. Providing an API allows external sites such as news readers and search engines to provide information about disputed claims, but limits coverage to those sites that support the API. The best approach may be a combination.

\item[What information should we show someone about a disputed claim?] If someone clicked on a disputed claim on a web page, what information should we show them that will help them decide whether to talk the alternative points of view seriously. We experimented with using an argumentation graph, a summary of snippets from sources that support the two sides, automatically-found articles, and user-curated articles. 
\end{description}

In order for Dispute Finder to be useful, it needs to provide a service that users will actually appreciate. It is thus important that we understand how users feel about disputed information. Dispute Finder is designed to cater to two personas. Each persona was created from interviews we conducted with people who we believe fit into these categories:

\todo{Use interviews to get some actual observations here. These are just fillers.}

\begin{description}

\item[Skeptical Readers] want to know when information they read is disputed. They are primarily motivated by a desire to avoid being misled. Although there are some sources that they strongly trust, they also regularly read web sites that they do not trust, and they are worried about being misled. In the abscence of Dispute Finder, they often try to verify information they read online by searching several web sites on the same topic, or checking something they have read on a known trusted site.

\item[Activists] care strongly about particular issues and are prepared to spend some time helping other users know that something they read is disputed. They are the same kinds of people who join protest groups, argue about topics online, post stories to news aggregators, or edit wikipedia. They are motivated by a desire to gain status by being publically seen to have led others to discover that important issues are disputed. They are also motivated by a desire to entertain themselves by seeing what disputed claims are being made and where online they are being made.

\end{description}

\todo{Improve the paraphraser UI so it shows users what pages are making the claim}
\todo{Improve the ``see examples on the web'' UI to it shows the pages that were found with the activists training work}
\todo{Provide a customized RSS reader and search engine that does dispute tracking. - future work?}

The same user may be an Activist for some issues and a Sceptical Reader for others. Dispute Finder is not useful for everyone. In our interviews, we encountered several people who either didn't rely on the internet as an important source of information, or only obtained important information from sources that they trust. If a user never reads information they care about from web sites that they don't entirely trust, then Dispute Finder will not be useful to them.

The design decisions made in Dispute Finder have been motivated by our interactions with potential users. We conducted a small survey, a series of interviews, and several rounds of user studies. 

\todo{Should we explicitly list what we think are our key contributions?}


\section{Related Work}

Dispute Finder builds on prior work in several different areas. The idea of highlighting potentially untrustworthy information was applied to Wikipedia by WikiTrust~\cite{Adler2008a}. Tagging Systems~\cite{Marlow2006} influenced the way Dispute Finder uses the community to collect and filter information. Dispute Finder's snippets are influenced by clipping tools such as Internet Scrapbook~\cite{Sugiura1998}. Many people have developed textual entailment algorithms~\cite{entail?} that determine when one sentence implies the trust of another, or contradiction detection algorithms that determine when one sentence contradicts another.

\todo{Add more references from the NewsCube paper}


\subsection{Fact Checking Sites}

If a user suspects that something they read online may be false then they can look it up on one of many fact checking sites such as Snopes.com, FactCheck.org, or Politifact.com. If one is aware that an issue is controversial and wants to understand the different sides, then one can use sites like Wikipedia.org, Debate.org, and ProCon.org. These sites do an excellent job at presenting accurate and balanced information about controversial topics. 

Dispute Finder is designed to deal with the cases where the user is not aware that the information they are reading is disputed and so does not realise that they should check it on one of these services, or does not know which of these services might have more information. Dispute Finder is designed to work together with fact checking sites like Snopes and Politifact. Indeed Dispute Finder automatically imports disputed claims made on Snopes or Politifact into its claim database, and will use articles from Snopes and Politifact as evidence about disputed claims.


\subsection{Analysing News}

News Cube~\cite{Park2009} automatically finds articles that present different {\it aspects} of the same news story. The intention is that by reading several such aspects, the user will encounter several different ways of looking at the issue at hand, and will gained a broader persective of the issue. Dispute Finder is trying to do something similar, but working at the finer granularity of specific claims made in an article, rather than the slant of the entire article. A reader may not have the patience to read multiple articles about the same topic, or may not find the article that rebuts the claim made in an article they read. 

Services such as Skewz.com and Newstrust.net allow users to rate news articles for bias. Skewz rates stories as being either liberal or conservative and encourages readers to read what the other side is thinking. Newstrust allows users to rate news articles for quality and objectivity. 


\subsection{Web Annotation Tools}

Annotation tools such as ReframeIt.com, ShiftSpace.org and SpinSpotter.com allow a user to manually annotate a web site that they disagree with, overlaying their own opinions on top of existing content Videolyzer~\cite{Diakopoulos2008} allows users to comment on disputed claims in video clips. There are many other web annotation tools, including Google SideWiki, Annotea~\cite{Koivunen2001} and ScreenCrayons~\cite{Olsen2004}. 

These annotation tools all allow a user to annotate a page with their thoughts on the same topic. Dispute Finder does not allow a user to directly express their own opinions about a topic. Instead, the only way they can disagree with something that is said is to link it to an article from a trusted source that argues for a different point of view. We believe that most users would rather know the cases where a trusted source disagrees with what is being written, rather than when an unknown user disagrees.

Another key difference between these annotation tools and Dispute Finder is that these annotation tools all allow a user to annotate a {\it page} while Dispute Finder attempts to allow a user to annotate a {\it claim} everywhere it appears on the web. If a user of an annotation tool adds an annotation to a page then their annotation will only appear on that page. By contrast, if a user of Dispute Finder tells Dispute Finder to highlight a disputed claim, that claim will be highlighted on every web page on which Dispute Finder's algorithms determine that it appears.

More generally, Dispute Finder is an example of an Open Hypermedia system~\cite{Bouvin2000,Wiil1996}. Like other Open Hypermedia systems, Dispute Finder lays an additional link structure over an existing hypertext document. In the case of Dispute Finder, the links are from disputed claims to information about those claims.

Dispute Finder can also be seen as an example of a tagging tool~\cite{Marlow2006,Golder2006}. Tagging tools allow users to collectively catagorize information by associating it with a user-created set of tags. In the case of Dispute Finder, the tags are disputed claims, and the tagged entities are sentences that make those claims.


\subsection{Sensemaking Tools}

Several Sensemaking, Decision Support, and Argumentation tools allow a user to annotate a document with structured information that they may then share with other users. TRELLIS~\cite{Gil2002} helps a user annotate the rationale for their decisions and opinions by annotating source documents with the facts that have been extracted from them, and connecting these facts into a decision graph. ClaimSpotter~\cite{Sereno2005,Serono2004} applies a similar approach to scholarly papers, allowing a user to make up a paper with logical subject-verb-object triples describing important claims made in the document. Entity Workspace~\cite{Bier2006} uses entity extraction algorithms to allow an intelligence analyst to easily mark up a source document with facts about it.

Cohere~\cite{Shum2008} is a web based argumentation tool that allows people to connect {\it ideas} together using arbitrary verbs such as "is an example of", "supports", or "challenges". An idea can contain a link to a web page that contains that idea, and the Cohere Firefox Extension informs a user when the page that they are is part of a known idea.

All these tools are intended to be used to identify the source of information that is being used to reach a conclusion. These tools allow a user to mark up the facts made by a single document, but do not provide facilities for a user to mark up large numbers of documents as being the same claim. While Dispute Finder does allow a user to mark up a trustworthy article as being the source of information, the focus is on making it easy for a user to mark up large numbers of documets that make claims that are disputed.


\subsection{Argumentation Tools}

One of the design options we explored for Dispute Finder is to explain a disputed claim by showing a user a user-editable argument graph, explaining the various aspects of the issue, and linking to the various sources. This graph is inspired by IBIS\footnote{Issue Based Information System}~\cite{Rittel1973} tools such as gIBIS~\cite{Conklin1987a}, Compendium~\cite{Selvin2001}, Zeno~\cite{Gordon1997}, and Cohere~\cite{Shum2008}. These tools model debate as a graph of issues, positions, and arguments. 

Isenmann and Reuter~\cite{Isenmann1997} identified a number of problems with using IBIS tools to help people resolve disputes and make decisions. Broadly speaking, they found that opposing groups were unkeen to agree to use an IBIS tool to resolve their disputes, and that users found it difficult to properly encode a complex issue as an argument graph. We encountered similar problems with using an IBIS graph to describe claims, which is why the current version of Dispute Finder presents a user with a list of articles, rather than an argument graph.

Several alternative graph structures have been proposed for describing arguments and design rationale. WinWin~\cite{Boehm2006} models the different stakeholders and their different motives. The Toulmin Model~\cite{toulmin1958} breaks down the logical way in which arguments are formed from evidence, rules, and exceptions. QOS~\cite{Maclean1991} explicitly states the criteria used to choose between positions. 


\subsection{Recognizing Textual Entailment}

The textual entailment problem is one of the standard problems in natural language processing. In the 3-way variant of the PASCAL Recognizing Textual Entailment (RTE) Challenge\footnote{http://pascallin.ecs.soton.ac.uk/Challenges/RTE/}, an algorithm is given two sentences T and H and asked to return one of three results: T {\it entails} H, T {\it contradicts} H, or the truth of H cannot be determined from T. 

Dispute Finder uses the standard Local Lexical Matching (LLM) algorithm, which is commonly used as a non-trivial baseline to which other algorithms are compared~\cite{Braz2005}. LLM simply reduces a sentence to a bag of lemmatized words, removes stopwords, checks for negations, and then looks at what the overlap is. LLM is far from being state of the art and many more sophisticated algorithms exist. One popular approach is to treat a sentence as being a logical formula and then attempt a logical proof, taking into account knowledge about the world~\cite{Bayer2005,Bos2005}. Snow et al~\cite{Snow2006} parse a phrase into a syntax tree, and then use syntax heuristics to determine entailment.

While Dispute Finder would probably improve its accuracy if it used a more sophisticated algorithm, LLM has the advantage of being simple enough to run efficiently inside a users web browser for every page they look at without causing a noticeable slowdown. 

\todo{Do human-guided approach that works well? Talk more about human guided task.}


\subsection{Finding Disputed Information on the Web}

An important part of Dispute Finder is identifying what claims are disputed. Several other authors looked at disputed information on the web.

Kittur et al~\cite{Kittur2007} developed an algorithm that can determine whether a wikipedia page is about a disputed topic. Kittur and Chi~\cite{Kittur2009} broke down the disputed pages by catagory and found that People, Society, and Religion were the categories with the most disputed pages.

Information extration tools such as TextRunner~\cite{Etzioni2008} 

TextRunner~\cite{Etzioni2008} 

\todo{cite lots of Etzioni stuff}


\todo{Online Dispute Resolution}

\todo{Cite Kittur et al}


\subsection{Finding Repeated Information on the Web}

\todo{Cite google quotation stuff and Ed Chi movable quotations stuff}


A key component of Dispute Finder is that in needs to identify phrases on the web that make a know disputed claim. The techniques that Dispute Finder uses have been influenced by related work that does similar things.

\cite{Kim2009} Efficient Overlap and Content Reuse Detection.

\cite{schillit?}

Kolak and Schillit~\cite{Kolak2008} detect cases where one book has quoted from another one, and use this to create links between books. Dispute Finder also creates new links between information, but it's links are created by users, rather than being mined automatically.

\cite{Something by Ed CHi about this}

\todo{Talk about textual entailment}

\todo{Talk about MemeTracker}


\subsection{Measuring Trust}

Several authors have analysed trust on Wikipedia. WikiTrust~\cite{Adler2008a} highlights passages on Wikipedia that are statistically likely to be reverted, based on how recently they were written and the track-record of the author. Wiki Dashboard~\cite{Kittur2008} creates a visualization of the edit history of a Wikipedia article that lets a user see how contentious it is. Wiki Scanner\footnote{http://wikiscanner.virgil.gr} finds cases where a Wikipedia edit has been made by someone with a conflict of interest. All these tools determine trustworthiness by examining the edit history of a page.

BJ Fogg et al~\cite{Fogg2000, Fogg2003} have looked at the metrics that users use to determine when they should trust a source online. They found that the most important factor was whether a web site had a professional-looking design. Gill and Arts~\cite{Gil2006} identified on a different set of factors, including topic (a medical site may not be trusted on car repair), popularity and authority.



\subsection{Augmented Web Navigation}

Several tools layer an alternative navigation graph over information on the web. TextRunner~\cite{Etzioni2008} and Idea Navigation~\cite{Etzioni2008} look for instances of subject-verb-object triples on web pages and connect these together as a graph in which objects are linked by statements made about them on different web pages. ScentHighlights~\cite{Chi2005a} highlights snippets of text that relate to topics the user has expressed interest in. 


\subsection{Persuasive Technology}

% \subsection{Semantic Web}
% 
% Nobody is going to mark up their own web page as being wrong.

% \subsection{To discuss in the body}
% 
% Paraphrases~\cite{Chklovski2005}. Suggested formal paraphrases~\cite{Blythe2004}.
% Importance of Lurkers~\cite{Takahashi2003}
% Wikify~\cite{Mihalcea2007}. OpenCalais\footnote{http://opencalais.com}.



\section{The Dispute Finder System}

Users interact with Dispute Finder in two ways. Skeptical readers browse the web using the Dispute Finder Firefox extension and discover when pages they read make disputed claims. Activists tell Dispute Finder about disputed claims that they care about, and add evidence to support their point of view.


\subsection{Highlighting Disputed Claims}

Dispute Finder aims to inform users when information they read on the web makes claims that are disputed by sources that they might trust. We are particularly interested in informing users about claims that they hadn't thought about before, hadn't realized were disputed by sources they repect, or have not yet established a strong opinion on.

Dispute Finder uses two mechanisms to inform a user when information on the page they are reading is disputed. It highlights any snippets that make the disputed claims in red, and it displays a message bar.

The message bar alerts the user that they should look out for highlighted snippets on the current page. 
Highlighted snippets can be difficult to see if the page is using a background color that is similar to our highlight color\footnote{We tried to choose a color that is rarely used as a background} or if the user is color blind. The message also provides a ``go to next snippet'' button that allows the user to step though the highlighted snippets one at a time.

The highlights show a user {\it why} Dispute Finder thinks that a page is making a disputed claim. In some cases Dispute Finder may have mistakenly thought an article was saying something it wasn't, or the disputed claim may be in text the user isn't interested in, such as a comment. If Dispute Finder has incorrectly marked a snippet as making a disputed claim then the user is encouraged to tell Dispute Finder this by clicking on the snippet and then cliking on the ``report incorrect highlighing'' button in the popup interface.

A user can discover what disputed claim Dispute Finder thinks a snippet is making by hovering their mouse over it, and can bring up more information about a claim by clicking on the snippet (Figure\ref{claimview}).

There is little point repeatedly telling a user that the same claim is disputed. In our current version, a user can ask Dispute Finder to not highlight a claim again by clicking on the ``ignore this claim]'' button in the popup interface. An alternative is to automatically stop highlighting a disputed claim, once the user has brought up the popup interface for it once. We have not yet conclusively decided which method works better. Requiring a user to manually opt out of a claim requires more work from the user, but also causes less user-confusion as users do not normally expect viewing something to be a destructive operation.

A web site can also opt to use the Dispute Finder API to detect disputed claims on the content that they present to users. This API could be particularly useful to tools like search engines and RSS feed readers that a user may use to access a large proportion of the information they consume. The firefox extension itself uses the same API. The advantage of using the Firefox extension is that it can look for disputed claims on any web site. The disadvantage is that it can only be used by users who use a compatible browser and are prepared to install an extension (well known to be a significant barrier to adoption\cite{extension-bad?}

\todo{Document API online}
\todo{Change the highlight color to yellow? Auto-adjust highlight color based on background color?}
\todo{Should we automatically adjust the highlight color, based on the background color of the page}
\todo{Discuss previous work on highlighting here, rather than in related work?}


\subsection{Explaining Disputed Claims}

Once a user has been informed that the page they are reading is making a disputed claim, they will typically be interested in learning more about that claim, so they can judge whether there are alternative points of view that they should take seriously.

The simplest option would be to merely inform the user that the page is making a disputed claim, but provide no further information about that claim.The user could then use a tool such as a search engine to investigate the claim further. 

There are several reasons why it is useful to associate a claim with information justifying alternative points of view:

\begin{itemize}
\item To allow a user to quickly determine whether alternative points of view are sufficiently credible that they should take them seriously
\item To allow users who are moderating the database to determine when no arguments exist for other points of view, and thus the claim should not be in the database
\item To allow Dispute Finder's algorithms to determine whether the claim is disputed by someone that that particular user would take seriously. Although we have not yet implemented such features, we believe they will be important.
\end{itemize}

We prototyped and tested two different ways of showing a user alternative points of view to the disputed claim they are looking at:

\begin{description}
\item[Argumentation graph:] When the user clicks on a snippet that makes a disputed claim, Dispute Finder shows them an IBIS-style\cite{gibis} argumentation graph that explains the structure of the argument against the claim. Each claim is linked to claims that represent alternative points of view, and claims that support that point of view. Each claim also has a list of sources that argue in favor of that claim (Figure\ref{arg-graph?})

\item[Source lists:] Dispute Finder shows the user two lists of sources, one of which contains sources arguing in favor of the claim, and the other of which contains sources arguing against the claim (Figure~\ref{article-list})
\end{description}

The argumentation graph is potentially much more powerful. When a user is presented with a simple list of sources, several of them may be making the same core points and it may not be obvious that one of the sources is making a point that the user had not come across before. The argumentation graph also allows the user to browse around the network of different claims being made about an area, which can be interesting in itself.

On important disadvantage of using an argumentation graph is that someone has to build it. In our prototype, the argumentation graph was built entirely by users. We found that our users had difficulty creating well structured argumentation graphs that were useful for other users, a result that is consistent with previous studies~\cite{ibis-bad?}. It is possible that an alternative (simpler?) graph structure or interface that made it easier to build such graphs might make them work better. Argumentation graphs might also work better if they could be built automatically by mining the web.

Another point in favor of using a simple list of sources is that we found that users are far more concerned with ``who'' disputes a claim, than what their argument is. For example, if a user is a reader of the New York Times, and they hear that the New York Times argues against the claim they are reading, then they will take the dispute much more seriously than if the key article arguing against the claim is from a source they are not familiar with. The argumentation graph focusses on presenting the user with the structure of the argument against the claim, but our studies suggest that the user is likely to find this much less interesting than the authority behind the arguments against the claim. 

In the present version of Dispute Finder, a source can be any web page that meets the Wikipedia criteria\footnote{http://en.wikipedia.org/wiki/Wikipedia:SOURCES} for being reliable. Good sources include newspapers, universities, respected organizations, and Wikipedia itself. Users can vote on whether they think a particular source is useful, and this voting determines the order in which sources are listed. A user can also request that a source be deleted if it is not relevant to the claim, or request that a claim be deleted if it is not disputed by any reliable sources. Users with moderator privileges review requests for deletion and delete claims and sources that do not meet requirements.

\todo{study result: verify}
There are significant weaknesses in this approach. In our studies, we found that users disagree about what they would consider a reliable source. Users consider a source to be reliable if it espouses opinions that they themselves agree with, and is accepted as being a reliable source within their social group. There may be little point showing liberal sources to a conservative, or vice-versa. Similarly, a global voting system can be gamed by people who want to hide good arguments against a claim that they support by voting up bad ones. Another problem is that, by resorting to moderators to decide which sources and claims are high enough quality to be included, we open ourselves up to charges of bias.

In the future it may be better to learn what sources a particular user is likely to believe are reliable, and then adjust both what sources Dispute Finder shows to the user, and what claims are highlighted, based on this.

There is a difficult trade-off here. If we only show users sources that we believe they are likely to trust, then we risk reinforcing the echo-chamber effect that Dispute Finder is intended to fight against. On the other hand, if we only provide information from sources that are widely regarded as being reliable, we risk enforcing the beliefs of the establishment, and stifling the voices of those who are less widely respected by the establishment, but may be right. If we pay no attention to what sources the user trusts, or what sources are regarded as respectable, then we may waste time trying to persuade users using sources that they would not take seriously. We do not yet claim to know a good solution for this problem.

\todo{Cite Pew Research study saying people like to read news that supports their own point of view, but many others like neutral sources. http://people-press.org/report/?pageid=1353}


\subsection{What is Disputed?}

One of the key challenges for Dispute Finder is determining what claims are Disputed. Dispute Finder takes the approach of maintaining a database of known disputed claims, which it then looks for on web pages.

What we are after is not a list of everything that has every been disputed by anyone, but a list of claims that are frequently believed and are opposed by reliable sources. In some sense almost everything is disputed by someone on the web. There are enough people writing enough opinions that if we alerted users every time anything they read was disputed by anyone then Dispute Finder would would be so distracting as to be worthless. Similarly, there is little point spending effort rebutting claims that nobody believes. For example there is reliable evidence that the moon is made of cheese, but few people believe this claim is true.

Fortunately, several web sites already maintain databases of disputed claims, together with arguments against them. For example Snopes.com maintains a list of urban legends and politifact.com maintains a list of false claims about politics. We automatically import all claims that these sites debunk into our database and treat the sites themselves as reliable sources about the claims they debunk. In the future we intend to also import claims from other such sites.

We also allow users to add their own disputed claims using the Dispute Finder web interface (Figure\ref{web-add?}). The web interface is modeled after common issue-reporting software such as UserVoice\footnote{url?}. It first encourages the user to search the existing database to see if their claim already exists, and then allows them to create a new claim. When the claim is first added it is marked with a warning, informing the user that the claim will not be highlighted for other users until they have added at least one opposing source.

\todo{Actually import the Politifact data}

\subsection{Finding Snippets}

Given a web page that the user is browsing, and a database of claims that we believe are disputed, how can we determine what snippets on the page are making claims that are in our database? We implemented and tested four approaches:

\begin{description}
\item[Explicit page marking:] If the page a user is reading contains a snippet that makes a disputed claim, the user can mark that snippet by selecting it, right clicking, and selecting "mark as disputed" from a popup menu.

\item[Bulk page marking:] The user enters a paraphrase of the claim into a web UI. The server searches the web for snippets that resemble this phrase using Yahoo BOSS~\cite{boss?} and shows the user the snippets it found. The user clicks on all of the snippets that they would like to mark.

\item[Server-side classification:] The server uses the examples from the bulk page marking interface to train a classifier. We used a simple baysian classifier with n-grams as its features. As the user gives examples of snippets that do or do not entail the original claim, the classifier learns what n-grams should or should not be in a snippet. Once the classifier is sufficiently trained, the server applies it to the rest of the results from Yahoo BOSS to automatically mark web pages. We have only partially implemented this approach.

\todo{Has anyone done something like this before.}
\todo{We only partially implemented this approach}

\item[Client-side entailment:] The browser extension runs a simple textual entailment algorithm over all sentences on every web page the user browse, checking to see if any sentence on the page entails any claim in the database. A user can enter additional paraphrases of a claim to help the entailment algorithm. This is the implementation used by the currently released version of Dispute Finder.
\end{description}

Explicit page marking has the highest accuracy, but the poorest coverage. Since a user is looking at the page in its entirity, they can read the snippet in context and make a good judgement about whether the snippet is indeed making the claim. However the manual effort required per page makes it difficult for this approach to scale. It can also be hard to motivate a user to mark snippets if it is unlikely that another user with the Dispute Finder extension will read exactly this page. This is the same problem that has hindered the adoption of web page annotation tools.

Bulk page marking trades off some accuracy for better coverage. When a user searches for a phrase, they can quickly find hundreds of snippets and mark them by clicking on them. Since they are reading the snippet out of context, they are more likely to mark a phrase incorrectly. 

Server side classification trades off more accuracy for more coverage. The classifier can mark more pages than a user could ever mark manually, but is inevitably less accurate than a human.

Client side entailment gets even more coverage. Since the classification algorithm is run inside the client, the client can highlight snippets on pages that the server has not examined. This is particularly important for news pages, which are frequently read only a few minutes after they have been written. Moreover, the client-side approach can highlight snippets on web pages that would not be accessible to the server, such as web-based email, and information on an intranet.

The client side entailment method uses the standard Local Lexical Matching algorithm that is a common baseline in NLP. It divides the page into sentences, strips out stopwords, does stemming, and then looks for sentences that contain the keywords contained in a paraphrase of a known claim. If the claim contains a negation word (e.g. not, never, can't) then so must the matching sentence.

\todo{Discuss how and why this is simpler than the server-side classification method}
\todo{Explain how we avoid downloading the entire database}


The client side entailment method uses a simpler algorithm than the server-side classifier. 



\todo{Should we have a version where the interface merely suggests n-grams that should be used by the classifier}
\todo{Can we present all these systems without giving detailed stats about how they compare?}
\todo{Add support for a user to enter 'anti-phrases' when a snippet is wrongly highlighted}
\todo{Add support for a user to enter a paraphrase that will match the snippet they are looking at}
\todo{Do a load more people in a final user-study round. Try to get it up to 8.}
\todo{Explain how our algorithm relates to existing NLP work - due to unusual domain}


\section{Studying the Users}

The Design of Dispute Finder has been influenced by several different kinds of input from potential users. We performed a series of "think aloud" user studies to evaluate the user interface, we circulated a survey among members of a local debate club, and we performed a series of interviews with people selected from those who completed the survey.

\subsection{Survey}

\subsection{Interviews}

\subsection{Think-Aloud User Studies}

We performed three qualitative "think aloud" user studies. The aim of these studies was to inform the iterative design of the Dispute Finder tool. The studies were not intended to validate the design of Dispute Finder as being correct. The only way we will be able to truly validate Dispute Finder is by having it be adopted by a large community of active users - something it is not yet mature enough for.

\subsubsection{Procedure}

For the first two studies, we recruited participants using Craigslist. We posted a message asking people to tell us how they used the web to form and promote their opinions, and used this to select people who we thought might fit our "skeptical reader" and "activist" personas. After these studies, we decided that the kind of person who looks for jobs of craigslist is unlikely to be a good fit for our personas, and so for the final study we instead used people we knew personally and thought fit our personas well. All study groups were small. The first study had twelve participants (five female, seven male), the second study had six participants (four female, two male), and the final study had ?? participants (?? male, ?? male). 

Each batch of users was shown a different iteration of the Dispute Finder design. The first two batches used versions in which users marked snippets explicitly, and the popup window for a claim showed an argumentation graph describing the structure of the different alternative points of view. The final group used a version in which a textual entailment algorithm on the client was used to determine what to mark, and the popup window showed lists of sources that support or oppose the claim. We present the findings of the three user studies together. Where a comment refers to particular version we make this clear.

Study sessions took approximately fourty five minutes. Participants were seated at a workstatation with the Firefox browser augemented with the Dispute Finder extension. They were asked to view pages that had highlighted claims on them, and to attempt to add new disputed claims to our database.

\todo{Need to finish the third wave of user studies}

\subsubsection{Findings}

Response was generally positive, with many participants being very keen to use the tool soon. Several participants asked as to notify them when it is properly deployed. Most of the participants expressed an interest in using the tool, with some wanting to use it now, and others wanting to use it ``when it is more mature''.

Most participants said that they would want to use Dispute Finder to tell them when information they read was disputed (skeptical reader). One participant said ``The web needs to be taken with a grain of salt, and this gives you salt goggles''. A smaller number said they would be likely to enter claims they disagreed with (activist). One participant who was a political blogger was very excited about the mark things he thought were lies.

Most users were able to use Dispute Finder compentently as a skeptical reader (browsing information about disputed claims) but found it harder to act compentently as an activist (adding new disputed claims).

When browsing a page that had disputed claims highlighted, most users correctly inferred that these were sentences they should be skeptical about, but some users thought that we were saying they were wrong, rather than merely disputed. Not all users realised that one could click on a disputed claim to bring up more information.

%In the first study, a user could mark a snippet by 
%
%In the interface used in the first two studies, a user could mark a snippet by selecting it, right clicking on it, and clicking "mark as disputed". They were then prompted to either select an existing claim or create a new one.

When asked to mark snippets on a particular page that make disputed claims, users often did not appreciate that they should either re-use existing claims or create claims that would be applicable to snippets on many other pages. Several users tried to create a new claim with exactly the same text as the snippet they were marking, and several users asked why they had to "enter the text again". Similarly, users got confused when a snippet made two different disputed claims. The correct behavior is to mark the same text with two different claims, but several participants tried to create a new compound claim such as "Global warming will cause X and Y". 

Conversely, when adding a claim to the Dispute Finder web site, users would often enter claims that are not disputed anywhere on the web, or enter paraphrases that do not resemble the wording used on any web site. The challenge of how to help users come up with claims that occur on many web sites is one that we have not yet solved.

Several users expressed confusion about how specific a claim they created should be. For example, if a snippet says ``Global temperatures will rise by X degrees by 2050'' then is that making the claim ``Global temperatures will rise'', or should the claim include the extra information? In order to make a good judgement, one needs to know the range of similar claims that are being made by other web sites, and what claims one has good evidence against. If one makes the claim too specific then one will be able to find less web pages that make it, but if one makes the claim too general then it might be harder to find solid evidence against it.

When adding sources that support or oppose a claim, a user would frequently mark the first paragraph of the article rather than seeking out the sentence that best summarized the argument that the article was using against the claim. In some cases the first paragraph is indeed the right text to select, since the first paragraph is typically a summary of the core argument made by the articles. Several users wanted to mark up a table or image as the summary of an article, which is not currently supported.

In the first two studies, the popup interface for a claim showed an argumentation graph. This graph connected the graphs in our database using "supports" or "opposes" links, and allowed each claim to also be associated with supporting articles. 

When shown an argumentation graph for a claim, users seemed to have little difficulty navigating and understanding it and appreciated the ability to explore the structure of an argument and see how different claims were connected. One user said "I can see myself getting addicted to this", and another said "it's very intuitivet".

Users seemed to have difficulty creating such graph structures however. Some users linked one claim as supporting another when it would have been more logically correct for them to both support a third claim. For example "Global warming is causing more hurricanes" does not support "Global warming is causing rising sea levels", but both support "Global warming is causing problems". Users correctly realised that the claims were related, but were not sure how best to connect them. Some users were confused by claims that had a ``because'' relationship rather than a ``supports'' or ``opposes'' relationship. For example ``America did not sign the Kyoto Protocol'' {\it because} ``Signing Kyoto would harm the US economy''.  It is possible that creating logically correct claim structures may be too difficult for some people (see Isenmann and Reuter~\cite{Isenmann1997}).

Several users got confused by claims that referred to similar events at different points in time. For example, one participant in the first study marked two claims as opposing each other when each was true at the time that it was written. This is a particular problem when talking about breaking news events, where the facts can change fast. If Dispute Finder is to be effective for describing such events then it will need to have better support associating times with claims and snippets.

Several users expressed an interest in being able to add a disputed claim without having to find opposing evidence. One user said that opposing a claim required ``too many clicks'' and they wanted to be able to just vote against a claim without having to say why or find evidence. 

Several users created claims that had ambiguous meanings. One user entered a disputed claim about "Wood", meaning the guitarist "Ronnie Wood" of the Rolling Stones. Similar problems occured with claims that were specific to a particular country, or a particular point in time. 

\todo{Need to say that the argumentation graph contains all existing claims and that it was a simple "supports"/"oppsose" graph.}.

\todo{Come up with terminology for marking an evidence snippet, and agree on evidence vs source vs article}
\todo{Talk about how the early versions conflated evidence and snippets - and whether it makes sense to distinguish between them}
\todo{Screenshot of the claim graph interface}


\section{Conclusions and Future Work}

We have introduced the idea of creating an Open Hypermedia system that automatically highlight snippets on the web that are disputed by sources you might trust. We have explored several different design options, tested multiple variants on users, and reported insights from this testing.

An experimental preview version of Dispute Finder is available at the following URL:
\url{http://disputefinder.org}

Performing these tasks well is a hard problem, and we do not yet claim to have an implementation that is is good enough to be compelling for most users. We do however believe that Dispute Finder attacks an interseting problem that, if solved well, could significantly improve the utility of the web.


\section{Acknowledgments}

\todo{Do we want to have acknowledgements}
% We would like to Thank Barbara Rosario for help with textual entailment, and 
% Acknowledgements omitted for blind submission. Dispute Finder uses icons from the free FamFamFam Silk\footnote{http://famfamfam.com} collection.


\todo{Sort out bad references}
\bibliography{refs}

\end{document}



