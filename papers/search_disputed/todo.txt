
* Do bigger crawl and load many many more claims
* Trim out the "BAD" stuff (should all auto-go-away)
* Get some form of classifier working

* Load more URLs from Yahoo, to get a much bigger corpus
	- have this running slowly in the background while doing other stuff
	


* Get new classifier working on the web site, and verify it works
* Add "no evidence that" claims. + Process their data.
* Increase corpus size with larger crawl

* Use Turk to gather much more training data in there separate stages.
	- good/bad claim. Relevant/irrelevant claim. Agree/disagree.

* Request more urls with Yahoo
* Generate updated claims table (url, pattern, claim sentence, date)
* Load the data into the database
* Get the matching algorithm working well
* Produce Search Engine front-end using API - so we can start marking up data
* Add snippets to API and interface - so we can see the context and if it is right
* Add voting feature that tells us if the voting is correct
* Record stats for voting about snippets
* Use these votes to evaluate whether results are correct
* Build simple API that auto-searches for a set of searches on AOL search
	- open in multiple tabs ready to do bulk voting
* Tune matching algorithm until it seems to work well

* Add interface replacement for existing Dispute Finder front end
* Support all APIs called by the firefox extension
* Produce Search Async API.
* Support vaguer prefixes starting with just "claim that" etc, and then looking for negative sentiment
* Try to obtain an existing entailment algorithm and apply it
	- and then extend based on extra info I have from context


-- crawl other high frequency claims --

Year splitting works very well. For "no evidence that" we got 705k out of a predicted 807k.
For "the myth that" we get 290k out of predicted 306k.
	- pretty damn close to everything

[('no evidence that', 807698),
 ('the myth that', 306576),
 ('into thinking that', 293811),
 ('into believing that', 229559),
 ('the misconception that', 150754),
 ('mistaken belief that', 110762),
 ('the lie that', 91041),
 ('mistakenly believe that', 78699),
 ('it is not true that', 66171),
 ('the delusion that', 61163),
 ('against the idea that', 44716),
 ('rejected the idea that', 43741),
 ('reject the notion that', 43695),
 ('rejected the notion that', 42506),
 ('it is not the case that', 42266),
 ('mistakenly think that', 41763),
 ('falsely claimed that', 38980),
 ('no scientific evidence that', 37703),
 ('incorrectly stated that', 36454),
 ('the fantasy that', 30693),
 ('rejected the argument that', 29038),
 ('falsely claiming that', 28718),
 ('it is a myth that', 27905),
 ('no credible evidence that', 25873),
 ('mistaken notion that', 25810),
 ('false belief that', 25800),
 ('the misperception that', 25318),
 ('the fraud that', 24482),
 ('reject the idea that', 24385),
 ('mistakenly thought that', 23518),
 ('false claim that', 22860),
 ('mistaken idea that', 22282),
 ('disagree with the idea that', 21857),
 ('mistakenly believed that', 21404),
 ('the deception that', 20342),
 ('false idea that', 20241),
 ('the fallacy that', 20163),
 ('against the notion that', 20007),
 ('erroneous belief that', 19856),
 ('falsely believe that', 19715),
 ('disagree with the notion that', 18452),
 ('the myth is that', 18259),
 ('the scam that', 17980),
 ('the misunderstanding that', 17519),
 ('falsely claim that', 17407),
 ('false notion that', 16214),
 ('false claims that', 15965),
 ('wrongly believe that', 15819),
 ('erroneously believe that', 14234),
 ('absurd notion that', 13900),
 ('falsely claims that', 13644),
 ('rejected the suggestion that', 13269),
 ('disagree with the assertion that', 12205),
 ('the hoax that', 11964),
 ('false rumors that', 11223),
 ('incorrectly believe that', 11132),
 ('absurd claim that', 10990),
 ('rejected the claim that', 9534),
 ('erroneously stated that', 9446),
 ('false accusations that', 9188),
 ('falsely stated that', 9068),
 ('it is false that', 8982),
 ('false beliefs that', 8945),
 ('rejecting the idea that', 8625),
 ('false rumor that', 8514),
 ('disputed claims that', 8469),
 ('the urban legend that', 8448),
 ('rejecting the notion that', 8346),
 ('it is a lie that', 7989),
 ('wrongly believed that', 7364),
 ('absurd idea that', 7347),
 ('false assertion that', 6865),
 ('bogus claim that', 6701),
 ('erroneous idea that', 6602),
 ('mistakenly thinking that', 6576),
 ('contrary to the belief that', 6353),
 ('falsely stating that', 6322),
 ('refute the idea that', 6259),
 ('against the claim that', 6247),
 ('false accusation that', 6240),
 ('the misconception is that', 6121),
 ('rejected the contention that', 6062),
 ('reject the argument that', 5987),
 ('rejecting the argument that', 5591),
 ('debunk the idea that', 5537),
 ('wrongly think that', 5502),
 ('erroneously believed that', 5464),
 ('erroneous notion that', 5361),
 ('idiots who think that', 5146),
 ('refute the claim that', 5076),
 ('debunk the notion that', 5024),
 ('reject the claim that', 5023),
 ('the lie is that', 4960),
 ('refute the notion that', 4844),
 ('misleading claims that', 4799),
 ('erroneously think that', 4699),
 ('the deceit that', 4592),
 ('mistakenly thinks that', 4468),
 ('incorrectly believed that', 4368),
 ('against the belief that', 3959)]



-- extra prefixes -- 

"so called"



-- features --

Trimmed text contains full stop, question mark, etc.
Obtain DIRT knowledge base and use that?
Use verbOcean to match similar verbs and Wordnet for similar nouns.
BLUE - geometric average of n-gram overlap for different length n-grams.
Commonly occurring extra words.
Similarity to other pages that were exact matches for the claim
Document cosine vector similarity.
Paragraph cosine similarity.
Edit distance. Fractional edit distance. Word edit distance. Fractional word edit distance.
	Number of edit operations of particular types.
		(Add word, Add synonym, Add pos-X, Add particular common word, etc)
Wikipedia linkiness of words in the claim.
Wikipedia graph similarity of documents.
Are all match words in the same sentence?
Are all match words in the same order?
Number of "ok words" that are not present?
Number of extra words inserted between words in the matched text.
Number of bigram matches.
Number of claim words that matched a synonym rather than a correct word.
Kinds of extra words in the match text. E.g. are they verbs etc. Gather data and see what the trends are.
	Theory: verbs are bad. Adjectives are ok.
Date when page was written (we have dates for claims and for current page listings)
What prefix was used.

Proportion of missing claim words that are synonyms of match words.
Proportion of missing match words that are synonyms of claim words.
	- need to find exact proper textual entailment algorithms.


Upper vs lower case. Currently everything is lower case. Definitely want mixed case in future.

-- goals for CIKM paper --

Focus is on algorithms that tell us if we have a correct match.
Having a big data set is not quite as important, though obviously we want that too.


-- goals for R@I launch --

Want it to be actually usable as a real tool by real people.
Want it to be running on the existing server, rather than somewhere separate.


-- APIs used by the firefox extension --

/apianon/hotwords.json
	- get a list of all "hot words" used by claims
	- for each claim, what is the rarest word
	- disregard any claim that doesnt have a rare enough word

	Does the hotwords list get too long?

	How long is "hotwords" for our current set?
		34k words.
		What is the total length?
			278k
				That is totally reasonable, given we only grab it on startup.
	I think the current approach may actually work.

/apianon/hotwords/[word].json
	- easy to implement on top of current stuff
	- returns a list of second words.

/apianon/


-- too many requests for common words? --

Better to have it make a request for multiple words at once.

BUT:
	Actually should be fine to make multiple requests. HTTP1.1 should batch stuff.
	Worry about performance later.


-- split by top level domain also --

When we get down to a leaf level by years, we might want to also split by top level domain (e.g. "com", "net" etc)

Only worth splitting by domain if a domain appears several times in the one million url set. Otherwise probably just a rogue.


-- training data set --

Aim - get up to 1000. Then we have enough to start training...
Ignore anything where I can't make a clear call.

In most cases, we don't seem to need source page context as it is fairly obvious what was meant.
Of course, properties may change if we start using a different claim filter...


-- dates --

We aren't saving the Yahoo page date in our training data.
	We probably should.
	That information is probably important.

Can we get it back?
	We don't want to re-generate everything.

Solution: add it in going forward, but train with what we have.







