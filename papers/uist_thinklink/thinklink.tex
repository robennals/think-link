%\documentclass{article}
\documentclass{chi2009}
\usepackage{times}
%\usepackage{uist}
\usepackage{url}
\usepackage{graphics}
\usepackage{color}
% \usepackage[pdftex]{hyperref}
% \hypersetup{%
% pdftitle={Browsing the Web of Factual Claims},
% pdfauthor={Beth Trushkowsky and Rob Ennals},
% pdfkeywords={CSCW, sensemaking, web, browsers, collaboration, mind mapping},
% bookmarksnumbered,
% pdfstartview={FitH},
% colorlinks,
% citecolor=black,
% filecolor=black,
% linkcolor=black,
% urlcolor=black,
% breaklinks=true,
% }


\newcommand{\want}[1]{{[\color{blue} WANT: #1]}}
\newcommand{\todo}[1]{{[\color{blue} TODO: #1]}}

\begin{document}

% --- Copyright notice ---
\conferenceinfo{UIST'09}{October 4-7, 2008, Victoria, BC, Canada}
\CopyrightYear{2009}
\crdata{x-xxxxx-xxx-x/xx/xxxx}

% Uncomment the following line to hide the copyright notice
\toappear{}
% ------------------------

\bibliographystyle{plain}

\title{Exposing Disputed Statements on the Web}

%%
%% Note on formatting authors at different institutions, as shown below:
%% Change width arg (currently 7cm) to parbox commands as needed to
%% accommodate widest lines, taking care not to overflow the 17.8cm line width.
%% Add or delete parboxes for additional authors at different institutions. 
%% If additional authors won't fit in one row, you can add a "\\"  at the
%% end of a parbox's closing "}" to have the next parbox start a new row.
%% Be sure NOT to put any blank lines between parbox commands!
%%

\author{
\parbox[t]{9cm}{\centering
	     {\em Author Name removed for blind review}\\
}
\parbox[t]{9cm}{\centering
	     {\em Author Name removed for blind review}}
}

\maketitle

%RULE: Don't cite media reports unless I have to

\abstract
We present Think Link, a browser extension that aims to let users see when the information they are reading presents only one side of a disputed issue. As the user browses the web, Think Link highlights snippets of text that make claims that conflict with information on other web sites. If a user clicks on such a disputed claim then Think Link will show tem an argument graph showing the best evidence for and against the claim being true, as determined by other users of Think Link.

\keywords{CSCW, sensemaking, web, browsers, collaboration, mind mapping} 

\classification{H5.2 [Information interfaces and presentation]:
User Interfaces. - Graphical user interfaces.}

\terms{Design, Human Factors}

\keywords{Sense-making, Annotation, Argumentation, Web}


\tolerance=400 
  % makes some lines with lots of white space, but 	
  % tends to prevent words from sticking out in the margin

\section{INTRODUCTION}

The web provides users with a huge number of pages that they can read, but extracting accurate and balanced information from these pages can be difficult. Not everything on the web is accurate~\cite{Mintz2002,Neumann2003,Resnik1998,Zhou2004} and many web sites present only one side of a contentious issue~\cite{Herman2002,Gentzkow2007}. If a user is to form a rounded opinion about a topic then they will need to either stick to sources that they trust or spend time looking for evidence on other web sites that supports or opposes what they read. Even if a user tries hard to research every topic they read, they can still get caught out by beliefs that they had not realised were disputed.

In this paper we present Think Link, a tool helps users discover when information they read conflicts with information on other web sites, and shows users the best sources that provide alternative points of view. When Think Link is used as a browser plugin it will highlight text that makes a disputed claim. If a user clicks on such a highlighted snippet then Think Link presents the user with an argument graph that shows the best evidence for and against the claim, as judged by other users of Think Link (Figure~\ref{claimview}). The argument graph contains links to snippets of text on other web sites that express conflicting or supporting points of view.

Think Link relies on users to identify disputed claims, to find appearances of these claims on web sites, and to vote for which snippets are most important. If a user is viewing a web page, they can identify disputed claims and useful evidence. Think Link will guide a user in finding existing claims that a snippet may be making and in connecting existing claims.

Think Link is designed to cator to two distinct groups of people. Activists care strongly about particular claims that they disagree with and combine Think Link with a preferred search engine to find instances of these claims and mark them up so other users can see them. Sceptical readers install Think Link as a browser plugin so that they can see when things they read and disputed and find other links that present other points of view. A reader may of course be an activist for one issue and a sceptical reader for others.

The design of Think Link was guided by two user studies, in which we observed the behaviour of users who fitted the roles of Activist or Sceptical Reader. 

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=6cm]{../screenshots/claim_popup_crop2.png}
	\caption{Click on a claim to investigate evidence for and against it}
	\label{claimview}
	\end{center}
\end{figure}

% \begin{figure}[tb]
% 	\begin{center}
% 	\includegraphics[width=7.7cm]{../screenshots/summary_graph.png}
% 	\caption{Think link connects claims to each other and to web snippets}
% 	\label{summarygraph}
% 	\end{center}
% \end{figure}


\section{Related Work}

Think Link builds on work in several different areas. The argumentation structure influenced by IBIS~\cite{Rittel1973} tools such as gIBIS~\cite{Conklin1987}; the idea of highlighting information that may not be trustworthy was previously applied to Wikipedia by Wiki-Trust~\cite{Adler2008}; the model of using a community to collect and filter information from a range of sources is influenced by tagging systems~\cite{Marlow2006}; and the idea of gathering up a collection of snippets from web pages has been used by clipping tools such as Internet Scrapbook~\cite{Sugiura1998}. 

What makes Think Link interesting is the way that it combines ideas from these different domains and applies them to the task of leading users towards information that conflicts with that which they read.

\subsection{Argumentation}

Think Link is an example of an Issue Based Information System (IBIS)~\cite{Rittel1973}. IBIS tools such as gIBIS~\cite{Conklin1987}, Compendium~\cite{Selvin2001}, Collabatorium~\cite{Klein2007}, Zeno~\cite{Gordon1996}, and Cohere~\cite{Shum2008} model discouse as a graph of connected ideas. While the graph structure varies between tools, most tools allow one to mark an idea as supporting or opposing another idea, and allow one to mark an idea as addressing an issue. Some tools, such as Collabatorium~\cite{Klein2007} and Cope It~\cite{Karacapilidis2001} structure an argument as a tree, while others such as Think Link, gIBIS~\cite{Conklin1987} and Cohere~\cite{Shum2008} structure an argument as a graph, in which a single idea can support or oppose multiple other ideas.

Cohere is perhaps the tool most similar to Think Link. Cohere allows one to use snippets from web pages as evidence to support ideas in its argument graph and provides a Firefox plugin that makes it easier to grab snippets from pages that one browses. While Cohere and Think Link both connect an argument graph to the web, they do so in very different ways. In Cohere, a user attaches a web snippet to their idea in order to use it as evidence. By contrast, in Think Link, the main reason to connect a web snippet to an argument is to mark the snippet as contentious and encourage other readers of the snippet to look at the argument. 

ClaimSpotter~\cite{Sereno2005,Sereno2004} allows one to mark up a scholarly document with logical triples (subject, verb, object) describing interesting claims that are being made in the document. This semantic information can be used to connect claims in different documents and see when a logical claim in one document contradicts another. Entity Workspace~\cite{Bier2006} does something similar for intelligence documents.  

Think Link uses a relatively simple graph structure, similar to that of gIBIS~\cite{Conklink1987}, allowing a claim to support, oppose, or be related to another claim. Cohere~\cite{Shum2008} extends this by allowing one to new link types marked with pro,con,or neutral polarity Toulmin~\cite{toulmin1958} proposes a more complex graph structure, implemented that expresses warrants, data, qualifiers, and reservations. Verheij~\cite{Verheij1999} uses the Toulmin model to create an argumentation tool for lawyers.

Think Link's argument visualization is influenced by the left-to-right layout of Cohere~\cite{Shum2008}. Compendium~\cite{Selvin2001} contains a number of other visualizations of argument graphs. Mess Maps~\cite{Horn2007} present an alternative view in which an argument is divided into different sectors, each of which presents the argument from a different frame of discourse (e.g. policy maker vs industrialist vs environmentalist).

Isenmann and Reuter~\cite{Isenmann1997} identify a number of problems with the IBIS model, which they argue are reasons why it has not achieved widespread use. We believe that while the problems they observe are important when an IBIS tool is being used for conflict modelling and resolution they are less of a problem for a tool like Think Link that is designed primarily for conflict discovery. We do not expect users to use Think Link to create a detailed model of an argument and use this to reach consensus. Instead, our aim is that a user should use Think Link to discover when things they read are disputed, and easily find evidence for the other side.
\todo{Say more about this}.

When chosing an argumentation structure, there is an inherent trade-off between accurately modelling the structure of an argument and making the tool easy to use. For Think Link, we have tried to minimize the complexity of the model, and thus adopted a very simple pro/con/netural link model. The idea here is not so much to present the detailed logical structure of an argument as to show a user what sources they should look at when forming an argument for or against a claim.

% TRELLIS
% 
%  gIBIS~\cite{Conklin1987} and other IBIS~\cite{Rittel1973} such as ZEN
% 
% Cohere~\cite{Shum2008} is probably the tool most similar
% 
% 
% 
% Cohere~\cite{Shum2008}. Compendium~\cite{Selvin2001}. Cope it~\cite{Karacapilidis2001}. AIF~\cite{McGinnis2007} and ArgDF~\cite{Rahwan2007}. IBIS~\cite{Rittel1973}. gIBIS~\cite{Conklin1987}. IBIS problems~\cite{Isenmann1997}. ClaimSpotter~\cite{Sereno2005,Sereno2004}. ClaiMaker~\cite{Uren2003}. Video Annotation~\cite{Diakopoulos2008}. Collabatorium~\cite{Klein2007}, for Global Warming~\cite{Malone2007}. Lawyer argument model~\cite{Verheij1999}. Toulmin model~\cite{Toulmin1958}. Zeno~\cite{Gordon1997}. Discoursium~\cite{Yetim2007}.
% Entity Workspace~\cite{Billman2007}. 
% Mess Maps and Resolution Mapping~\cite{Horn2007}.
% TRELLIS~\cite{Chklovski2005}.  
% People should define own link types~\cite{Wang1998}.
% 
% Hypertext systems such as Notecards~\cite{Halasz1988}.

\subsection{Checking Accuracy and Bias on the Web}

If one sees a claim on the web that one suspects might be untrue then one can look it up on Snopes\footnote{http://snopes.com} or FactCheck\footnote{http://factcheck.org}. Snopes is a database of urban legends that the site owners have investigated to determine whether they are true or not. FactCheck is a web site that investigates claims being made by US political parties and attempts to uncover the facts. 

NewsCube~\cite{Park2009} and MediaCloud\footnote{http://mediacloud.org} use statistics to help readers avoid media bias. NewsCube presents a user with articles on the same topic that have different biases. MediaCloud applies various statistical analyses to news sources so that a reader can see when different news sources associate different words with the same topic.

Several authors have investigated ways to make Wikipedia\footnote{http://wikipedia.org} more trustworthy. WikiTrust~\cite{Adler2008} highlights passages on wikipedia based on the likelihood that another user will change that text in the future --- recent edits by untrusted editors are marked as less trustworthy than old edits by trusted editors. Wiki Dashboard~\cite{Kittur2008} presents the reader of a Wikipedia article with a visualization that shows them how it has been edited in the past and lets them see graphically how contentious the topic is. Wiki Scanner\footnote{http://wikiscanner.virgil.gr} finds Wikipedia edits that have been made by people with an interest in spreading misinformation (e.g. people from a company editing pages about that company).

% 
% 
% NewsCube~\cite{Park2009}.
% Wikipedia fixes Vandalism~\cite{Viegas2004}.
% Trustworthiness~\cite{Gil2006}.
% WikiTrust~\cite{Adler2008}. Wiki Dashboard~\cite{Kittur2008}.
% Wiki Scanner\footnote{http://wikiscanner.virgil.gr}.
% SourceWatch\footnote{http://sourcewatch.org}, Snopes\footnote{http://snopes.com}, FactCheck\footnote{http://factcheck.org}.

\subsection{Tagging and Annotating}

Video Annotation~\cite{Diakopoulos2008}

Tagging~\cite{Marlow2006}. Tagomizer~\cite{Park2007}. Reasons for choices of tags~\cite{Sen2006}. Tagging Roles~\cite{Muller2008}. 

SpinSpotter\footnote{http://spinspotter.com}. ClipMarks\footnote{http://clipmarks.com}, Diigo~\footnote{http://diigo.com}, Stickis\footnote{http://stickis.com}.

How to Personalize the Web~\cite{Barrett1997}. 

\subsection{Clipping}

ScratchPad~\cite{Gotz2007}. Internet Scrapbook~\cite{Sugiura1998}. Reverse Linking~\cite{Yesilada2007}. Hunter Gatherer~\cite{2002}. Dontcheva~\cite{Dontcheva2007a}.

\subsection{Semantic Web}

Nobody is going to mark up their own web page as being wrong.

\subsection{To discuss in the body}

Paraphrases~\cite{Chklovski2005}. Suggested formal paraphrases~\cite{Blythe2004}.
Importance of Lurkers~\cite{Takahashi2003}
Wikify~\cite{Mihalcea2007}.





Think Link is very influenced by wikis like Wikipedia~\cite{wikipedia}. Like Think Link, wikis allow users to find information organized by topic rather than author and allow users to collaborate together to bring together all the best information about a topic. Wikipedia's greatest strength is arguably also its greatest weakness. Since anyone can edit Wikipedia, there is always the danger that information one reads may be incorrect~\cite{wikifalse}. Several projects have attempted to address this problem by tracking sources of edits~\cite{wikicorrect,wikicorrect2,wikicorrect3}, but it is difficult to remove the problem entirely. While good Wikipedia articles will often include references to sources for their claims, following all sources to check up all claims can be laborious. Think Link tries to avoid this problem by linking claims back to the original sources that made these claims. Users can thus use the known trustworthiness of the original sources to judge the reliability of a claim. 

When a topic is heavily politicized, Wikipedia can be subject to edit wars in which people who hold one opinion delete opinions held by the other side~\cite{wikicorrect3}, making it difficult for the community to collaborate together to produce a document that is both comprehensive and unbiased. Think Link attempts to avoid this problem by taking an ``append-only, collaborative filtering'' approach. A user cannot remove claims that they disagree with\footnote{With special exceptions for dealing with spam and abuse}. Instead all they can do is vote against them, and connect them to claims that provide opposing evidence.

Another key difference between Think Link and a wiki is that Think Link pulls the whole web into its graph of connected claims. A user can use Think Link to investigate claims they read on arbitrary web sites, without having to restrict their browsing to a single wiki site.

SpinSpotter~\cite{spinspotter} shares Think Link's goal of allowing users to identify misleading and inaccurate information on web pages that they read. If a user sees a section of text that they think is misleading then they can mark it up, causing it to be highlighted when other users view the same page. While Think Link and SpinSpotter both share the goal of letting users mark up snippets that may be inaccurate, they differ in what they let users find out about such snippets. SpinSpotter allows users to give a textual description of why the snippet is spin and a suggested edit that would make it more accurate. Think Link instead connects the snippet to its global claim graph, allowing users to quickly access evidence for and against the truth of the claim. There is also a difference in the nature of what SpinSpotter and Think Link expect users to mark up. Think Link is interested in evaluating the truth of factual claims, while SpinSpotter also interested in identifying biased phrases (e.g. ``tree hugger'').

Other web annotation systems such as ShiftSpace.org, Stickis.com, SharedCopy.com, and Diigo.com allow people to add their own annotations to existing web pages and view annotations written by other people. Common annotations include commenting on perceived inaccuracies, highlighting interesting passages, or linking to other relevant documents. More generally, tools like WBI~\cite{personalweb} and Mash Maker~\cite{mashmaker} allow arbitrary changes to be made to web pages. We are not aware of any such system that links web pages to a graph of factual claims. 


Web clipping tools such as Google Notebook, Scrapbook~\cite{scrapbook}, and Zotero.org allow one to gather and organize interesting from web pages. Many web clipping tools are also web annotation systems. These tools are designed for gathering and sharing interesting information, rather than for identifying the claims being made, or allowing users to navigate to related claims being made on other sites.

In Vannevar Bush's seminal MEMEX article~\cite{memex} he proposed an architecture in which links between documents were established by readers, according to the associations between them. As Bush says: ``It is exactly as though the physical items had been gathered together from widely separated sources and bound together to form a new book''. Several more recent systems have allowed user to add links to existing pages. ENQUIRE~\cite{weavingtheweb} and TrackBack~\cite{trackback} have bidirectional links, allowing one to see the sites that link to a page as well as those that link from it. Everything2.com links each page to the most popular pages that users viewed at the same time. Think Link's key difference from this work is that it imposes an additional layer of structure, identifying the factual claims that snippets are making and allowing users to browse this graph, rather than just allowing users to specify links between pages.

One of the goals of Think Link is that people should be able to browse information on the web through the ideas being expressed. This is a goal that is shared with several other projects. Kolak and Schilit~\cite{quotations} find places where a passage is repeated in several documents (usually a quotation) and allow users to navigate from such a passage to all other documents where that passage is quoted. Idea Navigation~\cite{ideanavigation} uses a natural language parser to identify subject-verb-object assertions in documents and then allows users to search for browse the assertions in a document corpus. ScentHighlights~\cite{Chi2005} identifies sections of text that you might find interesting and highlights them for you. ScentTrails~\cite{Olston2003} identifies links to documents that you might find interesting and makes them bigger. Unlike Think Link, these tool attempt to extract text of interest automatically, rather than relying on users to identify and connect interesting factual claims.

Much work has been done on the idea of using a graph to represent an argument~\cite{argumentation,argmas}. Popular argument models include the Toulmin Model~\cite{toulmin}, the Carneades Model~\cite{carneades}, and the IBIS model~\cite{ibis}. Models used for argumentation theory are usually significantly more complex than our simple supports/opposes model, with the result that they provide a more accurate model of the logical argument, at the cost of requiring more skill to assemble. One feature found in some argumentation graphs~\cite{Korb97acognitive} that we may add in the future is the ability to attach a numerical weight (maybe from voting) asserting how much a claim supports or opposes another claim, or how reliable a claim is.


%\subsection{Automated Reasoning}
%
%Case-Based reasoning
%Sensemaking

%\subsection{Argumentation Graphs}
%Argumentation graphs express positions and arguments in a formal graph model as nodes and edges, respectively, and are typically used to make a decision or draw a conclusion about some issue. One example implementation is the {\it Zeno} argumentation framework~\cite{zeno}, designed for collaborative use in mediation systems to debate the quality of alternative solutions for a problem. In their object model of argumentation elements, based on Rittel's IBIS model~\cite{ibis}, example nodes include pro/con arguments, positions, preferences, comments, and decisions. Importantly, arguments are connected via {\it consequent} and {\it antecedent} edges, which are used to inform {\it choices}. The decision-making power of the argumentation graph follows from the traversal of argument relationships to enhance the depth and breadth of understanding about an issue. Our application similarly links claims as {\it supporting} and {\it opposing} other claims to allow users to develop a cohesive understanding of arguments.
%
%Traditional argumentation graphs are designed to solve a specific, isolated issue. Our application supports an ever-expanding set of topics, and arguments can form links between multiple topics. Users can consult the web of ideas directly to form an opinion about a particular issue, but they can also browse for new issues to explore. Opinions or decisions in our model don't have to be static: as the topic is expanded with more supporting and opposing evidence, users may alter previous viewpoints. Another advantage of our model is that the ability to explore claims' source-document evidence is built right into the navigation. Looking at an argument shows both its related argument as well as its supporting {\it snippets}, allowing the user to explore the evidence for himself. 

\section{The Think Link System}


\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=6cm]{../screenshots/highlight_crop.png}
	\caption{Hovering over a highlighted snippet shows a summary}
	\label{highlight}
	\end{center}
\end{figure}


Think Link is a tool that overlays a web of factual claims on the existing web (Figure~\ref{summarygraph}). As a user browses the web, Think Link highlights snippets of text that have been identified as making factual claims. If a user clicks on a highlighted snippet, Think Link will display an interface that allows the user to easily find snippets on other pages that make related claims (Figure~\ref{claimview}). Think Link allows a user to easily access the best arguments for and against a claim that can be found on the web, and allows users to more easily evaluate the truth of claims that they read.

Think Link has a global graph of factual claims that is shared by all users (Figure~\ref{summarygraph}). This graph is managed like a wiki, allowing any user to add new claims or snippets. As a user browses the web, they can identify snippets that make claims that are interesting or controversial and link them into the global claim graph. 

Think Link is implemented as a Firefox extension~\cite{firefoxextend} and so can be applied to arbitrary websites without requiring them to be aware of Think Link.


\subsection{Exploring factual claims on a page}

When a user browses a web page, we want to make them aware of claims being made on the page that they might find interesting, or that other sources disagree with. Think Link draws attention to the factual claims that other users have identified on a web page by highlighting them (Figure~\ref{highlight}). Snippets are highlighted in red if they are contentious (other sources disagree with the claim). The highlight colors are chosen to be pale enough to not impede reading, dark enough to be noticeable\footnote{Unless the background is close to a highlight color. Think Link does not yet adapt to different page background colors}, and different enough to be distinguishable by colorblind people.
A user can see what claim a snippet is making by hovering their mouse over the snippet (Figure~\ref{highlight}).

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=6cm]{../screenshots/sidebar_diagram.png}
	\caption{The margin summarizes the key claims on the page}
	\label{margin}
	\end{center}
\end{figure}

If a user thinks a claim is interesting and wants to know what other sources say about it then they can open up a ``claim browser'' window (Figures~\ref{claimview} and \ref{claimbrowse_diagram}) by clicking on the highlighted snippet. The claim browser allows the user to easily view claims that support or oppose the selected claim, and find snippets of text on the web that make these claims (Figure~\ref{claimview}). 
For example, if a user browsed a web page that claimed ``Global Warming does not exist'', then the snippet that made this claim would be highlighted in red, indicating that there are web pages elsewhere that make opposing claims. If the user were to click on the highlighted snippet then an ``investigate claim'' window would appear (Figure~\ref{claimview}). This window would show the user that the claim ``Global Warming does not exist'' is opposed by the claim ``There is strong evidence for global warming''. If the user navigated to this new claim then they could quickly see the best claims that support the existence of global warming, and would be able to see summaries of the best sources that supported these claims.

%\begin{floatingfigure}{2cm}
%\includegraphics[width=2cm]{../screenshots/marginpull_out.png}
%\end{floatingfigure}

If the current page contains snippets then a tab appears in the top left corner of the window. The tab contains a light bulb icon whose color changes according to the nature of the snippets on the page (Figure~\ref{bookmark_icons}) - red if a snippet contains a contentious claim. This allows a user to quickly tell if a page contains something of interest without having to scroll through the whole page. Clicking on the tab opens the margin. The margin provides a summary of all the interesting claims that users have identified on the current page and is designed to mimic the traditional margin notes that readers often write on physical documents~\cite{marginalia}. To emphasize the connection between a margin note and its associated snippet, each margin note is aligned vertically with its snippet and the snippet is highlighted more strongly when the user mouses over the associated margin note. 

\subsection{The Mental Model}

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=7cm]{../screenshots/bookmark_icons2.png}
	\caption{Icons used for Claims, Snippets, and Topics}
	\label{bookmark_icons}
	\end{center}
\end{figure}

Think Link users interact with three kinds of object, each associated with a different family of icons (Figure~\ref{bookmark_icons}): 	

\begin{itemize}
\item {\bf a claim} (\includegraphics[width=0.3cm]{../images/lightbulb_off.png}) is a factual claim about the world that may be true or false. For example ``Global warming is man made''. A claim may support or oppose other claims. Claims are written as raw English\footnote{though one can imagine supporting other languages in the future} text and Think Link does not try to understand what they mean semantically.
\item {\bf a snippet} (\includegraphics[width=0.3cm]{../images/comment.png}) is a section of text on a web page that asserts or assumes the truth of a particular claim. Many snippets may assert the same claim and users are encouraged to re-use existing claims rather than creating new ones when creating new snippets.
\item {\bf a topic} (\includegraphics[width=0.3cm]{../images/folder_grey.png}) is a thing that claims can be about. For example ``Global Warming'', or ``Computer Science''. A claim can be about one or more topics, and a topic can have one or more more general topics. Topics are used to organize and disambiguate claims. For example ``Bush'' can mean either ``George H W Bush'', ``George W Bush'', ``Vannevar Bush'', ``Kate Bush'', ``The Rock Band Bush'', or just ``A Bush''. Associating a claim with a topic allows one to write shorter claims without worrying about being ambiguous. A topic can itself by disambiguated by having a super-topic.
\end{itemize}


\subsection{Browsing factual claims}
\label{browseclaim}\label{claimbrowser}

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=8cm]{../screenshots/claimbrowse_diagram.png}
	\caption{The claim browser visualizes the claim graph}
	\label{claimbrowse_diagram}
	\end{center}
\end{figure}


Claims and topics form a directed graph structure. A claim can have any number of claims that support or oppose it, and any number of claims that it supports or opposes.
A topic can have any number of more specific topics (e.g. ``US Election 2008'' is more specific than ``US Elections'') and any number of more general topics. A topic can also have any number of claims about that topic.

When designing an interface to this structure, we were faced with two opposing constraints. We needed to be able to clearly view a large number of claims and topics in a small space, and we needed an interface that made it clear that the data was a graph rather than a tree. Dynamically reorganizing graphs such as those used in Vizster~\cite{vizster} and Personal Brain~\cite{thebrain} made the graph structure very clear, but made it difficult to clearly view large numbers of claims in a small place. Tree-based outliners such as OmniOutliner~\cite{omnioutliner} made it easy to view large numbers of related claims, but made it difficult to present an impression of the data being a graph rather than a tree.

After several design iterations, we settled on an interface that is a dynamically reorganizing graph laid out like an outliner. Like other dynamically reorganizing graphs, the interface is arranged around the currently selected node, and when a new node is selected the interface animates to surround the newly selected node with objects to relate to it. Like an outliner, the nodes that relate to the selected node are listed vertically below the selected node, each on their own line, and grouped by category.

The placement of objects above and below is intended to emphasize the conventional hierarchical structuring of an argument graph, with topics going upwards and arguments for and against a claim going downwards. A user can navigate down to get to explore why a claim may or may not be true, or navigate up to find out about more general topics, or claims that the selected claim supports or opposes.

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=6cm]{../screenshots/claimbrowse_zoom.png}
	\caption{Close up of a list of supporting claims}
	\label{claimbrowse_zoom}
	\end{center}
\end{figure}

Animation is used throughout the interface to give users a sense of where they are and how the current interface state related to previous states. When a new item is selected, it grows in size and moves to the center. Other items that were already on the screen move from their current locations to their new locations. Other objects appear and disappear by smoothly sliding into or out of view. 

Users see a claim browser in three different places. The {\it organizer} contains two claim browsers, to help users use drag and drop to create connections (Figure~\ref{fig:claimbrowser}). The {\it popup browser} shows one claim browser in a reduced-size window and is used to quickly investigate a claim found on a web page (Figure~\ref{claimview}). The {\it claim selector} shows a claim browser, together with the text of a new snippet, and is used to identify the claim that a snippet is making (Figure~\ref{snipsavecrop}).


\subsection{Creating new Snippets}
\label{newsnippet}

\begin{figure*}[tb]
	\begin{center}
	\includegraphics[width=16cm]{../screenshots/newsnip_all.png}
	\caption{Process for creating a new snippet}
	\label{createprocess}
	\end{center}
\end{figure*}

%\begin{figure}[tb]
%	\includegraphics[width=8.5cm]{../screenshots/snipsave_full.png}
%	\caption{The claim selection window allows one to identify the claim a snippet is making}
%	\label{snipsavefull}
%\end{figure}

\begin{figure}[tb]
	\includegraphics[width=8.5cm]{../screenshots/snipsave_diagram_full.png}
	\caption{Selecting the claim made by a new snippet}
	\label{snipsavecrop}
\end{figure}

There are several reasons a user may wish to add a snippet to Think Link. They may find the snippet useful and may want to refer to it again in the future; they may disagree with the claim the snippet is making, and want to alert other readers to the fact that there are opposing arguments; they may think the claim argues a point well and want to be able to use it to make an argument, or they may agree with the claim and want to provide easy access to evidence elsewhere that backs it up. 

To create a new snippet, the user selects the text to be included and then either clicks on the ``new snippet'' button on the browser tool bar, or selects the ``new snippet'' option from the context menu that appears when they click the right mouse button (Figure~\ref{createprocess}). This is a similar approach to that taken clipping tools such as Google Notebook.

Once the user has identified the text in a snippet, they need to identify the claim that the snippet is making. To do this, Think Link presents the user with a ``claim selector'' window. This window contains a small version of the claim browser that the user can use to select the claim that the snippet is making. 

Since much of Think Link's utility comes from linking snippets together, it is important to encourage users to reuse existing claims rather than creating new ones, and that when users do create new claims they connect them to existing claims and existing topics. We designed the claim selection window to make it easier to pick out an existing claim than to create a new one. Moreover, one cannot create a new claim without connecting it to an existing topic or an existing claim. To create a new claim, one navigates to a topic that the claim is about, or a claim that the new claim supports or opposes, and then clicks on the (\includegraphics[width=0.3cm]{../images/add.png}) button on the list that one wishes to add the new claim to. For example, if the new claim opposes an existing claim, then one clicks the (\includegraphics[width=0.3cm]{../images/add.png}) button on the ``opposed by'' heading for the existing claim. This is an intentionally different model to that used by ad-hoc tag-based systems such as Del.icio.us and Flickr.com. This is because in bookmarking or image storing systems it is not so important that duplicates be avoided and that objects be well connected. In practice, it is inevitable that duplicates claims and topics will sometimes be created. When this happens, a user can mark them as being identical using the same techniques used to create supporting and opposing connections.


\subsection{Organizing the Claim Graph}

\begin{figure}[tb]
	\begin{center}
	\includegraphics[width=6cm]{../screenshots/claimbrowse.png}
	\caption{The Claim Organizer contains two claim browsers}
	\label{fig:claimbrowser}
	\end{center}
\end{figure}

Like Wikipedia~\cite{wikipedia}, Think Link allows any user to improve the information in the claim graph. The claim graph is shared between all users and editable by anyone. Any user can add new snippets, create new claims, create new topics, or establish new relationships between these objects. One can think of Think Link as being rather like a wiki in which all the content is clipped from existing sources and links are created from those sources back to the wiki.

Think Link uses collaborative filtering~\cite{collective} to highlight the most interesting claims that support and oppose another claim, and the most interesting snippets that make a claim. If a user finds a snippet or claim interesting then they can vote in favor of it by clicking on its icon, causing it to light up (Figure~\ref{bookmark_icons}). When Think Link lists claims or snippets, it will show first those that the user marked as interesting, and order the rest according to the number of other users who marked them as interesting.

It is important to avoid political fights, where two competing sides delete claims, snippets, or connections that they disagree with. Similarly, it is important to avoid vandalism, where people abuse people with competing beliefs by adding abuse claims or snippets. While we do not have a perfect solution to this problem, our current approach is to treat deletion as a special case of collaborative filtering. If a user believes a claim, topic, snippet, or connection is junk then they can request that it be deleted by clicking on the ``delete'' button. This will hide the object for the user who request deletion and reduce the score of the object for other users. If enough people vote to delete the object then its score will eventually be low enough that it is not displayed to users unless they request to see junk objects. 

In a wiki, users edit and delete information produced by others, and history is used to revert abusive changes. Think Link's ``append-only, collaborative filtering'' approach only allows users to add information --- either new objects, or ratings for those objects. The hope is that over time ratings should converge to a steady state and edit wars should be avoided. It would not be practical for a wiki to take this approach as wiki data is human-readable text, rather than a weighted graph; indeed Think Link has to fall back to the ``edit and keep history'' approach to allow users to rename claims.

Think Link uses the familiar drag and drop interface for establishing new connections. To establish a connection between two claims, one need simply drag one claim onto the other. The claim organizer window has two claim browsers, allowing a user to points from one browser onto points on the other (Figure~\ref{fig:claimbrowser}).


\subsection{Why People Annotate}

Tools like Think Link rely on user contributions in order to be useful. If no users are identifying factual claims on pages then other people who browse such pages will not see any claims identified. Similarly, if no other users are connecting claims together, then users will not see any supporting or opposing claims when they click on a highlighted snippet.

Moreover, in order to become popular, a tool like Think Link needs to be useful even when very few people are using it. If a tool is only useful when it has a large community using it then it is unlikely that early adopters will stick with it enough for it to ever acquire a large community.

Our user study participants identified several reasons why they would want to mark up factual claims in documents they found. The most common reason people gave for identifying and organizing factual claims was if the person was writing an article or researching a topic and wanted to keep track of the information they had found. One user (who is an active blogger) also expressed an interest in finding and marking up instances of claims that he disagreed with, so that readers would see the arguments highlighted in red and be directed to the counter-arguments. The same user also expressed an interest in marking up claims in documents he had made in his own articles so that readers could quickly see the evidence he had found in support of his claims.


\subsection{Implementation}

Think Link is implemented as three largely independent components:

\begin{itemize}
\item {\bf A server}, written using Ruby, PHP, and MySQL that maintains the claim graph and provides an API that allows this data to be queried and modified
\item {\bf A web UI}, written using Javascript that implements the claim browser
\item {\bf A page enhancement script}, written in Javascript, that augments the page it is run on by highlighting the factual claims made on the page. This script displays the web UI in an iframe to pick or investigate a claim.
\item {\bf A Firefox extension}\cite{firefoxextend}, that inserts the page enhancement script into all pages the user browses to, and provides tool bar and context-menu shortcuts.
\end{itemize}

These components are largely independent. One could use the page enhancement script on a web page without using the Firefox extension, by either manually including it on the page (e.g. to enhance your own blog) or by adding it using a proxy. Since the server API is public, one could write alternative tools that mark up web pages in different ways, or use the claim graph for different purposes. 

The source code to Think Link is publicly available under the Apache license. 


\section{User Studies}

We performed two qualitative ``think aloud'' user studies to guide the development of Think Link. 

The aim of the first study was to see how users normally browse the web and how they might go about using Think Link to identify snippets in the pages they browse. The aim of the second study was to evaluate changes made to the interface as a result of the first study and see how people react to browsing pages that have interesting claims highlighted.

\subsection{Procedure for the First Study}

For the first study we recruited 12 paid participants. Five were female, seven were male. Their ages ranged from high school age to retired. Our intention was to recruit users who were not experts, but who regularly used the Internet to find information. We recruited participants using a posting to the Craigslist.org classified advert site. In our advert, we expressed an interest in people who use the Internet to gather knowledge, rather than just for tasks such as email or shopping. We filtered participants based on their short answers to questions about how they found, organized, and shared information on the web. 

Study sessions took approximately 45 minutes. Participants were seated at a single-screen workstation with the Firefox browser augmented with the Think Link plugin. We first demonstrated Think Link's interface, and then asked them to browse normally and use Think Link to identify snippets that made claims they found interesting and connect those claims to the existing claim graph. For the first half of the study, we asked them to constrain their browsing to political news articles, to increase the likelihood that there would be existing claims about the topic they were browsing.

In this initial study, users were exposed to the prototype interface shown in Figures~\ref{oldsnippetbox} and \ref{oldbrowser}, rather than the final interface described earlier in this paper. We discuss some of the key differences in the findings section.

\subsection{Procedure for the Second Study}

For the second study, we recruited 6 paid participants. Four were female and two were male. Although we recruited participants using the same advert as the first study, the timing of our second advert around the beginning of the college semester meant that five of the participants were students. Since the second group was different demographically to the first group, it was not possible to make a direct comparison between their behaviors. 

In the second study we were more confident about the usability of our tool and so we decided to tell them nothing about how to use it. We gave each user a brief introduction to the aims of the tool, similar to the introduction of this paper, and then asked them to perform two tasks with it. The first task was to look at a selection of web pages that already had highlighted snippets and explore the interface while thinking aloud about what they saw. The second task was to identify claims on a set of pages we gave them about global warming and connect them appropriately to existing claims that we had pre-populated the claim graph with. Participants were shown an interface that is largely identical to that described earlier in this paper. 

\subsection{Findings}

In this section we present the findings from our two user studies. Findings from the two studies are presented together and clustered by topic.

\subsubsection{High-Level Impressions}

Response was generally positive, with many participants being very keen to use the tool soon. One participant said ``I can see myself getting addicted to this'', and several participants asked as to notify them when it is properly deployed. Most of the participants expressed an interest in using the tool, with some wanting to use it now, and others wanting to use it ``when it is more mature''.

Participants liked the ability to see when other pages disagreed with the claim they were looking at. One participant said ``The web needs to be taken with a grain of salt, and this gives you salt goggles''.

\subsubsection{Usability}

Several usability problems were identified with the first version of the tool, causing us to make design changes for the second version. None of these problems re-occurred during the second study. We discuss some of these changes in the sections below.

Most participants in the first study, and all participants in the second study were able to use the tool competently. Participants in the second study were able to use Think Link competently without it being demonstrated in advance and were able to correctly deduce what the different parts of the interface meant. Participants said they found the tool ``very intuitive''.


\subsubsection{Creating a Snippet}

Users would often encounter a snippet that could be interpreted as making several interesting claims, and were unsure about what to do in such circumstances. Some users would deal with this by writing a compound claim like ``Global Warming will cause X and Y'' while other users would create several snippets for the same text, making different claims. Users seemed to find this confusing, suggesting that we may want support in the snippet creation interface for picking several claims that a snippet is making.

One special case of this problem was that several users wanted to mark up a table as a snippet. A table can usually be considered to be making several interesting claims and users were often confused about what they should say the table claimed. Our current guidance is that one should mark up a table as making the most interesting claims that that table makes --- those that support or oppose claims made elsewhere. In other cases, a user wanted to mark up an image as a snippet. While Think Link does not currently support this, it might make sense to allow this if an interesting claim can be inferred from the image.

Some users expressed an interest in marking up a snippet as a primary source rather than a claim. For example they might find the text of an important speech or an Olympic results table. Several expressed a desire to have a new class of object that was neither a topic nor a claim, but instead just ``interesting information relevant to this topic''.

Many users would consistently mark the first paragraph of an article as a snippet. This paragraph would frequently summarize the arguments made in the rest of the document document and often made an important claim that other claims in the document supported or provided context for. 


\subsubsection{Choosing a Claim for a Snippet}

\begin{figure}[t]
	\includegraphics[width=8.5cm]{../screenshots/oldsnipcreate_diagram.png}
	\caption{Initial Prototype Snippet Creation Dialog}
	\label{oldsnippetbox}
\end{figure}

In the initial interface we used a simplified snippet creation window (Figure~\ref{oldsnippetbox}) that was intended to make the process of snippet creation very lightweight. This window contained two text boxes. The first of these boxes was for the topic (e.g. ``Global Warming'') and the second of the boxes was for the claim (e.g. ``Global Warming is Man Made''). Both of these boxes used an auto-complete drop-down list to suggest appropriate existing topics or snippets as the user typed, 
biasing towards topics that were recent or hot. The auto-complete list would show either when the user started typing, or when the user clicked the drop down button. Selecting a claim would auto-populate the topic. Selecting a topic would constrain the claims that were suggested to be within that topic.

We found that participants using this initial interface felt disorientated by the fact that the interface for creating snippets was different to the interface used for visualizing them. Participants would often confuse claims and topics, either entering a claim in the topic box, or a topic in the claim box. Participants would also frequently create new points and topics when appropriate points and topics already existed in the claim graph, even when the suggestion list was drawing their attention to a topic or claim that would have been appropriate.

For the second study, we used the snippet creation interface described earlier in this paper, which uses the same claim browser interface used for exploring the claim graph. We found that users of this interface had no difficulty distinguishing between claims and topics and were more likely to reuse existing claims and topics. We theorized that part of the reason for increased reuse was that, because users could see the claim graph they were creating, they felt more motivation to keep it ``tidy'' by reusing existing claims.

Several users expressed confusion about how specific the claim made by a snippet should be, or when they should pick an existing claim rather than create a new one. For example, if a snippet says ``Global temperatures will rise by X degrees by 2050'' then is that making the claim ``Global temperatures will rise'', or should a new claim be created that contains the extra information? 

Several users also expressed an interest in being able to use the text of the snippet they selected as the text of its claim, particularly for short snippets. We intentionally made this a little difficult to do in an attempt to encourage users to find existing claims that are appropriate, however this may have been a mistake as it also increases the amount of effort required to create a snippet.

\subsubsection{Connecting Claims}

Many participants expressed a desire to organize claims into connected arguments during their session. 

Some users incorrectly marked one claim as supporting another when in fact they should have both been marked as supporting a third claim that needed to be created. For example ``Global warming is causing more hurricanes'' does not support ``Global warming is causing rising sea levels'', but both support ``Global warming is causing environmental problems''. Users realized that the claims were related, but did not immediately recognize that they needed to create new claims in order to structure the relationship correctly. It is possible that creating correct logical claim structures may just be too difficult for some people, or it may be that users would get used to the idea with more practice. We hope that if Think Link was deployed more widely many of the intermediate claims that were needed would already have been created and this problem would thus be reduced.

Some users were confused by claims that had a ``because'' relationship rather than a ``supports'' or ``opposes'' relationship. For example ``America did not sign the Kyoto Protocol'' {\it because} ``Signing Kyoto would harm the US economy''. Similarly, many users expressed a desire to mark claims as being ``related'' without supporting or opposing each other. For example ``America did not sign the Kyoto Protocol'' {\it is related to} ``America was right to not sign the Kyoto Protocol''. Our current advice in such circumstances is to use topics to group claims that are related. For example these claims could all be in a topic called ``America and the Kyoto Protocol''. Participants seemed comfortable with the idea of relating claims in this way when we pointed it out to them, but most participants needed to be told that this was a strategy they could use.

Several users got confused by claims that referred to similar events at different points in time. For example, one participant in the first study marked a two claims as opposing each other when each was true at the time that it was written. This is a particular problem when talking about breaking news events, where what claims are true can change fast. If Think Link is to be effective for describing such events then it is likely that it will need to have better support for identifying the time at which a claim was asserted to be true.

Several users expressed an interest in being able to mark a claim as controversial without having to create an opposing claim. One user said that opposing a claim required ``too many clicks'' and they wanted to be able to just vote against a claim without having to say why or find evidence. In the future we are planning to implement a social voting system to allow users to say what claims they believe are false and see what claims their friends agreed or disagreed with.

\begin{figure}[tb]
	\includegraphics[width=8.5cm]{../screenshots/oldpoint_diagram.png}
	\caption{Initial Prototype Claim Browser}
	\label{oldbrowser}
\end{figure}

\section{Limitations and Future Work}

There are a number of issues that a widely released tool would need to address. Firstly, our current implementation has privacy issues. Every time one navigates to a web page, the plugin contacts our server and gives it the current URL so that the server can check if there are snippets on that page. These requests are anonymous, cacheable, and not logged, but it is still likely that some people would object to this information being given to an external server. 

At present, all claims have to be marked up by users who must not only identify the correct section of text to highlight, but also use a browsing interface to find the interesting claim that is being made. It would be interesting to see if natural language processing techniques could be used to either simplify the process of marking snippets, or even to detect snippets that make known claims without human intervention.

Think Link is designed to be used as a social tool in which large numbers of people collaborate to find large numbers of claims and snippets about interesting topics. Since our graph and user base are currently small, we have not yet evaluated how Think Link works when data sets are huge, many users are concurrently editing data, and some users are malicious.

We think it could be useful to use Think Link as a tool to suggest reading material. Just as tools like Digg suggest pages that you might like, Think Link could potentially suggest pages that contain claims that the user had not read and would be likely to find interesting.


\section{Conclusions}

We have introduced the concept of browsing the web of factual claims using Think Link. Think Link allows users to navigate between pages based on the factual claims made on pages, rather than being restricted to the links provided by authors. It allows users to identify contentious claims on web pages and connect them directly to the arguments that those claims are part of, and related claims on other web sites.

On a practical level, Think Link works by allowing users to pick out snippets on pages that make claims that they think are interesting or controversial, and then using an ``append only, collaborative filtering'' model to allow users to collaborate together to structure claims into an argument graph.

We hope that Think Link will make it easier for people to be informed about the world and be exposed to factual claims that they might not otherwise be exposed to.

\section{Acknowledgments}

We would like to think Allison Woodruff, Tye Rattenbury, and all our user study participants for all their help during the design of Think Link. Think Link uses icons from the free FamFamFam Silk~\cite{silkicons} collection.



\bibliography{refs}

\end{document}



