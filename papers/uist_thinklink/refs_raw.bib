@article{Bulc2002,
author = {Bulc, Renato and Izeki, Claudia Akemi},
journal = {Engineering},
pages = {66--73},
title = {An Open Linking Service Supporting the Authoring of Web Documents},
year = {2002}
}
@article{Lansdale2003,
author = {Lansdale, Janet},
journal = {Human Factors},
keywords = {dance analysis,hypertextuality,intertextuality},
pages = {108--119},
title = {Decentering the Dancing Text: From Dance Intertext to Hypertext},
year = {2003}
}
@article{Iorio2005,
author = {Iorio, Angelo Di and Vitali, Fabio},
journal = {Design},
keywords = {collaboration,customization,global editability,web authoring},
pages = {35--45},
title = {From the Writable Web to Global Editability},
year = {2005}
}
@article{Olof2002,
author = {Olof, Niels and Polle, Bouvin and Zellweger, T and Grønbæk, Kaj and Mackinlay, Jock D},
journal = {Human Factors},
keywords = {annotations,annotea,fluid documents,hypermedia,rdf,web augmentation with open,xlink,xpointer},
pages = {160--171},
title = {Fluid Annotations Through Open Hypermedia: Using and Extending Emerging Web Standards},
year = {2002}
}
@article{Keywords2004,
author = {Keywords, A C M Classification},
journal = {Architecture},
keywords = {acm classification keywords,annotation,blogging,digital community poster boards,discussion,threaded},
pages = {1207--1210},
title = {Digital Graffiti: Public Annotation of Multimedia Content},
year = {2004}
}
@article{Bush1945,
author = {Bush, Vannevar},
journal = {The Atlantic Monthly},
title = {As We May Think},
year = {1945}
}
@article{Yee2002,
author = {Yee, Ka-ping},
journal = {CSCW Demo},
keywords = {annotation,argumentation,bi-directional linking,critical discussion,extrinsic links,hypertext,ne-grained links,public annotation,thinklink,typed links,world-wide web},
note = {Attach annotations to any location on any public page and view the annotations on any page.
 Say the key new feature of CritLink is that it runs as a proxy.
 Cites a load of useful stuff:ComMentor, CoNote,GrAnT, HyperNews,..
 Add comment annotations to a page.
},
title = {CritLink: Advanced Hyperlinks Enable Public Annotation on the Web},
year = {2002}
}
@article{Links,
author = {Links, T H E Search F O R Associative},
journal = {Computing},
keywords = {associative linking,internet archive,link taxonomies},
pages = {76--77},
title = {Looking for Linking: Associative Links on the Web}
}
@inproceedings{Bouvin1999,
author = {Bouvin, Niels Olof},
booktitle = {Hypertext},
keywords = {collaboration on the web,common reference architecture for,faces,media protocol,open hyper-,open hyperme-,open hypermedia,open hypermedia systems,thinklink,unifying inter-,web integration},
note = {Open Hypermedia systems addressed the problem of "augmenting third-party applications".
 Hypermedia augmentation *is* open hypermedia.
 "A tool shall be considered a web hypermedia augmentation tool if it, though integration with a web browser, a HTTP proxy, or a web server, adds content or controls not contained within the web pages themselves to th eeffect of allowing structure to be added to the web page directly or indirectly, or to navigate such structure".
 
 Divides tools into four grups:* Annotation/Discussion support* Link creation and transversal* Guided tours* Structuring/Spatial
 Bush envisioned marginalia in the Memex.NCSA mosiac allowed users to add annotations to pages.
 CritLink Mediator, part of CritSuite[10] allows people to add supports/issue/comment/query links to web pages.
 

},
title = {Unifying Strategies for Web Augmentation},
year = {1999}
}
@article{Karousos2003,
author = {Karousos, Nikos and Reich, Siegfried},
journal = {Computer Engineering},
keywords = {hypermedia services,open hypermedia systems,web services},
pages = {482--489},
title = {Offering Open Hypermedia Services to the WWW: A Step-by-Step Approach for Developers},
year = {2003}
}
@unpublished{Bouvin2000,
author = {Bouvin, Niels Olof},
booktitle = {Phd Thesis},
institution = {University of Aarhus},
note = {
},
title = {Augmenting the Web through Open Hypermedia},
year = {2000}
}
@article{Gordon2007,
author = {Gordon, Thomas F and Prakken, Henry and Walton, Douglas},
journal = {Artifical Intelligence},
keywords = {argument evaluation,argument graphs,argument structure,argumentation,burden of proof,legal argument,preprint submitted to elsevier,proof standards,schemes},
title = {The Carneades Model of Argument and Burden of Proof},
volume = {171},
year = {2007}
}
@inproceedings{Korb1997,
author = {Korb, Kevin B and Mcconachy, Richard and Zukerman, Ingrid},
booktitle = {Proceedings of the Nineteenth Annual Conference of the Cognitive Science Society},
title = {A Cognitive Model of Argumentation},
year = {1997}
}
@article{Olston2003,
author = {Olston, Christopher},
journal = {ACM Transactions on Computer-Human Interaction},
pages = {1--21},
title = {ScentTrails: Integrating Browsing and Searching on the Web},
volume = {10},
year = {2003}
}
@article{Nonneeke2000,
author = {Nonneeke, Blair and Preeee, Jenny},
keywords = {bbs,demographic,discussion list,email,health-support,lurker,lurking,membership,newsgroup,traffic},
pages = {73--80},
title = {Lurker demographics: Counting the silent},
volume = {2},
year = {2000}
}
@article{Hair2000,
author = {Hair, Mario},
title = {Think Before You Link: Controlling Ubiquitous Availability},
year = {2000}
}
@article{Kennedy2007,
author = {Kennedy, Lyndon and Naaman, Mor and Ahern, Shane and Nair, Rahul and Rattenbury, Tye},
keywords = {geo-referenced photographs,photo collections},
pages = {631--640},
title = {How Flickr Helps us Make Sense of the World: Context and Content in Community-Contributed Media Collections},
year = {2007}
}
@article{Noll2007,
author = {Noll, Michael G and Meinel, Christoph},
journal = {Human Factors},
keywords = {authoring,del,dmoz,dmoz100k06,document engi-,google,icio,icra,metadata,neering,pagerank,social bookmark-,us},
pages = {177--186},
title = {Authors vs. Readers - A Comparative Study of Document Metadata and Content in the WWW},
year = {2007}
}
@article{Conklin1987,
author = {Conklin, Jeff},
journal = {Computer},
title = {Hypertext: An Introduction and Survey},
year = {1987}
}
@article{Olston2001,
author = {Olston, Chris and Chi, E D H},
journal = {World Wide Web Internet And Web Information Systems},
title = {ScentTrails: Integrating Browsing and Searching on the Web},
year = {2001}
}
@article{Stewart2008,
author = {Stewart, Robin and Scott, Gregory and Zelevinsky, Vladimir},
journal = {CHI},
keywords = {1500-,3000,are looking for,as in a search,but what if we,for example,for flat-screen televi-,historical events that are,interesting in,may want to find,or metadata,sions that cost,something more abstract or,subjective,we},
pages = {1789--1792},
title = {Idea Navigation: Structured Browsing for Unstructured Text},
year = {2008}
}
@article{Etzioni2008,
author = {Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S},
journal = {Communications of the ACM},
title = {Open information Extraction from the Web},
volume = {51},
year = {2008}
}
@inproceedings{Bier2006,
author = {Bier, Eric A and Ishak, Edward W and Chi, Ed},
booktitle = {Proceedings of the International Conference on Intelligence and Security Informatics},
title = {Entity Workspace: an evidence file that aids memory, inference, and reading},
year = {2006}
}
@article{Frenkel1968,
author = {Frenkel, Karen A},
pages = {1467255--1467255},
title = {a Difficult, unforgettable idea},
year = {1968}
}
@article{Engelbart1995,
author = {Engelbart, Douglast C},
journal = {Communications of the ACM},
keywords = {argumentation,hypertext,thinklink},
note = {
},
title = {Towards Augmenting the Human Intellect and Boosting our Collective IQ},
year = {1995}
}
@article{Ricardo2001,
author = {Ricardo, Francisco J and Hall, Longfellow and Way, Appian},
journal = {Cultures},
keywords = {amounts of information generated,business practices,business world as a,from,having originated in the,hypertext,method for unifying the,vast},
note = {Very brief survey. Doesn't say all that much.
},
pages = {217--226},
title = {Hypertext and Knowledge Management},
year = {2001}
}
@inproceedings{Sen2006,
author = {Sen, Shilad and Lam, Shyong K Tony and Rashid, Al Mamunur and Cosley, Dan and Frankowski, Dan and Osterhouse, Jeremy and Harper, F Maxwell and Riedl, John},
booktitle = {CSCW},
keywords = {communities,evolution,social book-,tagging,vocabulary},
note = {Look at how tags used within a community evolve due to community influence and personal tendency.
 Explore tag selection algorithms that suggest tags that a user should use.
 Importance of having a free vocabulary.
 Users invent personally meaningful tags.Social navigation may be more powerful in communities that share a common vocabulary.
 Some tags, e.g. "I own this" are not useful socially.People use different names for the same thing.
},
pages = {181--190},
title = {tagging, communities, vocabulary, evolution},
year = {2006}
}
@inproceedings{Takahashi2003,
author = {Takahashi, Masamichi and Fujimoto, Masakazu and Yamasaki, Nobuhiro},
booktitle = {GROUP},
keywords = {classification,discussion list,evaluation,influence,lurker,lurking,mailing list,management,online community,social capital,thinklink,value},
note = {People who lurk but don't post are important due to their influence on the external community.
},
pages = {1--10},
title = {The Active Lurker: Influence of an In-house Online Community on its Outside Environment},
year = {2003}
}
@article{Heymann2007,
author = {Heymann, Paul and Ramage, Daniel and Garcia-molina, Hector},
journal = {In Practice},
keywords = {tagging},
note = {Trying to predict tags on delicious.
},
pages = {531--538},
title = {Social Tag Prediction},
year = {2007}
}
@article{Bogers2008,
author = {Bogers, Toine},
journal = {Most},
keywords = {about,added ref-,also applied to,any user,as well as information,associated with a chosen,browse other users who,from,reference,references,so that users can,tag,the author level,the popularity of a,these in turn enable,this same linking is,users to view all},
pages = {287--290},
title = {Recommending Scienti c Articles Using CiteULike},
year = {2008}
}
@article{Garg2008,
author = {Garg, Nikhil and Weber, Ingmar},
journal = {Work},
keywords = {ickr,tag co-occurrence,tag recommendation,tagging systems},
pages = {67--74},
title = {Personalized, Interactive Tag Recommendation for Flickr},
year = {2008}
}
@inproceedings{Muller2008,
author = {Muller, Michael J and Millen, David R},
booktitle = {CHI},
keywords = {tagging,thinklink},
note = {People tag for different reasons.
 Roles:* Community Seeker - find members of existing communities* Community Builder - create community* Evangelist - draw attention to certain information* Publisher - want people to find their information* Team-Leader - signalling to group members
 - think link -
 Markers are "evangelists". Readers are passive community-seekers.
 May also have "publishers" wanting to bring people to their information.
},
pages = {1041--1044},
title = {Social Tagging Roles: Publishers, Evangelists, Leaders},
year = {2008}
}
@inproceedings{Mishne2006,
author = {Mishne, Gilad},
booktitle = {WWW},
keywords = {tagging,thinklink},
note = {[just a 4 page paper]
 Suggests tags for weblog posts using collaborative filtering methods. 
 
 
 

},
pages = {953--954},
title = {AutoTag: A Collaborative Approach to Automated Tag Assignment for Weblog Posts},
year = {2006}
}
@article{Marlow2006,
author = {Marlow, Cameron and Naaman, Mor and Boyd, Danah and Davis, Marc},
journal = {HT},
keywords = {-based systems have existed,and other collection management,for many years,however,in web browsers,increased in,introduced,photo,popularity as elements of,repository applications,social interaction have been,systems,tagging,these tools have recently,thinklink},
note = {Offers a taxonomy of existing tagging systems. Good survey paper to cite.
 

},
pages = {31--39},
title = {HT06, Tagging Paper, Taxonomy, Flickr, Academic Article, To Read},
year = {2006}
}
@article{Ames2007,
author = {Ames, Morgan},
journal = {Communication},
pages = {971--980},
title = {Why We Tag: Motivations for Annotation in Mobile and Online Media},
year = {2007}
}
@article{Brooks2006,
author = {Brooks, Christopher H and Montanez, Nancy},
journal = {Distribution},
keywords = {automated annotation,blogs,hierarchical clustering,tagging},
pages = {625--631},
title = {Improved Annotation of the Blogosphere via Autotagging and Hierarchical Clustering},
year = {2006}
}
@article{Ye2008,
author = {Ye, Chen and Keywords, Author and Keywords, A C M Classification},
journal = {New York},
pages = {1097--1100},
title = {What Drives Content Tagging: The Case of Photos on Flickr},
year = {2008}
}
@article{Sánchez2007,
author = {Sánchez, J Alfredo and Arzamendi-pétriz, Adriana and Valdiviezo, Omar},
journal = {In Practice},
keywords = {collaboration,knowledge discovery,recommendation,tagging},
pages = {396--397},
title = {Induced Tagging: Promoting Resource Discovery and Recommendation in Digital Libraries},
year = {2007}
}
@article{Strohmaier2008,
author = {Strohmaier, Markus},
journal = {Search},
keywords = {social bookmarking,social search,tagging,user intent},
pages = {35--42},
title = {Purpose Tagging: Capturing User Intent to Assist Goal-Oriented Social Search},
year = {2008}
}
@article{Vainikainen2008,
author = {Vainikainen, Sari},
journal = {Methods},
keywords = {bookmarking,design,experimentation,human factors,metadata,ontologies,semantic web,tagging,tags,user study,web application},
pages = {167--171},
title = {Experiences of Semantic Tagging with Tilkut},
year = {2008}
}
@article{Subramanya2008,
author = {Subramanya, Shankara B and Liu, Huan},
journal = {Human Factors},
keywords = {blogs,collaborative tagging,context,in the traditional information,judgment and cultural background,play an important role,retrieval,subjective},
pages = {19--26},
title = {SocialTagger - Collaborative Tagging for Blogs in the Long Tail},
year = {2008}
}
@article{Chi2008,
author = {Chi, Ed H and Mytkowicz, Todd},
journal = {New York},
keywords = {3,a task best left,dif-,for a group of,for an object is,furnas links social tagging,relatively easy for a,set of keywords is,single user,to the vocabulary problem,users,while generating a large},
pages = {81--88},
title = {Understanding the Ef ciency of Social Tagging Systems using Information Theory},
year = {2008}
}
@article{Golder2006,
author = {Golder, Scott A and Huberman, Bernardo A},
journal = {Journal of Information Science},
keywords = {bookmarks,collaborative tagging,del,folksonomy,icio,tagging,thinklink,us,web},
note = {Talks about the structure of collaborative tagging systems.
},
title = {The Structure of Collaborative Tagging Systems},
year = {2006}
}
@book{Jackson2002,
author = {Jackson, H J},
publisher = {Yale University Press},
title = {Marginalia: Readers Writing in Books},
year = {2002}
}
@inproceedings{Schilit2008,
author = {Schilit, Bill N and Kolak, Okan},
booktitle = {Joint Conference on Digital Libraries},
keywords = {data min-,digital libraries,great ideas,humanities research,hypertext,ing,key phrases,quotations,thinklink},
note = {
},
title = {Exploring a Digital Library through Key Ideas},
year = {2008}
}
@inproceedings{Kolak2008,
author = {Kolak, Okan and Schilit, Bill N},
booktitle = {Hypertext},
keywords = {automatic hypertext,digital li-,link generation,quotations,thinklink},
note = {
},
title = {Generating Links by Mining Quotations},
year = {2008}
}
@inproceedings{Korb1997a,
author = {Korb, Kevin B and Mcconachy, Richard and Zukerman, Ingrid},
booktitle = {Annual Conference of the Cognitive Science Society},
keywords = {thinklink},
note = {
},
title = {A Cognitive Model of Argumentation},
year = {1997}
}
@inproceedings{Adler2007,
author = {Adler, B Thomas and Alfaro, Luca},
booktitle = {WWW},
keywords = {1 the,as well as one,content,creation,is the wikipedia,of the oldest,one of the most,reputation,successful examples of collaborative,user-generated content,wikipedia},
title = {A Content-Driven Reputation System for the Wikipedia},
year = {2007}
}
@inproceedings{Adler2008,
author = {Adler, B Thomas and Pye, Ian},
booktitle = {WikiSym},
title = {Measuring Author Contributions to the Wikipedia ∗},
year = {2008}
}
@inproceedings{Chatterjee2008,
author = {Chatterjee, Krishnendu and Alfaro, Luca De and Pye, Ian},
booktitle = {AISec},
keywords = {reputation,user-generated content,wikipedia},
title = {Robust Content-Driven Reputation ∗},
year = {2008}
}
@inproceedings{Adler2008a,
author = {Adler, B Thomas and Chatterjee, Krishnendu and Alfaro, Luca and Faella, Marco and Pye, Ian and Raman, Vishwanath},
booktitle = {WikiSym},
keywords = {thinklink,trust},
note = {
},
title = {Assigning Trust to Wikipedia Content},
year = {2008}
}
@article{Shum2007,
author = {Shum, Simon Buckingham and Uren, Victoria and Li, Gangmin and Mancini, Clara and Shum, Buckingham and Design, Interaction},
journal = {International Journal of Intelligent Systems},
pages = {17--47},
title = {Modelling Naturalistic Argumentation in Research Literatures: Representation and Interaction Design Issues},
year = {2007}
}
@article{Maiden2007,
author = {Maiden, Editor Neil and Shum, Simon Buckingham},
journal = {Ieee Software},
pages = {2007--2009},
title = {There’s Nothing Like a Good Argument ...},
year = {2007}
}
@article{Diego2008,
author = {Diego, San and Software, Social and Technologies, Teaching and Netherlands, The and Helou, El and Modeling, Social Software},
journal = {International Journal of Web-Based Learning and Teaching Technologies},
title = {Last Updated Thursday, 23 October 2008 2008 2008},
year = {2008}
}
@article{Seigenthaler2005,
author = {Seigenthaler, John},
journal = {USA Today},
title = {A False Wikipedia Biography},
volume = {November},
year = {2005}
}
@article{McGinnis2007,
author = {McGinnis, Jarred and Modgil, Sanjay and Rahwan, Iyad and Simari, Guillermo and South, Matthew and Vreeswijk, Gerard and Willmott, Steven},
journal = {The Knowledge Engineering Review},
keywords = {argumentation,thinklink},
note = {
},
title = {Towards an Argument Interchange Format},
year = {2007}
}
@article{Willmott2005,
author = {Willmott, Steven and Vreeswijk, Gerard and South, Matthew},
journal = {x-opennet.org},
pages = {1--17},
title = {AIF: Argumentation Interchange Format Strawman Model},
year = {2005}
}
@article{Atkinson2007,
author = {Atkinson, Katie and Bench-Capon, Trevor and McBurney, Peter},
journal = {Artificial Intelligence and Law},
keywords = {argumentation,deliberative democracy,practical reasoning},
month = {April},
pages = {261--275},
title = {Parmenides: facilitating deliberation in democracies},
volume = {14},
year = {2007}
}
@inproceedings{Selvin2001,
author = {Selvin, Albert and Shum, Simon Buckingham and Sierhuis, Maarten and Conklin, Jeff and Zimmermann, Beatrix and Palus, Charles and Drath, Wilfred and Horth, David},
booktitle = {Knowledge Technologies},
keywords = {argumentation,thinklink},
note = {
},
title = {Compendium: Making Meetings into Knowledge Events},
year = {2001}
}
@article{Jatzav2004,
author = {Jatzav, Joel and Reed, Chris},
journal = {Aurgumentation},
title = {On Argumentation Schemes and the Natural Classification of Arguments},
volume = {18},
year = {2004}
}
@article{Gelder2007,
author = {Gelder, Tim},
journal = {Oxford Journal of Law, Probability and Risk},
title = {The Rationale for Rationale™},
year = {2007}
}
@inproceedings{Shum2006,
author = {Shum, Simon Buckingham},
booktitle = {Pragmatic Web},
institution = {Knowledge Media Institute},
keywords = {argumentation,thinklink},
note = {Pitching Simon's work to the Pragmatic Web audience, arguing that there are shared goals.
 Talks about Compendium, and ClaiMaker.
 

},
title = {Sensemaking on the Pragmatic Web: A Hypermedia Discourse Perspective},
year = {2006}
}
@inbook{Shum2007a,
author = {Shum, Simon Buckingham},
booktitle = {Conceptual Structures: Knowledge Architectures for Smart Applications},
keywords = {argumentation,thinklink},
note = {An overview of things Simon Buckingham Shum has been working on.
 Compendium is a direct descendent of Conklin's gIBIS.Compendium and Cohere also lay out arguments from left to right - say ThinkLink is inspired by this.
 Then talks about ClaiMaker and ClaimSpotter.
 ClaiMapper - authoringClaimFinder - findingClaimSpotter - semantic annotation
 Less mature, proof of concept vehicles.
 

},
title = {Hypermedia Discourse: Contesting Networks of Ideas and Arguments},
year = {2007}
}
@inproceedings{Sereno2007,
author = {Sereno, Bertrand and Shum, Simon Buckingham and Motta, Enrico},
booktitle = {WWW},
keywords = {annotation,are,argumentation,discourse relations,local,national and international,our communities,pragmatic web,semantics,sensemaking,social tagging,thinklink,usability},
note = {About ClaimSpotter.
 Annotating academic papers.
 Has similar intentions to Think Link.
 
 --
 Add structure to freeform folksonomies.
 Provide enough support to initiate the interaction without overwhelming the user with suggestions.
 System-initiated tag suggestions.
 Can tag documents with triples expressing logically what is being said.
 
 Complex statements such as: "Domain ontology" is-about "A hierchary of URIs on multilple levels"

},
title = {Formalization, User Strategy and Interaction Design: Users’ Behaviour with Discourse Tagging Semantics},
year = {2007}
}
@article{Benn1908,
author = {Benn, Neil and Shum, Simon Buckingham and Domingue, John and Mancini, Clara},
journal = {Knowledge Creation Diffusion Utilization},
keywords = {macro-argument analysis,ontologies,scholarly debate mapping},
title = {Ontological Foundations for Scholarly Debate Mapping Technology},
volume = {44},
year = {1908}
}
@inproceedings{Shum2008,
author = {Shum, Simon Buckingham},
booktitle = {Computational Models of Argument (COMMA)},
keywords = {0,1,argument visualization,argumentation,argumentation tools,collective sensemaking tools,global scale which will,in which we find,introduction,organizational,ourselves,present problems on a,require negotiation and collaboration,scientific and political contexts,the need for distributed,the societal,thinklink,usability,web 2},
note = {Probably the tool most similar to think link.  Ideas can include references we web resources. But assumption is that users are using web resource as evidence for argument, rather than wanting to highlight contentious stuff.
 All ideas other than one's own have their owner clearly indicated iconically. (Think Link should do this).
 Cohere has a firefox plugin that allows one to easily mark snippets and can show you ideas that other people have attached to a web site.   However it does not distinguish between contested and non-contested ideas.
 Usage model is different. Not trying to gather two sides and join them together. About using web as evidence.
  --    A tool for "social bookmarking, idea-linking, and argument visualization".   Says: "Students, researchers, and professional analysts lack effective tools to make personal and collective sense of problems while working in distributed teams".   "The intended users of such tools include members of the public engagedin a public consultations and societal debate [8], students or educators in a learning context [9], lawyers [10], and analysts in many other walks of professional life such as public policy [11] and scholarly publishing [12]"   -- cohere itself --   Start with relaxed constraints, but allow users to incrementally add structure.   Drop-down menu encourages people to reuse an existing idea rather than creating a new one  - we found a drop-down menu isn't enough. You need to let people explore to see what it is.   Can assign websites to ideas.  - but direction is opposite to think link.  - using web site as evidence, rather than as thing to highlight to draw people in. Ideas can play roles such as Question, Answer, Pro, Con.Use can define new ones - e.g. Datum, Claim, Warrant for Toulmin.
 Connection types have either positive, negative, or neutral polarity.Defaults include proves, is-consistent-with, challenges, refutes.
 Users are free to create their own connection language. Also entirely up to users to determine what positive and negative mean (e.g. could be inhibit in biology).
 Web feeds allow one to track changes to ones' own items (like Think Link). Ideas have their own URls - same in Think Link. - mention simple API.    -- related work --  "First, there are desktopapplications like Compendium [30] and Rationale [16] with high quality user interfaces refined through the feedback from their extensive user communities: however, these are limited to publishing read-only maps to the Web, either as JPEG images, or as interactive image maps."  Compendium and Rationale are limited to read-only on the web.   "CoPe_it! [18] is designed forcommunity deliberation, and provides a way to synchronise views between IBIS graphs (it also integrates with Compendium in this respect), an IBIS outline tree, and a conventional threaded discussion forum. CoPe_it! also provides a mechanism to evaluate the strength of a position, and so represents another interesting development. Its interaction design is at present rather rudimentary compared to Web 2.0 interfaces."  Parmenides enforces aparticular argument ontology (it was not designed as a social web application) and does not appear to support any other Web 2.0 characteristics.   ClaiMaker and ClaimSpotter were precursors to Cohere.  TruthMapping goes much further than this, aiming specifically at tackling some ofthe limitations of threaded discussion forums, with a clear distinction between unsupported premises, which when supported become claims, and a way to post rebuttals and responses to each of these [22]. DebateMapper uses a combined graphical and outline structure to map debates using the IBIS scheme, with contributions tagged as issues, positions and arguments [23]. The provision of mechanisms to enable flexible linking of web resources aroundwhat we are calling Ideas is a goal shared by the Topic Maps community [26], -- topic maps --
 Topics point to one or more resources (web sites) and can be linked by associations.-- me --   Think Link takes a less involved approach. You aren't trying to explore an issue you know is interesting - you want to find out when things you didn't know are contentious actually are.  Think Link is not a collaborative argumentation tool in a strict sense. The aim is to assemble the information you would want to see, rather than impose a rigid structure. Structure is only there to show you what info you might want to look at.   Focus is in finding things, rather than organizing them.    -- cites --   Compendium[30]. Rationale[16], Cope_it[18], DebatePedia[17]. Parmenides[19]. TruthMapping - url DebateMapper - url   AIF argument interchange format.   -- asside --
 could one implement think Link on top of Cohere. Maybe, but it isn't really designed for that.
 

},
title = {Cohere: Towards Web 2.0 Argumentation},
volume = {44},
year = {2008}
}
@unpublished{Horn2007,
author = {Horn, Robert E and Weber, Robert},
institution = {Strategy Kinetics},
keywords = {argumentation,thinklink},
note = {Mess Mapping and Resolution Mapping Processes.  Two techniques:
 Mess Map: diagram argument from multiple points of view - connected together.
 Resolution Mapping Process - start with desired end-state and see how one could plausibly get there.    --    Detailed graphical analyses of wicked problems.   Resolution Scenario Mapping - looking at possible outcomes.   Solutions to wicked problems are not true or false but good or bad. Simple logical reasoning doesn't work.   Resolution, not solution - no correct answer.   -- mess map --   About representing problems as graphical arrangements of work, images, and shapes. Yellow sector contains description of the problem from one point of view - which may have different rules, customs, culture, etc. Each has its own icon to represent that sector/point of view.   Links between sectors when they correct to each oter.   -- resolution map --   Write down possible end states and how they come about from now. Describing the present with hindsight.   Print events on cards, each with an action who can influence the outcome doing something.   Thus trace plausible routes to possible outcomes.   Same cards can be reused in different scenarios.   Work backwards from desired end-state to see how one could plausibly get there.   Red slash through cards describing event that "must not" happen.   -- quotes --   "There is always an easy solution to every human problem—neat,plausible and wrong." H. L. Mencken  "Plans are only good intentions unless they immediately degenerate into hard work." Peter Drucker  "You can't step in the same Mess twice." Robert P. Weber 
},
title = {New Tools For Resolving Wicked Problems},
year = {2007}
}
@book{Toulmin1958,
author = {Toulmin, Stephen E},
keywords = {argumentation,thinklink},
note = {
},
publisher = {Cambridge University Press},
title = {The Uses of Argument},
year = {1958}
}
@inbook{Shum2006a,
author = {Shum, Simon J Buckingham and Selvin, Albert M and Sierhuis, Maarten and Conklin, Jeffrey and Haley, Charles B and Nuseibeh, Bashar and Mistrik, Ivan},
booktitle = {Rationale Management in Software Engineering},
editor = {Dutoit, Allen H and Mccall, Raymond and Mistrik, Ivan and Paech, Barbara},
institution = {Knowledge},
keywords = {argumentation,thinklink},
note = {
},
publisher = {Springer-Verlag},
title = {Hypermedia Support for Argumentation-Based Rationale},
year = {2006}
}
@unpublished{Horn2001,
author = {Horn, Robert E},
title = {Knowledge Mapping for Complex Social Messes},
year = {2001}
}
@inbook{Conklin2006,
author = {Conklin, Jeff},
booktitle = {Dialogue Mapping: Building Shared Understanding of Wicked Problems},
chapter = {1},
publisher = {Wiley},
title = {Wicked Problems and Social Complexity},
year = {2006}
}
@article{Rittel1973,
author = {Rittel, Horst W J and Webber, Melvin M},
journal = {Policy Sciences},
keywords = {argumentation,thinklink},
note = {Introduces the idea of "wicked" problems.
 A "wicked" problem is a problem whose solution requires large groups of individuals to change their mindsets.
 E.g. global climate change, US healthcare, etc
},
title = {Dilemmas in a General Theory of Planning*},
volume = {4},
year = {1973}
}
@inproceedings{Verheij1999,
author = {Verheij, Bart},
booktitle = {ICAIL},
keywords = {argumentation,thinklink},
note = {Interesting argument structure that takes into account legal arguments.Includes reasons, conclusions, exceptions, etc.
 Some features in common with Toulmin graph.
 --
 Presents the ArguMed argument assistance system.
 Distinguish from automated reasoning - help reasoning rather than do reasoning.
 Graphically shows how an argument has been attacked, as well as showing the argument itself.
 Shows dialectical arguments - ones in which attacks and counterattacks are incorporated.
 Designed to be used by a lawyer to structure the argument e will make in court. - not a collaborative tool
 
 -- structure --
 statement - a statement of fact   X is truereason - a reason why a statement is true   X is true becasue Y is trueconclusions   X is true, therefore Y is true.exceptions  (defeasable logic)   X is true, except when Y is true.
 warrant   Rules that can generate reasons.   All men are mortal + I am a man -m:linebreak/m:linebreak/m:linebreak/m:linebreak//m:note},
title = {Automated Argument Assistance for Lawyers},
year = {1999}
}
@inproceedings{Gordon1997,
author = {Gordon, Thomas F and Karacapilidis, Nikos},
booktitle = {ICAIL},
keywords = {argumentation,thinklink},
note = {--   IBIS tool. GeoMed/GMD Geographical Mediation project.   Creating a mediation tool for the web for reviewing development plans.   Mediation system = computer-based discussion forum with particular support for argumentation.   A "marked message" is a message that has been marked with an argumentation structure.  Node types: Issues, Position.Links:   position pro/con position   position preference for issue   issue is-an-issue-with position   Slightly different graph structure to gIBIS. Can label the alternatives for an issue, as distinguishes choices from preferences.
 Produces a formal, algebraic model of the argumentation system. Tries to be far too logical given the messy nature of real arguments.
 
 

},
title = {The Zeno Argumentation Framework},
year = {1997}
}
@misc{Ghosh2008,
author = {Ghosh, Pallab},
booktitle = {BBC News},
publisher = {BBC News},
title = {Warning Sounded Over Web's Future},
year = {2008}
}
@misc{Shirky2008,
address = {New York, NY, USA},
author = {Shirky, Clay},
booktitle = {Web 2.0 Expo},
publisher = {O'Reilly},
title = {It's not Information Overload. It's Filter Failure},
year = {2008}
}
@unpublished{Gentzkow2007,
author = {Gentzkow, Matthew and Shapiro, Jesse M},
institution = {Nation Bureau of Economic Research},
title = {What Drives Media Slant? Evidence from U.S. Daily Newspapers},
year = {2007}
}
@article{Wattenberg,
author = {Wattenberg, Martin and Kriss, Jesse and Ham, Frank Van and Lab, Visual Communication},
journal = {Compare A Journal Of Comparative Education},
title = {Talk Before You Type: Coordination in Wikipedia}
}
@article{Lab,
author = {Lab, Visual Communication},
journal = {Microscope},
title = {The Visual Side of Wikipedia}
}
@article{Wattenberga,
author = {Wattenberg, Martin and Hollenbach, Katherine},
journal = {Methods},
keywords = {peer production,visualization,wikipedia},
title = {Visualizing Activity on Wikipedia with Chromograms}
}
@article{Wattenbergb,
author = {Wattenberg, Martin and Mckeon, Matthew M},
keywords = {commons,governance,peer production,wikipedia},
title = {The Hidden Order of Wikipedia}
}
@article{Suh2007,
author = {Suh, Bongwon and Chi, Ed H and Pendleton, Bryan A and Kittur, Aniket},
journal = {Physical Review E},
pages = {163--170},
title = {Us vs. Them: Understanding Social Dynamics in Wikipedia with Revert Graph Visualizations},
year = {2007}
}
@inproceedings{Chi2005,
author = {Chi, Ed H and Suh, Bongwon and Kittur, Aniket},
booktitle = {Proceedings of the Social Data Analysis Workshop at CHI},
keywords = {thinklink,trust},
note = {
},
title = {Providing Social Transparency through Visualizations in Wikipedia},
year = {2005}
}
@article{Weld2008,
author = {Weld, Daniel S and Wu, Fei and Adar, Eytan and Amershi, Saleema and Fogarty, James and Hoffmann, Raphael and Patel, Kayur and Skinner, Michael},
journal = {Intelligence},
title = {Intelligence in Wikipedia},
year = {2008}
}
@article{Evans2008,
author = {Evans, James A},
journal = {Science},
title = {Electronic Publishing and the Narrowing of Science and Scholarship},
volume = {395},
year = {2008}
}
@book{Herman2002,
author = {Herman, Edward S and Chomsky, Noam},
note = {Talks about how market pressurse cause news media to say what corporations want.
},
publisher = {Pantheon},
title = {Manufacturing Consent: The Political Economy of the Mass Media},
year = {2002}
}
@inproceedings{Park2008,
author = {Park, Souneil and Kang, Seungwoo and Lee, Sangjeong and Chung, Sangyoung and Song, Junehwa},
booktitle = {Web Science},
pages = {47--51},
title = {Mitigating Media Bias: A Computational Approach},
year = {2008}
}
@article{Approach1994,
author = {Approach, An},
journal = {Media},
pages = {3--12},
title = {Galaxy of News},
year = {1994}
}
@article{Wallach2006,
author = {Wallach, Hanna M and Laboratory, Cavendish},
journal = {Machine Learning},
title = {Topic Modeling: Beyond Bag-of-Words},
year = {2006}
}
@inproceedings{Park2009,
author = {Park, Souneil and Kang, Seungwoo and Chung, Sangyoung and Song, Junehwa},
booktitle = {CHI},
keywords = {thinklink},
note = {Automatically creates multiple classified viewponts on a news event of interest.
 11,12 - references for bias in mass media.
},
publisher = {Information Today},
title = {NewsCube: Delivering Multiple Aspects of News to Mitigate Media Bias},
year = {2009}
}
@article{Gamon,
author = {Gamon, Michael and Basu, Sumit and Belenko, Dmitriy and Fisher, Danyel and Hurst, Matthew},
journal = {Distribution},
keywords = {blogosphere,emotion detection,news articles,polarity and emotion detection,visualization},
title = {BLEWS: Using Blogs to Provide Context for News Articles}
}
@article{Blei2003,
author = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
journal = {Journal of Machine Learning Research},
pages = {993--1022},
title = {Latent Dirichlet Allocation},
volume = {3},
year = {2003}
}
@article{Allan,
author = {Allan, James and Carbonell, Jaime and Doddington, George and Yamron, Jonathan and Yang, Yiming and Systems, Dragon},
journal = {Wall Street Journal},
title = {Topic Detection and Tracking Pilot Study Final Report}
}
@inproceedings{Zhou2004,
author = {Zhou, Lina and Zhang, Dongsong},
booktitle = {Proceedings of the International Conference on Web Intelligence},
publisher = {Information Today},
title = {Building a Misinformation Ontology},
year = {2004}
}
@article{Resnik1998,
author = {Resnik, David B},
journal = {Computers and Society},
keywords = {bias on the web,thinklink},
note = {Talks about widespread misinformation about medical problems on the web.
},
publisher = {Information Today},
title = {Medical Misinformation on the Web:},
year = {1998}
}
@article{Neumann2003,
author = {Neumann, Peter G},
journal = {Communications of the ACM},
note = {Misinformation is a problem on the web.
      widely held beliefs in supposedly valid informa-tion tend to take on lives of their own as urbanmyths; they tend to be trusted far beyond what isreasonable, even in the presence of well-baseddemonstrations of their invalidity.

},
publisher = {Information Today},
title = {E-Epistemology and Misinformation},
volume = {46},
year = {2003}
}
@misc{,
booktitle = {World Wide Web Internet And Web Information Systems},
note = {Just a talk abstract.
},
pages = {59593--59593},
publisher = {Information Today},
title = {WWW at 15 Years: Looking Forward}
}
@article{Weitzner2008,
author = {Weitzner, Daniel J and Abelson, Harold and Berners-Lee, Tim and Feigenbaum, Joan and Hendler, James and Sussman, Gerald Jay},
journal = {Communications of the ACM},
note = {About privacy, not misinformation.
},
publisher = {Information Today},
title = {Information Accountability},
volume = {51},
year = {2008}
}
@book{Mintz2002,
author = {Mintz, Anne P},
publisher = {Information Today},
title = {Web of Deception},
year = {2002}
}
@article{Marshall2001,
author = {Marshall, Jonathan and Laraki, Othman and Osipovich, Alex and Varma, Chris and Fang, Nicholas and Paul, Jyoti and Rangnekar, Akshay and Shon, John and Swani, Preeti and Treinen, Marissa and Lab, Persuasive Technology and Hall, Cordura},
keywords = {although some private,companies have created proprietary,exist,given the importance of,it is remarkable that,knowledge about,so few quantitative studies,web credibility},
pages = {61--68},
title = {What Makes Web Sites Credible? A Report on a Large Quantitative Study},
year = {2001}
}
@article{Artz2007,
author = {Artz, Donovan and Gil, Yolanda},
journal = {Journal Of Web Semantics},
keywords = {policies,reputation,trust,web of trust},
title = {A Survey of Trust in Computer Science and the Semantic Web},
year = {2007}
}
@article{Kriplean2008,
author = {Kriplean, Travis and Beschastnikh, Ivan and McDonald, David W},
journal = {CSCW},
title = {Articulations of WikiWork: Uncovering Valued Work in Wikipedia through Barnstars},
year = {2008}
}
@article{Rahwan2007,
author = {Rahwan, Iyad and Mcburney, Peter},
chapter = {5},
institution = {MIT Sloan School of Management},
journal = {IEEE Intelligent Systems},
keywords = {argumentation},
note = {Intro to special issue on argumentation.
 Not really looking at relating argumentation to the web.
 -- Argumentation History --
 Aristotle wrote about Argumentation in 350 BCE.
 

},
pages = {0--2},
title = {Argumentation Technology},
year = {2007}
}
@inproceedings{Chi2005a,
author = {Chi, Ed H and Hong, Lichan and Gumbrecht, Michelle and Card, Stuart K},
booktitle = {IUI},
keywords = {annotation,automatically highlighting relevant text,by user entering search,first,keywords on-the-fly,reader,s attention by,thinklink,topical interests are obtained,we highlight sentences by,we propose to direct},
note = {Helps user skim a document.
 Automatically highlight text related to keywords the reader is interested in.
 User enters search keywords on the fly.
},
title = {ScentHighlights: Highlighting Conceptually-Related Sentences during Reading},
year = {2005}
}
@article{Teevan2004,
author = {Teevan, Jaime and Alvarado, Christine and Ackerman, Mark S and Karger, David R},
keywords = {contextual knowledge as a,even when they knew,guide,information target using keywords,instead of jumping directly,local steps using their,navigated to their target,our participants,search,to their,with small},
pages = {415--422},
title = {The Perfect Search Engine Is Not Enough: A Study of Orienteering Behavior in Directed Search},
volume = {6},
year = {2004}
}
@inproceedings{Bier2006a,
author = {Bier, Eric A and Ishak, Edward W and Chi, Ed},
booktitle = {CHI},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {acm classification keywords,copy-and-paste,copying text,entity extraction,information extraction,sensemaking,text editing},
note = {Detects entities on web pages such as names, addresses, dates.
 Quickly gather entities by just clicking on them.
 
 Copy and paste is too slow, so instead detect entity boundaries and grab them with a simple click.

},
pages = {562--567},
title = {Entity Quick Click: Rapid Text Copying Based on Automatic Entity Extraction},
year = {2006}
}
@article{Morris2007,
author = {Morris, Meredith Ringel},
journal = {Human Factors},
keywords = {collaborative search,computer-supported cooperative work,per-,sistent search,web search interfaces},
pages = {3--12},
title = {SearchTogether: An Interface for Collaborative Web Search},
year = {2007}
}
@inproceedings{Gotz2007,
author = {Gotz, David},
booktitle = {WWW},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {annotation,argumentation,sensemaking,thinklink,visual analytics,web browser},
note = {[poster] 
 A browser extension to capture, organize, and exploit information found on the web.
 Calculates relevance of previously captured information to what you are currently browsing.
 -- 
 Record either full page or drag-and-drop portion.
 Objects can be linked to express relationships.
 Relevance algorithm uses these links to show relevant things.
 
 
  -- sensemaking --   Complex research behaviours in which users gather and comprehend information from many sources to answer potentially vague, non-procedural questions.
},
title = {The ScratchPad: Sensemaking Support for the Web},
year = {2007}
}
@inproceedings{Billman2007,
author = {Billman, Dorrit and Bier, Eric A},
booktitle = {CHI},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {annotation,argumentation,sensemaking},
note = {Eric Bier's stuff on Entity Workspace at PARC.
 Applied to medical tasks.
 Supports reading with automatic highlighting of important terms. Supports notetaking with an electronic notebook.
 
 Evidence Panel: take notes about entitiesEntity Inspector: displays info about an entitySuggestion: recomends related entitiesDocument trails: history of documents and searches
 
 Uses "one click entity selection" to find entities on pages.
 Highlights terms that the user has already placed in their notebook.

},
pages = {229--232},
title = {Medical Sensemaking with Entity Workspace},
year = {2007}
}
@article{Bhavnani2008,
author = {Bhavnani, Suresh K and Arbor, Ann and Clarkson, Gavin and Studies, Native American and Arbor, Ann and Scholl, Matthew and Arbor, Ann},
journal = {Search},
pages = {2799--2804},
title = {Collaborative Search and Sensemaking of Patents},
year = {2008}
}
@article{Qu2005,
author = {Qu, Yan and Furnas, George W and Arbor, Ann},
journal = {Representations},
keywords = {information seeking,representations,sensemaking},
pages = {1989--1992},
title = {Sources of Structure in Sensemaking},
year = {2005}
}
@article{Cheng2009,
author = {Cheng, Wen-huang},
pages = {107--116},
title = {Context-Based Page Unit Recommendation for Web-Based Sensemaking Tasks},
year = {2009}
}
@unpublished{Klein2008,
author = {Klein, Mark and Iandoli, Luca},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {argumentation},
note = {Like the other paper.
 Tested on 220 grad students who were asked to debate biofuels in italy.
 180 users contributed points. 3000 issues, ideas, and arguments posted. and 200 comments.
},
title = {Supporting Collaborative Deliberation Using a Large-Scale Argumentation System: The MIT Collaboratorium},
year = {2008}
}
@article{Malone2007,
author = {Malone, Thomas W},
chapter = {5},
institution = {IMT Sloan School of Management},
journal = {MIT Technology Review},
keywords = {arg},
note = {About collabatorium.
 Focused on Global Warming.
 Very high-level overview.
},
pages = {1--18},
title = {Group Thinking for Global Warming},
year = {2007}
}
@article{Park2008a,
author = {Park, Jack and Park, Menlo},
keywords = {argumentation,calo,docassist,machine learning,social computing,topic map},
note = {Talks about the CALO project (intelligent assistant).
 About a social bookmarking system.
 Users tag pages thought to be related to projects in CALO.
 Amanuensis  = Personal Assistant
 
 

},
pages = {140--153},
title = {Toward a Topic Maps Amanuensis},
year = {2008}
}
@inbook{Park2007,
author = {Park, Jack},
booktitle = {Leveraging the Semantics of Topic Maps},
keywords = {tagging},
note = {
},
pages = {200--214},
title = {Tagomizer: Subject Maps Meet Social Bookmarking},
year = {2007}
}
@article{Bothos2008,
author = {Bothos, Efthimios and Apostolou, Dimitris and Mentzas, Gregoris},
journal = {Most},
title = {Idea Selection and Information Aggregation Markets},
year = {2008}
}
@article{Bothos2008a,
author = {Bothos, Efthimios and Apostolou, Dimitris and Mentzas, Gregoris},
journal = {2008 Third International Conference on Internet and Web Applications and Services},
month = {June},
pages = {289--296},
publisher = {Ieee},
title = {A collaborative information aggregation system for idea management},
year = {2008}
}
@article{,
journal = {Society},
pages = {6--6},
title = {Idea management? Ask the crowd!}
}
@unpublished{Klein2007,
author = {Klein, Mark},
chapter = {5},
institution = {IMT Sloan School of Management},
keywords = {argumentation},
note = {
 Integrates a number of known techniques:
 IBIS + articles + voting.
 Uses the IBIS formalism.
 -- 
 Effective deliberation requires that:*   All important issues are considered•  The broadest possible range of high-quality solution ideas are identified•  The strongest arguments for and against each idea are captured•  People can distinguish good from bad arguments•  Individual select solutions rationally, i.e. they consider all the important issues and ideas, and•  make selections that are consistent with the arguments they most trust*  The aggregate results fairly represent the “wisdom of the people”
 
 Break into sharing, funnelling, and argumentation.
 problems with just sharing: noise, unsystematic coverage, balkanization, dysfunctional argumentation, hidden consensus
 Funnelling: voting, prediction markets, etc. Combining opinions.
 Uses IBIS: because it is simple to use and has been applied successfully in hundreds of collective decision-making contexts.
 Includes articles in the argument map.  Disagree by writing a new article, rather than editing someone else's.?:   Debate continues by updating your own articles, rather than posting endless replies.
 
 -- IBIS --
 Nodes: Issues, Ideas, Pros, Cons.TL: Topic, Claim, links that are pro and con.  Topic can be a question.
 Has voting, version histories, search etc.
},
title = {The MIT Collabatorium: Enabling Effective Large-Scale Deliberation for Complex Problems},
year = {2007}
}
@article{Karacapilidis2007,
author = {Karacapilidis, Nikos and Tzagarakis, Manolis},
journal = {Communities},
keywords = {collaborative knowledge building and,formalization,incremental,learning,learning communities and distributed,problem solving,services for technology enhanced,sharing,support,teams},
pages = {127--142},
title = {Supporting Incremental Formalization in Collaborative Learning Environments},
year = {2007}
}
@inproceedings{Karacapilidis2006,
author = {Karacapilidis, Nikos},
booktitle = {Invitational Workshop on Modelling Meetings, Argumentation, and Discourse},
keywords = {argumentation,thinklink},
note = {Web based tool.
 Supports communities of practice. (CoP).
 Mark idea as supporting or opposing another in a tree.
},
title = {CoPe it!: Towards augmenting collaboration and learning in Communities of Practice},
year = {2006}
}
@article{Tzagarakis,
author = {Tzagarakis, Manolis and Karousos, Nikos and Gkotsis, Giorgos and Kallistros, Vasilis and Mettouris, Christos and Kyriakou, Panagiotis and Nousia, Dora},
keywords = {thinklink},
note = {
},
title = {From ‘Collecting’ to ‘Deciding’: Facilitating the Emergence of Decisions in Argumentative Collaboration}
}
@article{Tzagarakis2008,
author = {Tzagarakis, Manolis and Karousos, Nikos and Karacapilidis, Nikos},
chapter = {5},
journal = {International Journal of Web-Based Learning and Teaching Technologies},
keywords = {action research,argumentation,awareness,collaborative work systems,thinklink,visualization,web-based},
note = {About CoPe_it!.
 Awareness = understanding of the activities of others.
 Presents a list of awareness mechanisms:
 * Informal: who is around and what are they doing* Presence: User availability and willingness to collaborate* Task: Aim of a task and how it fits in a bigger picture* Social: degree of attention and interest of a member* Group-structure: roles, responsibilities etc* Historical* Workspace
 

},
title = {Awareness Mechanisms for Web-based Argumentative Collaboration},
volume = {3},
year = {2008}
}
@unpublished{Shum,
author = {Shum, Simon Buckingham},
booktitle = {http://events.kmi.open.ac.uk/essence/tools/},
keywords = {argumentation,semantic web,sensemaking,thinklink},
note = {CompendiumDebateGraphCohereMIT DelibertoriumArgumentationsCope ITDebatewiseTruthmapping
 http://globalsensemaking.wik.is/About_GSm/Existing_Sm_Tools/Cohere
 -- Argumentations --
 Site to develop argument maps. People build simple argument trees.No papers. No research. 
 -- Argumentative --
 Windows app for building argument maps.
 -- Cohere --
 Simon Buckingham Shum et al.Annotate a URL with ideas. Make connections between ideas.Links such as responds-to.Links to related URLS, but isn't about identifying repeated bad ideas.Has a firefox plugin.Uses various visualizations.
 Use websites to back up ideas, rather than connection going the other way.
 Plugin:  v1: just let you quickly mark up ideas you found on a page v2: also shows you ideas that others have marked
 Gets much closer to our work.Key difference: we focus on the pages. About showing you when stuff you read in contentious.
 http://technologies.kmi.open.ac.uk/cohere/2008/08/29/updates-to-cohere-browser-plugin/
 Toolbar shows a list of ideas marked on the page. But: this will include ideas that aren't contentious. Not done by highlighting. Different usage model.
 -- Compendium --
 Argument graphing tool. From Simon Buckingham Shum, Jeff Conklin, et al.
 -- CoPe it! --
 Another shared argument graph tool.
 -- DebateGraph --
 Web based argument visualization + collaborative wiki editing.
 Uses a nice argument visualization.The argument is shown as a single tree that can be expanded downwards.Further graph on the righ shows multiple parents for it.-- Debatewise --
 Debatewise is a not-for-profit debating wiki with ambitions to become the Wikipedia of debate.Anyone can start a debate on any subject they like and anyone can edit and strengthen that debate.    
 Simple site listing pro and con arguments for topics.
 -- The Deliberatorium/Collaboratorium --
 From MIT.Uses Argument Mapping to reduce "scattering" and "the soapbox problem". Break into refute, update, etc.
 -- IDeM --
 Idea Market.Information aggregation market environment.Little info available.
 -- Open Qabal --
 Blog engine and comment/collaboration system.
 -- Rationale --
 Visual framework to consider the pros and cons of an issue. Desktop app rather than web based. Fancy windows app.
 -- TopicSpaces --
 Java based subject map platform. Little info available.
 -- TruthMapping --
 Use nice revision system to update your rebuttals and keep things tidy. Add "critiques" to things, and update in light of stuff other people say. Pretty cool. Similar to delibatorium IIRC.
 -- Wordsmyth --
 Semantic relation thesaurus.
 -- Zotero --
 Reference organizer.
 

},
title = {ESSENCE: eScience/Sensemaking/Climate Change}
}
@article{Bradshaw2007,
author = {Bradshaw, Shannon and Light, Marc},
journal = {Development},
keywords = {annotation,annotation consensus,knowledge management,passage recommendation},
pages = {209--216},
title = {Annotation Consensus: Implications for Passage Recommendation in Scienti c Literature},
year = {2007}
}
@article{Args,
author = {Args, The},
journal = {IEEE Intelligent Systems},
title = {Argumentation in the Semantic Web}
}
@article{Rahwan2007a,
author = {Rahwan, Iyad and Zablith, Fouad and Reed, Chris},
journal = {Artificial Intelligence},
keywords = {argument interchange format,argument schemes,argumentation,e-democracy,semantic web,thinklink,tools},
note = {Describes ArgDF, an extension of AIF - an XML/RDF encoding of arguments.
},
title = {Laying the foundations for a World Wide Argument Web},
volume = {171},
year = {2007}
}
@article{Rahwan2008,
author = {Rahwan, I},
journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
keywords = {0,1,a crash course,a verbal and social,activity,argumentation,argumentation can be de,argumentation theory,increasing,ned as,of reason aimed at,or decreasing,semantic web,the acceptabil-,web 2},
month = {February},
pages = {29--37},
title = {Mass argumentation and the semantic web},
volume = {6},
year = {2008}
}
@article{Rahwan2007b,
author = {Rahwan, Iyad and Zablith, Fouad and Reed, Chris},
journal = {Argument},
title = {Towards Large Scale Argumentation Support on the Semantic Web},
year = {2007}
}
@article{Ghaoui2007,
author = {Ghaoui, Laurent El and Colloquium, Information Systems},
journal = {Information Systems},
title = {Statistical Analysis of Online News},
year = {2007}
}
@article{Heer,
author = {Heer, Jeffrey and Agrawala, Maneesh},
journal = {Cognitive Science},
title = {Design Considerations for Collaborative Visual Analytics}
}
@article{Rheingold2008,
author = {Rheingold, Howard},
journal = {Series on Digital Media and Learning},
pages = {97--118},
title = {Using Participatory Media and Public Voice to Encourage Civic Engagement},
year = {2008}
}
@article{Furuta,
author = {Furuta, Richard and Stotts, P David},
chapter = {5},
journal = {TOIS},
pages = {1--19},
title = {Trellis: a Formally defined Hypertextual Basis for Integrating Task and Information}
}
@inproceedings{Stotts,
author = {Stotts, P David and Furuta, Richard},
booktitle = {Advances in Petri Nets},
chapter = {5},
keywords = {hypertext},
note = {Hypertext that suggests recommended browsing routes through the graph.
 -- 
 Traditional hypertext resembles a directed graph.Their model uses Petri nets. Models a browsers browsing semantics.
 Describes the petri-net based TRELLIS model.
 One problem with hypertext is disorientation.
 One problem is that hypertext author cannot formally express the order in which hypertext should be browsed.  (Web does this with layout - TRELLIS shows graph separately to document)
 "Browsing Semantics" means a specification of the order in which nodes should be visited.
 -- petri net --
 Net consists of places, transitions, and arcs.
 Transition is an event.
 Arcs go between places and events, never between places or between transitions.
 Execution is non-deterministic.
},
title = {aTrellis: A System for Writing and Browsing Petri-Net-Based Hypertext}
}
@article{Dice,
author = {Dice, Dave and Microsystems, Sun and Shavit, Nir and Research, Sun Microsystems},
title = {Understanding Tradeoffs in Software Transactional Memory}
}
@article{Dicea,
author = {Dice, Dave and Shalev, Ori and Shavit, Nir},
journal = {Network},
title = {Transactional Locking II}
}
@article{Ennals2006,
author = {Ennals, Robert},
title = {Software Transactional Memory Should Not Be Obstruction-Free},
year = {2006}
}
@article{Liu,
author = {Liu, Hugo and Singh, Push},
journal = {Structure},
title = {Commonsense Reasoning in and over Natural Language}
}
@article{Chklovski2003,
author = {Chklovski, Timothy},
journal = {Database},
title = {Learner: A System for Acquiring Commonsense Knowledge by Analogy},
year = {2003}
}
@article{Liu2004,
author = {Liu, H and Singh, P},
journal = {BT Technology Journal},
pages = {211--226},
title = {ConceptNet — a practical commonsense reasoning tool-kit},
volume = {22},
year = {2004}
}
@article{Lieberman2004,
author = {Lieberman, Henry and Liu, Hugo and Singh, Push and Barry, Barbara},
journal = {AI Magazine},
pages = {63--76},
title = {Beating Common Sense into Interactive Applications},
year = {2004}
}
@article{Chklovski2005,
author = {Chklovski, Timothy},
chapter = {5},
journal = {AAAI},
note = {Same as "Collecting paraphrase Corpora from Volunteer Contributor"
 ESP game to collect paraphrases for NLP training.
},
title = {1001 Paraphrases:},
volume = {2},
year = {2005}
}
@inproceedings{Chklovski2005a,
author = {Chklovski, Timothy},
booktitle = {K-CAP},
chapter = {5},
keywords = {acquisition,interfaces for knowledge elicitation,volunteer contributor-based knowledge},
title = {Collecting Paraphrase Corpora from Volunteer Contributors},
year = {2005}
}
@article{Chklovski2005b,
author = {Chklovski, Timothy and Gil, Yolanda},
journal = {Cognitive Science},
title = {An Analysis of Knowledge Collected from Volunteer Contributors},
year = {2005}
}
@article{Seattle2005,
author = {Seattle, Intel Research},
journal = {OMICS: A Journal of Integrative Biology},
title = {Sensor-Based Understanding of Daily Life via Large-Scale Use of Common Sense},
year = {2005}
}
@article{Speer2007,
author = {Speer, Robert and Group, Commonsense Computing},
journal = {Knowledge Creation Diffusion Utilization},
keywords = {analogy,commonsense,feedback,inference,knowledge acquisition},
title = {Open Mind Commons: An Inquisitive Approach to Learning Common Sense},
year = {2007}
}
@article{Science2003,
author = {Science, Computer and Winston, Patrick H and Science, Computer and Supervisor, Thesis and Smith, Arthur C},
journal = {Knowledge Creation Diffusion Utilization},
title = {Using Analogy To Acquire Commonsense Knowledge from Human Contributors},
year = {2003}
}
@inproceedings{Selvin2001a,
author = {Selvin, Albert and Shum, Simon Buckingham and Sierhuis, Maarten and Conklin, Jeff and Zimmermann, Beatrix and Palus, Charles and Drath, Wilfred and Horth, David and Domingue, John and Motta, Enrico and Li, Gangmin},
booktitle = {Knowledge Technologies},
keywords = {argumentation},
note = {Visualizations for organizing knowledge.
 Convert a document into a visual map of hypertext nodes.
 Create maps collaboratively in meetings.
 Uses "question-oriented templates" to organize knowledge for a particular domain.
 Move between formal and informal forms.
 Combination of an IBIS (Issue Based Information System) concept mapping tool with a structured modelling tol.
},
title = {Compendium: Making Meetings into Knowledge Events},
year = {2001}
}
@article{,
journal = {Annals of Internal Medicine},
pages = {59593--59593},
title = {Highly Structured Scientific Publications},
year = {2007}
}
@article{Ipeirotis2006,
author = {Ipeirotis, Panagiotis G and Agichtein, Eugene and Jain, Pranay and Gravano, Luis},
journal = {Plant Physiology},
pages = {265--276},
title = {To Search or to Crawl? Towards a Query Optimizer for Text-Centric Tasks},
year = {2006}
}
@inproceedings{Wu2006,
author = {Wu, Xian and Zhang, Lei and Yu, Yong},
booktitle = {WWW},
keywords = {annotation,emergent semantics,semantic web,social,social annotation,wrappers},
note = {Semantic web.
 Social annotation of the web with semantic web meaning.
 Users tag things very loosely and a probabalistic model is used to infer something more formal.
 

},
pages = {417--426},
title = {Exploring Social Annotations for the Semantic Web},
year = {2006}
}
@inproceedings{Dalvi2004,
author = {Dalvi, Nilesh and Domingos, Pedro and Sanghai, Sumit and Verma, Deepak},
booktitle = {KDD},
keywords = {cost-sensitive learning,game theory,integer linear programming,naive bayes,spam de-,tection},
note = {When building a classifier (e.g. spam checker or intrusion detector) mean in mind that the attacker will try to defeat it.
 

},
pages = {99--108},
title = {Adversarial Classification},
year = {2004}
}
@article{Gruhl,
author = {Gruhl, D and Guha, R and Liben-nowell, David and Tomkins, A},
journal = {SIGKDD Explorations},
pages = {43--52},
title = {Information Diffusion Through Blogspace},
volume = {6}
}
@article{Chklovski2005c,
author = {Chklovski, Timothy and Gil, Yolanda},
journal = {Knowledge Acquisition},
keywords = {broad-,collecting knowledge,coverage knowledge repositories,intelligent user,interfaces,interfaces for knowledge elicitation,knowledge acquisition},
pages = {35--42},
title = {Improving the Design of Intelligent Acquisition Interfaces for Collecting World Knowledge from Web Contributors},
year = {2005}
}
@article{Baumeister2007,
author = {Baumeister, Joachim and Reutelshoefer, Jochen and Puppe, Frank},
journal = {Knowledge Creation Diffusion Utilization},
pages = {189--190},
title = {KnowWE – Community-based Knowledge Capture with Knowledge Wikis},
year = {2007}
}
@article{Liu2006,
author = {Liu, Jinze and Zhang, Qi and Wang, Wei and Mcmillan, Leonard and Prins, Jan},
journal = {Distribution},
keywords = {clustering,dissimilarity,pocluster,poset},
pages = {637--642},
title = {Partially Ordered Sets},
year = {2006}
}
@inproceedings{Chklovski2005d,
author = {Chklovski, Timothy},
booktitle = {K-CAP},
keywords = {acquisition,interfaces for knowledge elicitation,paraphrases,thinklink,volunteer contributor-based knowledge},
note = {Get volunteers to contribute paraphrases.
 Ask users to guess partially obfuscated paraphrases.
 Built as an online game.
 Used it to collect 20,944 paraphrases of 400 statements.Visited by 1,300 people.
 
 Most previous systems offered recognition or prizes to those who provided the most content.
 People will game the system if you make that possible.
 Create gaps in a paraphrase and ask people to guess what the right word is. Initially only need one right word, but soon you have many more...
 Aim is to guess the "correct" answer, but by getting it wrong they also give us many others.
 

},
title = {Collecting Paraphrase Corpora from Volunteer Contributors},
year = {2005}
}
@article{Chklovski2005e,
author = {Chklovski, Timothy},
journal = {Building},
keywords = {broad-coverage knowledge repositories,collecting,generalization in knowl-,interfaces for knowledge elicitation},
pages = {311--313},
title = {Designing Interfaces for Guided Collection of Knowledge about Everyday Objects from Volunteers},
year = {2005}
}
@article{Minsky2000,
author = {Minsky, Marvin},
journal = {Communications of the ACM},
keywords = {knowledge gathering},
note = {Important to understand something several different ways. - when one way fails you can look at it the other way.
 Important to give computers a base level of knowledge.
},
title = {Commonsense-Based Interfaces},
volume = {43},
year = {2000}
}
@article{Leake2003,
author = {Leake, David B and Maguitman, Ana and Reichherzer, Thomas and Carvalho, Marco and Arguedas, Marco and Eskridge, Tom},
journal = {Human Factors},
keywords = {case-based reasoning,concept mapping,context,edge acquisition tools,knowl-,knowledge engineering and modeling,knowledge management environments,methodologies,re-},
pages = {44--53},
title = {Aiding Knowledge Capture by Searching for Extensions of Knowledge Models},
year = {2003}
}
@inproceedings{David1992,
author = {David, Douglass R and Karger, David R and Pedersen, Jan O and Tukey, John W},
booktitle = {SIGIR},
note = {About document clustering. Not clear it is particularly useful for me.
},
title = {Scatter/Gather: A Cluster-based approach to Browsing Large Document Collections},
year = {1992}
}
@article{Stumpf2007,
author = {Stumpf, Simone and Rajaram, Vidya and Li, Lida and Burnett, Margaret and Dietterich, Thomas and Sullivan, Erin and Drummond, Russell and Herlocker, Jonathan},
journal = {Machine Learning},
keywords = {cate with each other,explanations,machine learning,otherwise supplement the machine,rating user feedback,s accuracy or,s inferences by incorpo-,to improve the machine,user feedback},
pages = {82--91},
title = {Toward Harnessing User Feedback for Machine Learning},
year = {2007}
}
@inproceedings{Chklovski2006,
author = {Chklovski, Timothy},
booktitle = {Intelligent User Interfaces (IUI)},
chapter = {5},
keywords = {information extraction,sentiment analysis,thinklink},
note = {Looking for people's opinions of things.
 More than just positive vs negative. Can do things like asking "Is Bill Clinton Charismatic", mining positive and negative mentions of the concet.
 Works with "entity-property" pairs.
 Uses templates of degree expressions. "x is very", "x is not at all" etc.
 
 very cool.
},
title = {Deriving Quantitative Overviews of Free Text Assessments on the Web},
year = {2006}
}
@article{Richardson2003,
author = {Richardson, Matthew and Domingos, Pedro},
journal = {Engineering},
pages = {129--137},
title = {Building Large Knowledge Bases by Mass Collaboration},
year = {2003}
}
@article{Chklovski2003a,
author = {Chklovski, Timothy},
pages = {4--12},
title = {Learner: A System for Acquiring Commonsense Knowledge by Analogy},
year = {2003}
}
@inproceedings{Blythe2004,
author = {Blythe, Jim and Gil, Yolanda},
booktitle = {WWW},
chapter = {5},
keywords = {annotation,hypertext,semantic web,thinklink},
note = {
 User enters informal annotation and system guides user to translate it into a formal structure.
 System creates plausible paraphrases within the ontology. User selects the one that is correct.
 If new terms appear, system suggests suitable enhancements to the ontology.
 System called ACE. Extension of the TRELLIS annotation tool.
 UI lists a number of suggested changes to the statement, which the user can turn on and off using check boxes.
 UI then suggests several formal statements it may be making.
 
 Can be used to annotate a document with the meanings of its text.
 --
 In our approach, users enter a short sentence in free text to describe all or part of a document, and the system presents a set of potential paraphrases of the sentence that are generated from valid expressions in the ontology, from which the user chooses the closest match.
 Handcrafted annotations can be more accurate and allow an author to express things the way the want to. However formal annotations let us do more powerful stuff.
 
 -- TRELLIS --
 Aids decision making process.
 A statement is a piece of free text or data that may or may not have been extracted from a document.
 Link statements together with constructions like "is supported by" or "in contrast with".
 ACE extends TRELLIS by helping users formalise their statements.
 
 -- techniques --
 * Suggest rewriting specific terms with their canonical values. E.g. replace "forwards" with "strikers".
 * Suggest simplifications, base on parsing.
 
 -- notes --
 WWW is clearly the right place to be publishing this kind of stuff, rather than CHI.
},
pages = {455--461},
title = {Incremental Formalization of Document Annotations through Ontology-Based Paraphrasing},
year = {2004}
}
@article{Denning2003,
author = {Denning, Peter J},
journal = {Communications of the ACM},
pages = {19--23},
title = {The Profession of IT},
volume = {46},
year = {2003}
}
@article{Strong1997,
author = {Strong, Diane M and Lee, Yang W and Wang, Richard Y},
journal = {Communications of the ACM},
note = {About data quality in databases.
},
pages = {103--110},
title = {Data Quality in Context},
volume = {40},
year = {1997}
}
@article{Kleinberg1999,
author = {Kleinberg, J O N M},
journal = {New York},
pages = {604 --632},
title = {Authoritative Sources in a Hyperlinked Environment},
volume = {46},
year = {1999}
}
@inproceedings{Gil2006,
author = {Gil, Yolanda and Artz, Donovan},
booktitle = {WWW},
chapter = {5},
keywords = {agents when searching for,gies and axioms,how will these automated,over the thousands of,semantic web,systems choose,the popula-,the us census bureau,travel and real estate,trust,web of trust,web pages from},
note = {Did prior work using TRELLIS - which they created.
 Factors influencing trust:* Topic: is the web site focused on the topic this fact is about* Context: If the information is important then the user will trust less* Popularity: If popular, people trust it* Authority: Does the source have some degree of authority (e.g. it is about them, or something they are involved in)* Direct Experience: * Recommendation* Related Resources* Provenence* User extertise* Bias* Incentive* Limited Resources* Agreement* Specificity* Likelihood* Age* Appearance* Deception* Recency
 

},
pages = {565--574},
title = {Towards Content Trust of Web Resources},
year = {2006}
}
@inproceedings{Chklovski2005f,
author = {Chklovski, Timothy and Ratnakar, Varun and Gil, Yolanda},
booktitle = {Intelligent User Interfaces (IUI)},
keywords = {argumentation,thinklink},
note = {Discusses various varients of TRELLIS.
 Tree Trellis is like Think Link.
 Allow one to combine structured argument connectors with free text.
 --
 Compendium for organizing meetings.Trellis mixes free text and structured connectors.
 Want to use natural language processing to infer structured claims from free text.
 Prior work [9,10] used NLP + volunteers to identify 100,000 free text statements contributed by volunteers.
 
 -- Rich Trellis --
 Example connectors:* is elaborated by* Is supported by* stands through contradicted by* allows AND connections
 -- Tree Trellis --
 Only allows "pro" and "con" connectors.
 Structures as a tree rather than a graph, so a "con" argument may be opposing the connection to the parent, rather than the node itself.
 Collected 517 statements on 83 arguments from 60 people on a chat board.
 -- Table Trellis --
 Row = noun. Column = verb. Seems strange.
 
 Uses WordNet[20] to get synonyms and word conjunctions.
},
title = {User Interfaces with Semi-Formal Representations: A Study of Designing Argumentation Structures},
year = {2005}
}
@article{Allwood2008,
author = {Allwood, Jens},
journal = {Pragmatics},
keywords = {context,context dependence,context use,pragmatic web,pragmatics,semantic web,semantics},
pages = {35--40},
title = {Some Remarks on the Relationship between the Semantic and the Pragmatic Web},
year = {2008}
}
@article{Aakhus2008,
author = {Aakhus, Mark and Benovitz, Miriam Greenfeld},
chapter = {5},
journal = {Pragmatic Web},
keywords = {argument reconstruction,argumentation,discourse communities,facilitation,large-scale,mediation,sense-making},
note = {Seems fairly incoherent. 5 pages. No system proposed.
},
pages = {77--81},
title = {Argument Reconstruction and Socio-Technical Facilitation of Large Scale Argumentation},
year = {2008}
}
@article{Schoop2006,
author = {Schoop, By Mareike and Moor, Aldo De and Dietz, Jan L G},
journal = {Communications of the ACM},
keywords = {semantic web,thinklink},
note = {About sorting out the human aspects of the semantic web.
 
 Semantic web will fail because it is too complex and not human-friendly.
 "If there is one lesson to be learned from databases it is that it is practically impossible to describe data well enough for it to be used in arbitrary applicatons".
 "The best hope for the semantic web is to encourage the emergence of communities of interest and practice that develop their own consensus knowledgeon the basis of which they will standardize their representations".
 "The vision of the pragmatic web is thus to aument human colloboration effectively by approriate technologies, such as systems for ontology negotations, for ontology-based business interactions, and for pragmatic ontology-building efforts in communities of practice.
},
pages = {5--6},
title = {The Pragmatic Web: A Manifesto},
volume = {49},
year = {2006}
}
@article{,
pages = {5220--5220},
title = {ask doctor usability}
}
@inproceedings{Yetim2007,
author = {Yetim, Fahri},
booktitle = {Pragmatic Web},
chapter = {5},
keywords = {argument mapping,argumentation,design,discourse-support,examination dialogues,human factors,information quality,pragmatic web,systems,theory},
note = {DISCOURSIUM - tool and methodology for discursive 
},
pages = {29--40},
publisher = {ACM},
title = {DISCOURSIUM for Cooperative Examination of Information in the Context of the Pragmatic Web},
year = {2007}
}
@article{Nagura2006,
author = {Nagura, Ryosuke and Seki, Yohei and Kando, Noriko and Aono, Masaki},
journal = {Group},
pages = {683--684},
title = {A Method of Rating the Credibility of News Documents on the Web},
year = {2006}
}
@article{Shaparenko,
author = {Shaparenko, Benyah and Joachims, Thorsten},
journal = {Test},
keywords = {citation inference,flow of ideas,information genealogy,language models,temporal data,text mining},
pages = {619--628},
title = {Information Genealogy: Uncovering the Flow of Ideas in Non-Hyperlinked Document Databases}
}
@article{Krause2006,
author = {Krause, Andreas and Leskovec, Jure and Guestrin, Carlos},
journal = {Machine Learning},
pages = {497--504},
title = {Data Association for Topic Intensity Tracking},
year = {2006}
}
@article{Marneffe2008,
author = {Marneffe, Marie-catherine De and Rafferty, Anna N and Manning, Christopher D},
journal = {ACL},
keywords = {contradictions},
note = {Surveys different kinds of contradictions.Talks about ways to detect them.
},
pages = {1039--1047},
publisher = {Springer},
title = {Finding Contradictions in Text},
year = {2008}
}
@inproceedings{Titov2008,
author = {Titov, Ivan and Mcdonald, Ryan},
booktitle = {ACL},
keywords = {sentiment analysis},
note = {Analyses online reviews.Extracts aspects that are being discussed (e.g. price, service) and finds positive and negative comments about each.
},
pages = {308--316},
publisher = {Springer},
title = {A Joint Model of Text and Aspect Ratings for Sentiment Summarization},
year = {2008}
}
@inproceedings{Cafarella2005,
author = {Cafarella, Michael J and Downey, Doug and Soderland, Stephen and Etzioni, Oren},
booktitle = {HLT/EMNLP},
keywords = {fact extract,information extraction},
note = {KnowItNow is an improvement on KnowItAll that uses its own search engine rather than relying on an external search engine.
 
 NLP applications often rely on search engine queries.Search engines limit the number of queries you can make.
 Paper allows us to extract info for whole web by not using using engines.
 Extension of previous knowitall system.
 google created Google API to shunt programmatic queries away from HTML page, and has placed hard quotas on use of this.
 
 How original KnowItAll works: generate and test   Generates candidate facts by searching for template phrases. such as "cities such as ..."   Searches for sentences that would indicate that this is true by looking at hit counts for phrases.
 Built their own search engine called the Bindings Engine.Does the same kind of phrase queries directly on its own data.
 First system to extract facts from the web in minutes rather than days.
 

},
pages = {563--570},
publisher = {Springer},
title = {KnowItNow: Fast, Scalable Information Extraction from the Web},
year = {2005}
}
@inproceedings{Etzioni2007,
author = {Etzioni, Oren},
booktitle = {K-CAP},
keywords = {information extraction,machine reading},
note = {KnowItAll
 Extract facts from the web.5 years an UW.
 

},
pages = {1--3},
publisher = {Springer},
title = {Machine Reading of Web Text (Talk Abstract)},
year = {2007}
}
@article{Rahwan2006,
author = {Rahwan, Iyad and Amgoud, Leila},
journal = {Argumentation},
keywords = {11,2,argumentation in agent systems,arti cial intelligence,categories and subject descriptors,distributed arti cial in-,formal models of agency,i},
title = {An Argumentation›based Approach for Practical Reasoning},
year = {2006}
}
@article{Ellis2004,
author = {Ellis, Sean E and Groth, Dennis P},
journal = {Work},
keywords = {annotation,computer supported collaborative,visualization},
pages = {411--414},
title = {A Collaborative Annotation System for Data Visualization},
year = {2004}
}
@article{Zellweger,
author = {Zellweger, Polle T and Bouvin, Niels Olof and Mackinlay, Jock D},
keywords = {arakne,fluid docu-,open hypermedia},
pages = {9--18},
title = {Fluid Annotations in an Open World}
}
@article{Handschuh2003,
author = {Handschuh, Siegfried and Staab, Steffen and Volz, Raphael},
journal = {Management},
title = {On Deep Annotation},
year = {2003}
}
@article{Wolfe2000,
author = {Wolfe, Joanna L},
keywords = {annotation,annotation systems design,composition instruction,note-making,paper,reading},
pages = {19--26},
title = {Effects of Annotations on Student Readers and Writers},
year = {2000}
}
@article{Obendorf2003,
author = {Obendorf, Hartmut},
journal = {Design},
keywords = {1,active reading,annotation,be crucial to the,human created meta-data might,motivation for annotations,success of advan-,user study},
pages = {120--121},
title = {Simplifying Annotation Support for Real-World-Settings: A Comparative Study of Active Reading},
year = {2003}
}
@article{Marshall2004,
author = {Marshall, Catherine C and Brush, A J Bernheim},
journal = {First Monday},
pages = {349--357},
title = {Exploring the Relationship between Personal and Public Annotations},
year = {2004}
}
@article{Dourish1999,
author = {Dourish, Paul and Edwards, W Keith and Lamarca, Anthony and Salisbury, Michael and Laboratory, Computer Science and Center, Xerox Palo Alto Research},
keywords = {12,and rogers,exploring the,riences reported by marshall,rigid structures they offered,systems,the,the more,use of structured hypertext,were poorly suited to,who also found that},
pages = {55--64},
title = {Using Properties for Uniform Interaction in the Presto Document System},
volume = {1},
year = {1999}
}
@article{Bauer2008,
author = {Bauer, Aaron and Koedinger, Kenneth R},
journal = {Human Factors},
keywords = {annotation,copy-paste,design,education,note-taking},
pages = {397--406},
title = {Note-Taking, Selecting, and Choice: Designing Interfaces That Encourage Smaller Selections},
year = {2008}
}
@article{Marshall1997,
author = {Marshall, Catherine C and Corporation, Xerox and Alto, Palo},
keywords = {annotation,annotation systems design,digital library,markings,reading tools,study},
pages = {131--140},
title = {Annotation: from paper books to the digital library},
year = {1997}
}
@inproceedings{Marshall1998,
author = {Marshall, Catherine C},
booktitle = {Hypertext},
keywords = {annotation,consensus,oriented systems,reading-,spatial hypertext,study},
pages = {40--49},
title = {Toward an ecology of hypertext annotation},
year = {1998}
}
@article{Marshall2002,
author = {Marshall, Catherine C},
journal = {Library},
keywords = {annotation,collaboration,on-line discussion,reading},
pages = {812--813},
title = {From Personal to Shared Annotations},
year = {2002}
}
@article{Brush2001,
author = {Brush, A J Bernheim and Bargeron, David and Gupta, Anoop and Group, Multimedia Systems and Research, Microsoft and Way, One Microsoft},
journal = {Framework},
keywords = {3,being refined,cadiz et al,however,line width,more primitive and currently,report on a recent,study where they observed,the annotation capabilities provided,to date are},
pages = {285--292},
title = {Robust Annotation Positioning in Digital Documents},
year = {2001}
}
@article{Aleman-meza2006,
author = {Aleman-meza, Boanerges and Nagarajan, Meenakshi and Ramakrishnan, Cartic and Ding, Li and Kolari, Pranam and Sheth, Amit P and Arpinar, I Budak and Joshi, Anupam and Finin, Tim},
journal = {Social Networks},
keywords = {conflict of interest,data,entity disambiguation,peer,review process,semantic analytics,semantic web,social networks},
pages = {407--416},
title = {Semantic Analytics on Social Networks: Experiences in Addressing the Problem of Conflict of Interest Detection},
year = {2006}
}
@article{Nam2007,
author = {Nam, Kevin K and Ackerman, Mark S},
journal = {Communities},
pages = {137--146},
title = {Arkose: Reusing Informal Information from Online Discussions},
year = {2007}
}
@article{Graham1999,
author = {Graham, Jamey and Center, California Research and Valley, Ricoh Silicon and Park, Menlo},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {14,are forced to optimize,daily reading by sifting,enough time to read,ful documents and not,in particular,of informa-,office workers,their,them all,through the vast amount},
title = {The Reader’s Helper: A Personalized Document Reading Environment},
year = {1999}
}
@article{Salton1996,
author = {Salton, Gerard and Singhal, Amit and Buckley, Chris and Science, Computer},
journal = {Compare A Journal Of Comparative Education},
pages = {53--65},
title = {Automatic Text Decomposition Using Text Segments and Text Themes},
year = {1996}
}
@article{Views1986,
author = {Views, Fisheye and Furnas, George W and Research, Bell Communications and Jersey, New},
title = {CH 1’86 Proceedings April 1986},
year = {1986}
}
@article{Schwartz1987,
author = {Schwartz, D},
journal = {Acm Transactions On Office Information Systems},
pages = {168--186},
title = {Contexts-A Partitioning Concept for Hypertext},
volume = {5},
year = {1987}
}
@article{Framework,
author = {Framework, Analytic},
journal = {Structure},
pages = {121--127},
title = {Analytic framework}
}
@article{Marshall1987,
author = {Marshall, C and Information, Xerox Special},
title = {Exploring Representation Using Hypertext},
year = {1987}
}
@article{Brown1987,
author = {Brown, P J and Laboratory, Computing},
journal = {History},
pages = {33--40},
title = {Turning Ideas into Products: The Guide System},
year = {1987}
}
@article{Grudin1988,
author = {Grudin, Jonathan},
pages = {85--93},
title = {Why cscw applications fail: problems in the design and evaluation of organizational interfaces},
year = {1988}
}
@article{Carr2001,
author = {Carr, Leslie and Hall, Wendy and Bechhofer, Sean and Goble, Carole},
journal = {Science},
keywords = {an important activity,as the attributes,enabling search engines to,link service,metadata,navigation,of web pages is,ontology,open hypermedia,providing conceptual content-based information},
title = {Conceptual Linking: Ontology-based Open Hypermedia},
year = {2001}
}
@article{Paul2008,
author = {Paul, Sharoda A},
journal = {Russell The Journal Of The Bertrand Russell Archives},
keywords = {acm classification keywords,collaborative sensemaking,emergency department,ethnography,icts,representations},
pages = {3105--3110},
title = {Information and Communication Tools as Aids to Collaborative Sensemaking},
year = {2008}
}
@article{Trigg1987,
author = {Trigg, Randall H and Irish, Peggy M},
journal = {Screen},
pages = {89--108},
title = {Hypertext Habitats: Experiences of Writers},
year = {1987}
}
@article{Ackermann1995,
author = {Ackermann, Mark S and Starr, Brian},
journal = {UIST},
title = {Social Activity Indicators: Interface Components for CSCW Systems},
year = {1995}
}
@article{Jones1986,
author = {Jones, William P and Corporation, Computer Technology},
journal = {Machinery},
title = {CH 1’86 Proceedings April 1986},
year = {1986}
}
@article{Kim2004,
author = {Kim, Sunghun and Whitehead, E James},
journal = {Text},
keywords = {and show various properties,background reading for researchers,background reading paper extractor,bpe,especially useful as,field,in this,new to a research,of academic paper references,paper we introduce the,such related papers are},
pages = {44--45},
title = {Properties of Academic Paper References},
year = {2004}
}
@inproceedings{Wiil1996,
author = {Wiil, Uffe Kock and Leggett, John J},
booktitle = {Hypertext},
keywords = {hypertext,open hypermedia,thinklink},
note = {Supports inter-tool linking between hypermedia systems.
 All about information integration between hypermedia systems. Seems a bit boring.
},
title = {The HyperDisco Approach to Open Hypermedia Systems},
year = {1996}
}
@article{Niimberg1997,
author = {Niimberg, Peter J and Leggett, John J and Schneider, Erich R and Laboratory, Hypermedia Research},
journal = {Structure},
title = {As We Should Have Thought},
year = {1997}
}
@article{El-beltagy2001,
author = {El-beltagy, Samhaa R and Hall, Wendy and Roure, David De and Carr, Leslie},
journal = {Sort},
keywords = {advance and links are,dynamic linking,if a user,link generation,links,pages that meet a,s information needs are,s interest,the,then this could lead,to be anticipated in,to be dynamically added,to web,user},
pages = {151--160},
title = {Linking in Context},
year = {2001}
}
@article{Akscyn1989,
author = {Akscyn, Robert and Mccracken, Donald and Yoder, Elise and Incorporated, Knowledge Systems},
journal = {Electronic Publishing},
title = {KMS: A Distributed Hypermedia System for Managing Knowledge In Organizations},
year = {1989}
}
@article{Ashman2000,
author = {Ashman, Helen and Simpson, Rosemary Michelle},
journal = {ACM Computing Surveys},
title = {Computing Surveys’ Electronic Symposium on Hypertext and Hypermedia: Editorial},
volume = {31},
year = {2000}
}
@article{Center,
author = {Center, Xerox Palo Alto Research and Alto, Palo},
journal = {Artificial Intelligence},
title = {Information Environments}
}
@article{Carlson1990,
author = {Carlson, David A and Ram, Sudha},
journal = {Communications of the ACM},
pages = {311--321},
title = {HyperIntelligence: The Next Frontier},
volume = {33},
year = {1990}
}
@article{Marchionini,
author = {Marchionini, Gary},
journal = {Communications of the ACM},
pages = {41--46},
title = {From finding to understanding},
volume = {49}
}
@article{Giles,
author = {Giles, C Lee and Bollacker, Kurt D and Lawrence, Steve},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {available for,citeseer will soon be,given,links,or,paper can be located,papers related to a,search or by citation,using common citation information,word vector similarity},
pages = {89--98},
title = {CiteSeer: An Automatic Citation Indexing System}
}
@article{John1996,
author = {John, Bonnie E and Kieras, David E},
journal = {ACM Transactions on Computer-Human Interaction},
pages = {320 --351},
title = {The GOMS Family of User Interface Analysis Techniques: Comparison and Contrast},
volume = {3},
year = {1996}
}
@article{Center1983,
author = {Center, Xerox Palo Alto Research},
journal = {Acm Transactions On Office Information Systems},
pages = {99--112},
title = {How Do People Organize Their Desks? Implications for the Design of Office Information Systems},
volume = {1},
year = {1983}
}
@article{Cover1989,
author = {Cover, Robin},
pages = {249--257},
title = {the Notion of Links},
year = {1989}
}
@article{,
title = {No title.}
}
@article{Bier2004,
author = {Bier, Eric and Good, Lance and Popat, Kris and Newberger, Alan},
journal = {Human Factors},
keywords = {bookplex,computer-aided reading,digital library,document management,figure 1,in-depth reading,spatial memory,the iterative process of,visualization,zoomable user interface},
pages = {87--96},
title = {A Document Corpus Browser for In-Depth Reading},
year = {2004}
}
@article{Piroui1996,
author = {Piroui, Peter and Schank, Patricia and Hearst, Marti and Diem, Christine},
journal = {Processing},
keywords = {browsing,clustering,gather,information retrieval,scatter},
pages = {213--220},
title = {Scatter/Gather Browsing Communicates the Topic Structure of a Very Large Text Collection},
year = {1996}
}
@article{Kaufer1987,
author = {Kaufer, David and Chimera, Rick},
journal = {Knowledge Creation Diffusion Utilization},
pages = {121--141},
title = {The Notes Program: A Hypertext Application for Writing from Source Texts},
year = {1987}
}
@article{Kaplan,
author = {Kaplan, Nancy and Chisik, Yoram},
journal = {Director},
keywords = {children,digital annotations,digital libraries,literacy,participatory design,sociable},
title = {Reading Alone Together: Creating Sociable Digital Library Books}
}
@article{Catlin1989,
author = {Catlin, Timothy and Bush, Paulette and Yankelovich, Nicole},
journal = {InterMedia},
pages = {365--378},
title = {InterNote: Extending a Hypermedia Framework to Support Annotative Collaboration},
year = {1989}
}
@article{Halasz1987,
author = {Halasz, Frank G},
journal = {Hypertext},
title = {Reflections on NoteCards: Seven Issues for the Next Generation of Hypermedia Systems},
year = {1987}
}
@article{Marshall2001a,
author = {Marshall, Catherine C},
journal = {Journal of Computer Documentation},
keywords = {formality,hypermedia,hypertext,reading,retrieval,use,user interface design,world-wide web},
pages = {96--103},
title = {Notecards in the Age of the Web},
year = {2001}
}
@article{Prante,
author = {Prante, Thorsten and Magerkurth, Carsten and Streitz, Norbert},
journal = {Idea},
keywords = {by entering text simultaneously,e,i,in parallel instead of,production blocking,uttering oral statements sequentially},
pages = {170--179},
title = {Developing CSCW Tools for Idea Finding – Empirical Results and Implications for Design}
}
@article{Halasz2001,
author = {Halasz, Frank G},
journal = {ACM Journal of Computer Documentation},
keywords = {hypermedia,hypertext,user interface design,world-wide web},
pages = {109--114},
title = {Reflections on the "Seven Issues": Hypertext in the Era of the Web},
volume = {25},
year = {2001}
}
@article{Marshall1992,
author = {Marshall, Catherine C and Center, Xerox Palo Alto Research and Alto, Palo and Rogers, Russell A},
journal = {System},
title = {Two Years before the Mist: Experiences with Aquanet},
year = {1992}
}
@article{Lawton1993,
author = {Lawton, T and Smith, Ian E},
journal = {Machinery},
pages = {106--117},
title = {No title.},
year = {1993}
}
@article{Agosti2007,
author = {Agosti, Maristella and Ferro, Nicola},
journal = {ACM Transactions on Information Systems},
month = {November},
pages = {3--es},
title = {A Formal Model of Annotations of Digital Content},
volume = {26},
year = {2007}
}
@article{Abowd2000,
author = {Abowd, Gregory D and Ishiguro, Yoshihide},
keywords = {and made available as,experiences are rich in,humans,hypermedia documents,information,it also assumes that,provides a,valuable source of information,when captured,which},
pages = {39--48},
title = {Linking by Interacting: a Paradigm for Authoring Hypertext},
year = {2000}
}
@article{Noirhomme-p,
author = {Noirhomme-p, Monique and Tel, Belgium},
journal = {Media},
pages = {146--155},
title = {Visual representation of hypermedia links according to their types}
}
@article{Taufer2004,
author = {Taufer, Trent and Fails, Jerry Alan},
journal = {October},
keywords = {annotation},
note = {
},
title = {ScreenCrayons: Annotating Anything},
volume = {6},
year = {2004}
}
@article{Chen1895,
author = {Chen, Chaomei and Carr, Les},
journal = {Communications of the ACM},
pages = {51--60},
title = {Trailblazing the Literature of Hypertext: Author Co-Citation Analysis (198&l 998)},
year = {1895}
}
@article{Quint1992,
author = {Quint, Vincent and Vatton, Irene},
title = {Combining Hypertext and Structured Documents in Grif},
year = {1992}
}
@article{Shipman1994,
author = {Shipman, M},
pages = {285--291},
title = {Supporting Knowledge-Base Evolution with Incremental Formalization},
year = {1994}
}
@article{Henry1991,
author = {Henry, R and Hudson, E},
journal = {Science},
pages = {55--64},
title = {Tyson University R. Henry},
year = {1991}
}
@article{Dobroth2001,
author = {Dobroth, Kate},
journal = {Journal of Computer Documentation},
keywords = {and exchanging data,apple was just about,for email,hypermedia,in 1988,newsgroups,the internet was widely,to,usability,used by unix-running academics,user interface design,world-wide web},
pages = {88--91},
title = {From Notecards to the Web: The Role of Halasz's Seven Issues},
volume = {25},
year = {2001}
}
@inproceedings{Furuta1989,
author = {Furuta, Richard and Stotts, P David},
booktitle = {Hypertext},
chapter = {5},
keywords = {hypertext,thinklink},
note = {There are several different ways that a hypertext document can be browsed.
 Let the document itself specify the correct way to visualize it.
 Based on Trellis.
},
title = {Programmable Browsing Semantics in Trellis},
year = {1989}
}
@article{Stefik1987,
author = {Stefik, Mark and Foster, Gregg and Bobrow, Daniel G and Kahn, Kenneth and Lanning, Stan and Suchman, Lucy},
journal = {Communications of the ACM},
title = {BEYOND THE CHdLKBOARD: COMPUTER SUPPORT FOR COllA0ORATlON AND PROBLEM SOlVlhIG /IV MEETINGS},
volume = {30},
year = {1987}
}
@article{Introduction1987,
author = {Introduction, I},
title = {Relationally Encoded Rhetoric of Hypertext},
year = {1987}
}
@inproceedings{Sereno2005,
author = {Sereno, Bertrand and Shum, Buckingham and Motta, Enrico},
booktitle = {Intelligent User Interfaces (IUI)},
keywords = {sensemaking,thinklink},
note = {Scholarly documents.TriplesAnnotate a document with an interpretation of its contents
 -- Supporting environment to help people annotate a document with an interpretation of its contents.
 Suggestions to support document annotation.
 Not about annotating with "facts" but interpretations from a sensemaking process.
 For a scholarly document: what it's salient points are, how it relates to previous work in a community, how innovative it is. 
 Describe relationship with documents published afterwards and other material not cited.
 Part of the Scholarly Ontologies project.
 Connection of plugins suggests possible annotations.
 
 Did a user study with 13 people.
 
 Previous work:See [10] - CREAM

},
title = {ClaimSpotter: an Environment to Support Sensemaking with Knowledge Triples},
year = {2005}
}
@inproceedings{Hoffmann2007,
author = {Hoffmann, Michael H G},
booktitle = {Pragmatic Web},
keywords = {charles s,computer supported argument visualization,csav,diagram-,dialog mapping,jeff conklin,lam,logical argument mapping,matic reasoning,peirce,rationale,thinklink,tim van},
note = {link types:* therefore (maps many inputs to one conclusion)* supports (one input to one conclusion)* objects* clarifies and supports
 Similar to Toulmin graph.Not a software tool, but a graph structure.
 Paper is difficult to understand. Not clear what's being done.
 --
 The web can play a role in building common ground between people who have different valus and interests.
 About Logical Argument Mapping (LAM).
 
 Talks about Toulmin's model of argumentation, computer supported argument visualization (CSAV).
 
 Best overviews: visualizing argumentation: software tools for collaborative and educational sense-making.   (insanely overpriced text book)
 quote:  an argument is“any set of statements in which the truth of one statement isintended to be supported by the other statement (or statements)”
 Graph features:   links are: therefore, supports, clarifies and supports, objects
},
title = {Logical Argument Mapping: A cognitive-change-based method for building common ground},
year = {2007}
}
@article{Hilll1999,
author = {Hilll, Will and Terveenl, Loren and Jul, Peter and Park, Florham},
journal = {Collections},
title = {An Empirical Evaluation of User Interfaces Management of Web Sites for Topic},
year = {1999}
}
@article{Baldonado2000,
author = {Baldonado, Michelle Q Wang and Woodruff, Allison},
keywords = {guidelines,information visualization,multiple views,usability heuristics,user interfaces},
pages = {110--119},
title = {Guidelines for Using Multiple Views in Information Visualization},
year = {2000}
}
@article{Baldonado1997,
author = {Baldonado, Michelle Q Wang and Winograd, Terry},
journal = {Options},
keywords = {can find a,collection of resources on,designed for,good topic and a,successfully completed if he,that topic,the interface presented in,this paper has been,will consider his task},
title = {SenseMaker: An Information-Exploration Interface Supporting the Contextual Evolution of a User’s Interests},
year = {1997}
}
@article{Russell1993,
author = {Russell, Daniel M and Stefii, Mark J and Pirolli, Peter and Card, Stuart K and Area, User Interface Research and Center, Xerox Palo Alto Research and Alto, Palo},
journal = {Time},
keywords = {cost structure,representation,search,sensemaking},
pages = {24--29},
title = {The Cost Structure},
year = {1993}
}
@article{Nakakoji2000,
author = {Nakakoji, Kumiyo and Yamamoto, Yasuhiro and Takada, Shingo and Reeves, Brent N},
journal = {Design},
keywords = {an alternative to sketching,cognitive models,reflection-in-action,support,theoretical framework for design,two-dimensional positioning,writing support},
pages = {145--154},
title = {Two-Dimensional Spatial Positioning as a Means for Reflection in Design},
year = {2000}
}
@article{Fu2008,
author = {Fu, Wai-tat and Lab, Applied Cognitive Science and Division, Human Factors},
pages = {229--238},
title = {The Microstructures of Social Tagging: A Rational Model},
year = {2008}
}
@inproceedings{Anderson1997,
author = {Anderson, Kenneth M},
booktitle = {Hypertext},
keywords = {annotation,open hypermedia,thinklink},
note = {Open hypermedia seems to just be about different hypertext systems talking to each other and doing link maintainence.
 Not clear why it is exciting or why relevant to annotation.
},
title = {Integrating Open Hypermedia Systems with the World Wide Web},
year = {1997}
}
@inproceedings{Handschuh2002,
author = {Handschuh, Siegfried and Staab, Steffen},
booktitle = {WWW},
keywords = {annotation,metadata,rdf,semanticweb,thinklink},
note = {  --    semantic web Lets users create metadata while writing a page.   Previous systems required people to first create the content and then annotate it. CREAM makes it easier to create both together.   Helps spot facts that are appearing on the page you write so you can mark them up.
 Ont-O-Mat is the reference implementation of CREAM.
},
title = {Authoring and Annotation of Web Pages in CREAM},
year = {2002}
}
@article{Sereno2004,
author = {Sereno, Bertrand and Buckingham, Simon and Motta, Enrico},
journal = {WWW},
keywords = {annotation,thinklink},
note = {[Just a 2 page note]
 Focussed on scholarly work.About formal knowledge triples.Highlights things in a document.
 Part of ClaimSpotter.
 Not clear what they want to use it for.
 
 ---
 Part of Scholarly Ontologies project, which aims at buliding a network of interpretations enriching a corpus of scholarly papers. One does not have "right" and "wrong" values.
 Semantic web is about representing knowledge which is known to be true. Scholarly Ontologies is instead about knowledge which is open to debate.
 Scholarly documents are annotated or enriched with (possibly contradicting) interpretions made by readers.
 Annotations are expressed as triples/claims. [node,relation,node]
 Nodes can be chunks of text, or (typed) concepts.The relation is in an instance of a class defined in a formal ontology.
 
 The knowledge may not actually appear in the documents (unlike semantic web), and may be different for different annotators.
 
 Builds on "Scholarly Publishing and Argument in Hypertext"
 Shipman quote "Users are hesitant about formalization because of a fear of prematurely committing to a specific perspective on their tasks; this may be especially true in a collaborative setting where people must agree on an appropriate formalism"  [2] - Supporting Knowledge Base Evolution with Incremental Formalization
 Use a recommending approach, suggesting things one may wish to annotate. Searches for known noun groups.
 
 
 

},
title = {Semi-Automatic Annotation of Contested Knowledge on the World Wide Web},
year = {2004}
}
@inproceedings{Uren2003,
author = {Uren, Victoria and Shum, Simon Buckingham and Li, Gangmin and Domingue, John and Motta, Enrico},
booktitle = {WWW},
keywords = {argumentation,collaborative,modeling debate,scholarly interpretation,scientific publishing,thinklink,web},
note = {For scholarly publishing.
 New ideas are nodes.People build on them by linking to them.
 Paper is itself written in the ClaiMaker model.
 Links nouns together with verbs.E.g. ClaiMaker system addresses Digital Library Management.
 Has a large collection of links that one can use.
 -- 
 
 
 Hypertext shaped by Memex and NLS from Engelart.
 

},
title = {Scholarly Publishing and Argument in Hyperspace},
year = {2003}
}
@article{Trigg1986,
author = {Trigg, Randall H and Weiser, Mark},
journal = {Acm Transactions On Office Information Systems},
keywords = {and phrases,hypertext},
title = {TEXTNET: A Network-Based Approach to Text Handling},
volume = {4},
year = {1986}
}
@article{Wang1998,
author = {Wang, Weigang and Rada, Roy},
chapter = {5},
journal = {ACM Transactions on Information Systems},
keywords = {hypertext,thinklink},
note = {Found that users often don't use link types, or use them wrong.
 Create link model specific for a given domain - not one size fits all.
 --
 Most semantic-net based hypertext systems leave the linking consistency of the net to individual users. Users without guidance may accidentally introduce structural and relational inconsistencies in the semantic nets. The relational inconsistency hinders the creation of domain information models.Typed links a very old idea in hypertext, and standards exist for the web (though not widely used).
 
 Three types of hypertext structures:* unstructured - arbitrary node and link types* semistructured - recommended link types, but also use own* structured - fixed set of node and link types, and rules about what can link to what with what type
 
 
 Authors created the MUCH hypertext system (Man Using and Creating Hypertext).
 Found that users did not use link types - everyone used the default link type. When a non-default type was used, it was often inconsistent with uses by others.
 Uses a depth-first algorithm to generate hierachial views for printing purposes. KMS also does this.
 
 

},
title = {Structured Hypertext with Domain Semantics},
volume = {16},
year = {1998}
}
@article{Bernstein2000,
author = {Bernstein, Mark},
journal = {ACM Computing Surveys},
keywords = {absence of,criticism,design,engelbart 1963,expression in interlinked media,fiction,had to imagine the,hypertext rhetoric,hypertext structure,hypertexts to study,kinds of,navigation problem,nelson 1976,originally developed in the,pattern languages,patterns,rhetoric,the end of the,the first hypertext critics,the study of effective},
pages = {1--6},
title = {Structural Patterns and Hypertext Rhetoric},
volume = {1},
year = {2000}
}
@article{Nguyen,
author = {Nguyen, Tien N and Munson, Ethan V and Boyland, John T},
journal = {System},
keywords = {hypertext versioning,sion control,software con guration management,software engineering,ver-},
title = {The Molhado Hypertext Versioning System}
}
@inproceedings{Marshall1993,
author = {Marshall, C and Center, Xerox Palo Alto Research and Alto, Palo},
booktitle = {Hypertext},
title = {Searching for the Missing Link: Discovering Implicit Structure in Spacial Hypertext},
year = {1993}
}
@article{Vitali,
author = {Vitali, Fabio and Bieber, Michael},
journal = {ACM Computing Surveys},
pages = {1--6},
title = {Hypermedia on the Web: What Will It Take?},
volume = {1}
}
@article{Systems1993,
author = {Systems, Eastgate and Drive, Coyote Hill and Alto, Palo and Bernstein, Mark and Bernstein, Mark and Bolter, J David},
journal = {Environment},
title = {Argumentation in Action},
year = {1993}
}
@article{Plains1990,
author = {Plains, White},
journal = {Critique},
pages = {337--347},
title = {Using Critics to Empower Users},
year = {1990}
}
@article{Silverman1992,
author = {Silverman, Barry G},
journal = {Communications of the ACM},
title = {Survey of Expert Critiquing Systems: Practical and Theoretical Frontiers},
year = {1992}
}
@article{Creativity1995,
author = {Creativity, O F},
journal = {Sciences-New York},
pages = {123--124},
title = {Belvedere: Stimulating Students’ Critical Discussion},
year = {1995}
}
@article{Greenberg1991,
author = {Greenberg, Saul},
journal = {SIGCHI Bulletin},
keywords = {and a list of,and overview of the,general,groupware systems and concepts,indexed to the bibliogra-,is selected from the,limited set shown in,section 2,sources that publish cscw,table 1,the article also includes,works},
title = {An annotated bibliography of computer supported cooperative work},
volume = {23},
year = {1991}
}
@inproceedings{Marshall1991,
author = {Marshall, Catherine C and Halasz, Frank G and Rogers, Russell A and Janssen, William C},
booktitle = {Hypertext},
keywords = {argumentation,hypertext,thinklink},
note = {Tool for organizing and structuring information.   May have unknown structure, rather than imposing a structure - like IBIS.
 Allows users to define their own "schemas" that express argument structures and link types that they can use.
},
title = {Aquanet: a hypertext tool to hold your knowledge in place},
year = {1991}
}
@article{Marshall2003,
author = {Marshall, Catherine C and Shipman, Frank M},
journal = {Human Factors},
keywords = {digital libraries,hypertext,information systems,knowledge,knowledge acquisition,representation,semantic web},
pages = {57--66},
title = {Which Semantic Web?},
year = {2003}
}
@article{Rubart2008,
author = {Rubart, Jessica},
journal = {Web Semantics},
keywords = {language sharing,web engineering,web science,web semantics},
pages = {53--56},
title = {Semantics through Language Sharing},
year = {2008}
}
@article{Furnas2005,
author = {Furnas, George W and Arbor, Ann and Russell, Daniel M and Jose, San},
journal = {Human Factors},
pages = {2115--2116},
title = {Making Sense of Sensemaking},
year = {2005}
}
@article{Work1995,
author = {Work, Making},
journal = {Communications of the ACM},
title = {Visible 1},
year = {1995}
}
@article{Shneiderman2000,
author = {Shneiderman, B E N},
journal = {ACM Transactions on Computer-Human Interaction},
pages = {114 --138},
title = {Creating Creativity: User Interfaces for Supporting Innovation},
volume = {7},
year = {2000}
}
@article{Erickson2000,
author = {Erickson, Thomas and Kellogg, Wendy A},
journal = {ACM Transactions on Computer-Human Interaction},
pages = {59 --83},
title = {Social Translucence: An Approach to Designing Systems that Support Social Processes},
volume = {7},
year = {2000}
}
@article{Mosher1995,
author = {Mosher, Andrea and Together, Users and Corbin, Juliet and Publications, Sage},
journal = {October},
pages = {27--28},
title = {How to Avoid Designing Digital Libraries: A Scenario-based Approach John M. Carroll Virginia Tech, Blacksburg, VA},
volume = {16},
year = {1995}
}
@article{,
journal = {Cognition},
pages = {44--54},
title = {No title.}
}
@article{Arias2000,
author = {Arias, Ernesto and Eden, H A L and Fischer, Gerhard and Gorman, Andrew and Scharff, Eric},
journal = {ACM Transactions on Computer-Human Interaction},
pages = {84 --113},
title = {Transcending the Individual Human Mind—Creating Shared Understanding through Collaborative Design},
volume = {7},
year = {2000}
}
@article{Lemke1991,
author = {Lemke, C},
journal = {Science And Technology},
keywords = {and phrases,design environments},
pages = {123--151},
title = {The Role of Critiquing in Cooperative Problem Solving},
volume = {9},
year = {1991}
}
@article{Girgensohn,
author = {Girgensohn, Andreas and Shipman, Frank M},
journal = {Network},
pages = {340--348},
title = {Supporting Knowledge Acquisition by End Users: Tools and Representations}
}
@article{Plains,
author = {Plains, White},
journal = {Journal of the ACM},
title = {Janus: basic concepts and sample dialog}
}
@article{Fischer1988,
author = {Fischer, Gerhard and Jones, William P and Little, Arthur D and Kintsch, Walter and Kay, Alan C and Weyer, Stephen A and Trigg, Randall H},
journal = {CHI},
pages = {223--227},
title = {A Critical Assessment of Hypertext Systems},
year = {1988}
}
@article{Whitehead1960,
author = {Whitehead, Jim and Cruz, Santa},
journal = {System},
title = {As We Do Write: Hyper-terms for Hypertext},
year = {1960}
}
@article{Thiiring1989,
author = {Thiiring, Manfred},
journal = {Information Systems},
title = {Norbetl A, Streitz, J&g Hannemann, and Manfred Thiiring},
year = {1989}
}
@article{Niirnberg1999,
author = {Niirnberg, Peter J and Ashman, Helen},
journal = {Synthesis},
pages = {83--90},
title = {What Was the Question ? Reconciling Open Hypermedia World Wide Web Research and},
year = {1999}
}
@article{Davies,
author = {Davies, Stephen and Allen, Scotty and Raphaelson, Jon and Meng, Emil and Engleman, Jake and King, Roger and Lewis, Clayton},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {concept maps,personal knowledge bases,transclusion},
pages = {150--159},
title = {Popcorn: the personal knowledge base}
}
@article{Shipman2002,
author = {Shipman, Frank and Moore, J Michael and Maloor, Preetam and Hsieh, Haowei and Akkapeddi, Raghu},
journal = {Communications of the ACM},
keywords = {1,dialogs,hypertext and knowledge,incremental formalization,mixed-initiative,spatial hypertext,spatial parser,suggestion-based interfaces,visual language},
pages = {25--34},
title = {Semantics Happen: Knowledge Building in Spatial Hypertext},
year = {2002}
}
@article{Treleaven1993,
author = {Treleaven, B},
pages = {190--195},
title = {OMNI: Through},
year = {1993}
}
@article{Cox2000,
author = {Cox, Donald and Laboratory, Toronto},
journal = {Science},
keywords = {collaborative interpretation,emergence,meeting support,real-time distributed groupware,tools},
title = {Supporting Collaborative Interpretation in Distributed Groupware},
year = {2000}
}
@article{Qu2003,
author = {Qu, Yan and Arbor, Ann},
journal = {New Horizons},
keywords = {information gathering,representation shift,sensemaking},
pages = {906--907},
title = {A Sensemaking-Supporting Information Gathering System},
year = {2003}
}
@article{Cleary1996,
author = {Cleary, Chip and Bareiss, Ray},
journal = {Context},
keywords = {automated},
pages = {31--41},
title = {Practical Methods for Automatically Links},
year = {1996}
}
@article{Hai1991,
author = {Hai, Charles},
pages = {71--74},
title = {Legalese: a legal argumentation too l},
volume = {23},
year = {1991}
}
@article{Zhang2008,
author = {Zhang, Xiaolong and Qu, Yan and Giles, C Lee and Song, Piyou},
journal = {Notes},
keywords = {light weight interaction,sensemaking},
pages = {677--680},
title = {CiteSense: Supporting Sensemaking of Research Literature},
year = {2008}
}
@article{Nejati,
author = {Nejati, Shiva and Chechik, Marsha},
journal = {Framework},
keywords = {3-valued logic,inconsistency detection,model checking,model merging,negotiation,re nement},
pages = {287--290},
title = {Let’s Agree to Disagree}
}
@article{Romero-salcedo,
author = {Romero-salcedo, Manuel and Sheremetov, Leonid and Chi, Manuel and Villa, Luis},
keywords = {action-,cdebate esta basada en,cognitivos y motores que,el cual establece una,el modelo apri,formalización de los estados,perception-reflection-intention},
pages = {107--115},
title = {Estudio y análisis de la conciencia de espacio de trabajo en CDebate: una aplicación groupware para debates colaborativos}
}
@article{Caloini1992,
author = {Caloini, Andrea and Laboratory, Technology Research},
title = {Matching Hypertext Models to Hypertext Systems: a Compilative Approach},
year = {1992}
}
@article{Hypertext1995,
author = {Hypertext, Spatial},
journal = {Communications of the ACM},
title = {Designing for Change},
volume = {38},
year = {1995}
}
@article{,
title = {No title.}
}
@article{Oinas-kukkonen2000,
author = {Oinas-kukkonen, Harri},
journal = {ACM Computing Surveys},
title = {Flexible CASE and Hypertext},
volume = {1},
year = {2000}
}
@article{Tao,
author = {Tao, Tao},
pages = {163--176},
title = {HyperRef - Online Support for Research literature Assessment and Documentation}
}
@inproceedings{Trigg1986a,
author = {Trigg, Randall H},
booktitle = {CSCW},
pages = {153--162},
title = {Supporting Collaboration in Notecards},
year = {1986}
}
@article{Malone1986,
author = {Malone, Thomas W and Grant, Kenneth R and Lai, Kum-yew and Rao, Ramana and Rosenblitt, David},
pages = {102--114},
title = {Semi-Structured M e s s a g e s are Surprisingly Useful for C o m p u t e r - S u p p o r t e d Coordination},
year = {1986}
}
@article{Halasz1987a,
author = {Halasz, Frank G and Moran, Thomas P and Trigg, Randall H and Laboratory, Intelligent Systems and Center, Xerox Palo Alto Research and Alto, Palo},
journal = {Race},
pages = {45--52},
title = {+ gi 1987},
year = {1987}
}
@article{Halasz1988,
author = {Halasz, Frank G},
journal = {Communications of the ACM},
keywords = {hypertext,thinklink},
note = {Electronic note cards linked by typed links.
 Allowed one to view the link graph graphically.
 A filebox is a special card that contains a collection of links to other cards.
 
 -- early hypermedia --
 NLS/Augment, FRESS, ZOG.
},
title = {Reflections on Notecards: Seven Issues for the Next Generation of Hypermedia Systems},
volume = {31},
year = {1988}
}
@inproceedings{Diakopoulos2008,
author = {Diakopoulos, Nicholas and Essa, Irfan},
booktitle = {Pragmatic Web},
keywords = {sensemaking,thinklink},
note = {4 page paper.I've seen this one demoed.
 Allows people to comment on a transcript of video. Could be applied to text. Highlights text in red if discussed.
 Key actions are "mark as a claim" and "comment on an existing claim". Comments can be given typed tags.
 References lots of useful material from other fields.
 About rating a particular speaker, rather than the core idea. Rate them for validity, accuracy, reliabliity, comprehensiveness.
 
 -- 
 asside:It's a shame that most academic publications are locked away so that you can't read them.
 --
 Allow people to respond to criticisms of information quality in online political videos and their transcripts.
 Aimed at politically astute people such as bloggers.
 Rate accuracy, credibility, expertise, and trust.
 Could also apply same technique to a purely textual article.
 Interviewed three local political bloggers and surveyed 27 people. Did think-aloud walkthroughs with 2 local political bloggers.
 Supports both unconstrained comments and typed annotations.
 Doesn't seem to link stuff as part of a greater graph.
 Validity = well groundedness or logical correctness of a claim. Are they correctly interpreting their sources?
 High level annotations are "mark as a claim" and "add a comment".
 Can associate with an external source. Can rate trust and expertise of a source on a three point scale.
 Also allows user-defined tags.
 
 
 
 
 
 
 

},
title = {An Annotation Model for Making Sense of Information Quality in Online Video},
year = {2008}
}
@article{Streitz1992,
author = {Streitz, Norbert and Lemke, Andreas and Publication, Integrated and Schtitt, Helge and Thuring, Manfred},
title = {SEPIA: A Cooperative Hypermedia},
year = {1992}
}
@inproceedings{Fischer1989,
author = {Fischer, Gerhard and Mccall, Raymond and March, Anders},
booktitle = {Hypertext},
keywords = {argumentation,based information systems,construction,construction kits,design environments,human problem-domain communication,hypertext,ibis,informed design,issue-,knowledge-based systems,methodology,phi,procedural hierarchy of issues,thinklink},
note = {Architectural design program that includes argumentation.
},
title = {JANUS: Integrating Hypertext with a Knowledge-based Design Environment},
year = {1989}
}
@article{Burgess,
author = {Burgess, K C and Jeffrey, E},
journal = {October},
title = {Report on a Development Project Use of an Issue-Based Information System}
}
@article{Dowell2007,
author = {Dowell, John and Gladisch, Thomas},
journal = {Argumentation},
keywords = {a,computer mediated and,current day learning,distinct departure from the,much communication will be,much of it by,this design vision offers,visual text},
pages = {28--31},
title = {Design of Argument Diagramming for Case-Based Group Learning},
year = {2007}
}
@article{Conklin2001,
author = {Conklin, Jeff and Selvin, Albert and Shum, Simon Buckingham and Sierhuis, Maarten},
journal = {Design},
keywords = {facilitated hypertext,knowledge management},
pages = {123--124},
title = {Facilitated Hypertext for Collective Sensemaking: 15 Years on from gIBIS},
year = {2001}
}
@article{Farooq1993,
author = {Farooq, Umer and Carroll, John M and Ganoe, Craig H},
journal = {Creativity},
keywords = {collaboratory,creativity,scientific collaboration},
pages = {217--226},
title = {Supporting Creativity in Distributed Scientific Communities},
year = {1993}
}
@article{Moor2006,
author = {Moor, Aldo De and Aakhus, Mark},
journal = {Communications of the ACM},
keywords = {argumentation,thinklink},
note = {General topic of argumentation, rather than presenting specific tools.
 Gives example of forestry land use debate.
 --
 quote:Decisionexploration software is highly capable of recording,organizing, and providing access to the argumentsadvocating or refuting a particular issue, but makes itvery difficult for participants to evaluate the personalmotivations of participants.
 For instance, an IBIS allows its users to create issues, take positions on these issues, and make arguments pro and contra positions.
 
 

},
title = {Argumentation Support: From Technologies to Tools},
volume = {49},
year = {2006}
}
@inproceedings{Murphy,
author = {Murphy, Stephen},
booktitle = {Computer Documentation},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {argumentation},
note = {Time spent looking for information is a productivity hit.
 By chunking information into discrete small pieces it can be remembered longer and recalled faster.
 Arguming in favor of structured documents.
},
pages = {477--482},
title = {The Paragraph: The Weak Link in Technical Communication?}
}
@article{Fischer1989a,
author = {Fischer, Gerhard and Mccall, Raymond and Morch, Anders},
journal = {Cognitive Science},
keywords = {communication,construction kits,critics,design en-,human problem-domain,hyper-,intelligent support systems,knowledge-based systems,vironments},
pages = {269--275},
title = {Design Environments for Constructive and Argumentative Design},
year = {1989}
}
@inproceedings{Conklin1987a,
author = {Conklin, Jeff and Begeman, Michael L},
booktitle = {Hypertext},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {argumentation,thinklink},
note = {Graphical IBIS. Supports multiple users.   IBIS was developed by Horst Rittel [RIT70].   Issues, positions, arguments.   Position responds-to IssueAurgument is-suggested-by Issue Argument supports/objects-to Position Issue questions/is-suggested-by Argument Issue questions/is-suggested-by Position Issue generalizes/specializes Issue Issue replaces/questions/is-suggested-by Issue   Graph view on the left and more detailed argument on the right.    Short 5 page paper.     -- observations --   Premature segmentation problem: Unnatural to break one's thoughts into discrete units when the problem is not yet well understood. IBIS can make this problem worse due to added structure.   ThinkLink is less strict as can start by just dropping data into a topic.   Context in Non-Linear Documents; When presenting stuff in a document, you can arrange stuff in an order so that a user has the context to understand the arguments. In a graph there is a danger that you find yourself at an argument that you do not have the background to understand.   Annotative or Meta discussions: Sometimes people want to discuss the way that someone has used IBIS to create a link, rather than the argument itself.  - can raise this with a related issue   Disorientation:       -- reason Think Link isn't quite the same --   Similar basic idea.   Use topic as Issue and general category. Don't distinguish between Position and Argument.   Think Link is more like Tree Trellis - just simple pro-con.   
},
title = {gIBIS: A Hypertext Tool for Team Design Deliberation},
year = {1987}
}
@inproceedings{Conklin1988,
author = {Conklin, Jeff and Begeman, Michael L},
booktitle = {CSCW},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {argumentation,thinklink},
note = {See other gIBIS paper.
 Premature Segmentation:
 Aren't always sure what the issue is yet, or may want to rephrase the issue later.
 ThinkLink: doesn't require you to actually file stuff until later.

},
title = {glBIS: A Hypertext Tool for. Exploratory Policy Discussion},
year = {1988}
}
@article{Program1989,
author = {Program, Software Technology},
journal = {Acm Transactions On Office Information Systems},
keywords = {and phrases,issue-based information},
pages = {303--331},
title = {glBIS: A Hypertext Tool for Exploratory Policy Discussion},
volume = {6},
year = {1989}
}
@article{Ketcham1989,
author = {Ketcham, Michael G and Rajagopalan, Ramesh},
journal = {Test},
pages = {834--839},
title = {Proceedings of the 1989 Winter Simulation Conference},
year = {1989}
}
@inproceedings{Isenmann1997,
author = {Isenmann, Severin and Reuter, Wolf D},
booktitle = {Designing Interactive Systems (DIS)},
chapter = {5},
institution = {MIT Sloan School of Management},
keywords = {argumentation,argumentative problem solving,design,planning,thinklink},
note = {Used HyperIBIS - A Hypertext implementatino of IBIS.   Encountered problems: * disagreement with the discourse model as underlying theory * misdirected expectations about the objectives of the method * problems caused by methodological requirements   = Problems voiced about IBIS === Concept ==
 People objecting to the idea that argument was needed. See themselves as right. People come from different camps and are not interested in seeing the other point of view.
 People assume there is one "optimal" solution and thus no need for a discourse.
 May not see the need for a question that is being answered.
 See decisions as being made based on power structures and don't see how argumentation will help them.
 Problem when only one camp uses IBIS and their opponents don't use it to debate with them.
 People do participate in IBIS but use social pressures to affect the outcome. Use IBIS in a destructive way.
 == Incorrect Expectations ==
 Important to describe what IBIS is not. People think the tool is intelligent and will solve the problems for them.
 See it as a retreival system - but instead just a place you can put data you find yourself.
 == Method related difficulties ==
 People had little difficulty understanding an argument that was already represented inside the system.
 Much harder to correctly add information to the system.
 Have to break arguments down into atoms and connect these atoms together correctl - which people find hard.
 A question may contain more than one underlying issue - what are you rebutting? How do you arganize?
 Connections between statements might make sense when created but not when looked at later as the context is lost. Outside of a train of thought, might not appreaciate why this implies that.
 People miss out important intermediate steps that make arguments hard to understand.
 Can get a "pedantry" problem where people make the action too distanct from the original question.
 = ASSIDE: looking at solution suggestions ==
   Topic: How should we reduce traffic?   -m:linebreak/},
title = {IBIS - a Convincing Concept . . . But a Lousy Instrument?},
year = {1997}
}
@article{Mowshowitz2002,
author = {Mowshowitz, Abbe and Kawaguchi, Akira},
journal = {Communications of the ACM},
keywords = {bias on the web},
note = {Looks at which companies appear early in search engine results.
 Boring paper.
},
title = {Bias on the Web},
volume = {45},
year = {2002}
}
@article{Middleton2004,
author = {Middleton, Stuart E and Shadbolt, Nigel R and Roure, David C D E},
journal = {ACM Transactions on Information Systems},
pages = {54--88},
title = {Ontological User Profiling in Recommender Systems},
volume = {22},
year = {2004}
}
@article{Krishnamurthy2007,
author = {Krishnamurthy, Balachander},
journal = {Methodology},
pages = {52--63},
title = {Measuring Privacy Loss and the Impact of Privacy Protection in Web Browsing},
year = {2007}
}
@article{Eirinaki2003,
author = {Eirinaki, Magdalini and Vazirgiannis, Michalis},
journal = {ACM Transactions on Internet Technology},
pages = {1--27},
title = {Web Mining for Web Personalization},
volume = {3},
year = {2003}
}
@article{Grande2006,
author = {Grande, Robson Eduardo De and Zorzo, Donizetti},
journal = {Security},
pages = {89--98},
title = {Privacy Protection Without Impairing Personalization by Using the Extended System MASKS and the Extended Contextualized P3P Privacy Policies},
year = {2006}
}
@article{Holsapple2002,
author = {Holsapple, Clyde W and Joshi, K D},
journal = {Communications of the ACM},
note = {Not describing a tool.
},
publisher = {Springer},
title = {A Collaborative Approach to Ontology Design},
volume = {45},
year = {2002}
}
@article{Hayes,
author = {Hayes, Pat and Eskridge, Thomas C and Saavedra, Raul and Reichherzer, Thomas and Mehrotra, Mala and Bobrovnikoff, Dmitri},
journal = {Human Factors},
keywords = {agement,concept maps,diagrams,information retrieval,knowledge man-,ontologies},
pages = {99--106},
title = {Collaborative Knowledge Capture in Ontologies}
}
@inproceedings{Noy2006,
author = {Noy, Natalya F and Chugh, Abhita and Liu, William and Musen, Mark A},
booktitle = {ISWC},
keywords = {ontology editor},
note = {Collaborative ontology editor.

},
pages = {544--558},
publisher = {Springer},
title = {A Framework for Ontology Evolution in Collaborative Environments},
year = {2006}
}
@inproceedings{Tudorache2008,
author = {Tudorache, Tania and Noy, Natalya F and Tu, Samson and Musen, Mark A},
booktitle = {ISWC},
keywords = {ontology editor},
note = {Collaborative Ontology Editor.
},
pages = {17--32},
publisher = {Springer},
title = {Supporting Collaborative Ontology Development in Protege},
volume = {22},
year = {2008}
}
@article{Raeder1985,
author = {Raeder, Georg},
journal = {IEEE Xplore},
keywords = {end user programming},
note = {
},
title = {A Survey of Current Graphical Programming Techniques},
year = {1985}
}
@article{Programming,
author = {Programming, The End-user},
journal = {Most},
title = {Programming Agents Without a Programming Language}
}
@article{Drucker2006,
author = {Drucker, Steven M and Petschnigg, Georg and Research, Microsoft and Way, One Microsoft},
keywords = {alignment,correspondence,distance metrics,slide presentations,versions},
pages = {47--56},
title = {Comparing and Managing Multiple Versions of Slide Presentations},
year = {2006}
}
@article{Hansen1978,
author = {Hansen, Brinch},
journal = {Computing Surveys},
keywords = {0,3,4,69,80,and phrases interactive programming,cr categortes,lisp,program,programming methods,programming systems,structure},
title = {Programming in an Interactive Environment: the "LISP" Experience},
volume = {10},
year = {1978}
}
@article{Chitu2007,
author = {Chitu, Alex},
journal = {Google System Blog},
title = {Google Gadgets that Talk to Each Other},
year = {2007}
}
@article{Eugster2003,
author = {Eugster, Patrick T H and Felber, Pascal A and Guerraoui, Rachid and Kermarrec, Anne-Marie},
chapter = {5},
journal = {ACM Computing Surveys},
keywords = {survey},
note = {Subscribers register their interest in an event or a pattern of events are are notified of events generated by publishers.
Relates to the widget model of Mash Maker in which widgets publish and subscribe.
Similar to Shared Spaces - are created by Linda.Differs from publish-subscribe since it is synchronous - actions can synchronously remove things.
Relates to Rendezvous.

},
pages = {114--131},
title = {The Many Faces of Publish/Subscribe},
volume = {35},
year = {2003}
}
@article{Abstract2005,
author = {Abstract, Extended},
journal = {Telecommunication Systems},
keywords = {adaptivity,publish,self-orga-,self-stabilization,subscribe},
pages = {2--6},
title = {Self-Organizing Publish/Subscribe},
year = {2005}
}
@article{Gelernter,
author = {Gelernter, David},
journal = {Science},
title = {Applications Experience with Linda}
}
@inproceedings{Lam1991,
author = {Lam, S and Rinard, C},
booktitle = {PPPP},
chapter = {5},
pages = {94--105},
title = {Course Grain Parallel Programming in Jade},
volume = {3},
year = {1991}
}
@article{Brandenbwg,
author = {Brandenbwg, Jeff and Byerly, Boyce and Dobridge, Tom and Rajan, Dharmaraja and Roscoe, Timothy and I.t., Persimmon},
title = {Artefact: A Frameworkfor Low-Overhead Web-Based CollaborativeSystems}
}
@inproceedings{Feiner1991,
author = {Feiner, Steven and Shamash, Ari},
booktitle = {UIST},
chapter = {5},
pages = {9--17},
title = {Hybrid User Interfaces: Breeding Virtually Bigger Interfaces for Physically Smaller Computers},
year = {1991}
}
@article{Banatre1993,
author = {Banatre, Jean-Pierre and Metayer, Daniel Le},
journal = {Communications of the ACM},
title = {Programming by Multiset Transformation},
volume = {36},
year = {1993}
}
@article{Feiner,
author = {Feiner, Steven},
journal = {Network},
keywords = {distributed,distributed virtual environments,shared memory,shared-data object model,virtual reality},
pages = {83--94},
title = {Language-Level Support for Exploratory Programming Distributed Virtual Environments}
}
@article{Berry1990,
author = {Berry, Gerard and Boudol, Gerard},
chapter = {5},
journal = {POPL},
title = {The Chemical Abstract  Machine},
year = {1990}
}
@article{Bellur2006,
author = {Bellur, Umesh and Bondre, Siddharth},
journal = {Management},
pages = {23--27},
title = {xSpace – A Tuple Space for XML & its application in Orchestration of Web services},
year = {2006}
}
@article{Nurmi,
author = {Nurmi, Petteri and Liu, Tianyan and Oikarinen, Tiina-kaisa and Vetek, Akos},
journal = {Human Factors},
keywords = {adaptive user interfaces,mobile usability,mobile widgets},
pages = {327--330},
title = {Capricorn - An Intelligent User Interface for Mobile Widgets}
}
@article{Tuchinda2008,
author = {Tuchinda, Rattapoom and Szekely, Pedro and Knoblock, Craig A},
chapter = {5},
journal = {IUI},
keywords = {mashups},
note = {Tool called Karma.   Existing work uses widgets, but hard if mashup is complex, and finding correct widget can be hard.   43 widgets for Pipes, 300+ for Popfly.   Relevant for discussion of my copy-and-paste stuff - programming by demonstration.   Copy-paste style mashups. Retreive data, describe structure, clean it, determine join conditions.   Learns from previous data to work out how to model data sources.   Use constraints and programming-by-demonstration to work out how to join.

Wrongly describes what Mash Maker can do - can guess data integration as well as use expert-specified.


},
pages = {139--148},
title = {Building Mashups By Example},
year = {2008}
}
@article{Leshed2008,
author = {Leshed, Gilly and Haber, Eben M and Matthews, Tara and Lau, Tessa and Science, Information and Jose, San},
journal = {Tara},
pages = {1719--1728},
title = {CoScripter: Automating & Sharing How-To Knowledge in the Enterprise},
year = {2008}
}
@inproceedings{Iwazume2008,
author = {Iwazume, Michiaki and Kaneiwa, Ken and Zettsu, Koji and Nakanishi, Takafumi and Kidawara, Yutaka and Kiyoki, Yasushi},
booktitle = {WWW},
chapter = {5},
keywords = {mashups},
note = {Not clear they have done that much. Just a poster.
},
pages = {1209--1210},
title = {KC3 Browser: Semantic Mash-up and Link-free Browsing},
year = {2008}
}
@inproceedings{Wong2008,
author = {Wong, Jeffrey and Hong, Jason},
booktitle = {WEUSE},
chapter = {5},
keywords = {mashups,patterns,taxonomy},
note = {Qualitative study of high-quality mashups on the web.
Examined how mashups made use of existing mashups or improved on them, and how data from different web sites was combined.


},
pages = {35--39},
title = {What Do We "Mashup" When We Make Mashups?},
year = {2008}
}
@article{Reis,
author = {Reis, Charles and Dunagan, John and Wang, Helen J and Dubrovsky, Opher and Esmeir, Saher},
journal = {Symposium A Quarterly Journal In Modern Foreign Literatures},
pages = {61--74},
title = {BrowserShield: Vulnerability-Driven Filtering of Dynamic HTML}
}
@article{Riehle2006,
author = {Riehle, Dirk},
journal = {Computers and Society},
keywords = {collaboration,collaboration processes,collective intelligence,cscw,software,wiki,wikimedia foundation,wikipedia},
pages = {3--8},
title = {How and Why Wikipedia Works: An Interview with Angela Beesley, Elisabeth Bauer, and Kizu Naoko},
year = {2006}
}
@article{Tseng1999,
author = {Tseng, Shawn and Fogg, B J},
chapter = {5},
journal = {Communications of the ACM},
pages = {39--44},
publisher = {Morgan Kaufmann},
title = {Credibility and Computing Technology},
volume = {42},
year = {1999}
}
@article{Bauhs1994,
author = {Bauhs, Jeff A and Cooke, Nancy J},
journal = {Psychology},
keywords = {expert systems,trust in machines},
pages = {99--100},
title = {Is Knowing More Really Better’? Effects of System Development Information Human-Expert System Interacticms},
year = {1994}
}
@article{Lopes2008,
author = {Lopes, Rui and Carrico, Luis},
chapter = {5},
journal = {WICOW},
note = {Credibility of wikipedia pages suffers if the references are not easily accessible.

},
pages = {27--34},
publisher = {Morgan Kaufmann},
title = {On the Credibility of Wikipedia: an Accessibility Perspective},
year = {2008}
}
@article{Vrandecic2006,
author = {Vrandecic, Denny and Haller, Heiko and Studer, Rudi},
journal = {New York},
keywords = {rdf,semantic web,wiki,wikipedia},
pages = {585--594},
title = {Semantic Wikipedia},
year = {2006}
}
@article{Lab1999,
author = {Lab, Persuasive Technology and Hall, Cordura},
journal = {Context},
keywords = {as believability,credibility,credibility can be defined,credible people are believable,people,simply put,what is},
pages = {80--87},
title = {The Elements of Computer Credibility},
year = {1999}
}
@article{Raubal,
author = {Raubal, Martin and Barbara, Santa and States, United and Marsh, Meredith},
journal = {Computational Linguistics},
title = {Improving Interaction with Virtual Globes through Spatial Thinking: Helping Users Ask “Why?”}
}
@article{Louridas,
author = {Louridas, Panagiotis},
title = {the collaborative organization of Knowledge}
}
@article{Nov2007,
author = {Nov, Oded},
chapter = {5},
journal = {Communications of the ACM},
publisher = {Morgan Kaufmann},
title = {What Motivates Wikipedians},
volume = {50},
year = {2007}
}
@article{Heer2005,
author = {Heer, Jeffrey and Division, Computer Science},
journal = {Information Visualization},
keywords = {2,5,acm classification keywords,d,design tools and,h,information interfaces,software engineering,techniques,user},
pages = {421--430},
title = {prefuse: A Toolkit for Interactive Information Visualization},
year = {2005}
}
@article{Resnick2005,
author = {Resnick, Paul and Hansen, Derek and Riedl, John and Terveen, Loren and Ackerman, Mark},
journal = {Engineering},
keywords = {asynchronous communication,computer-mediated,information systems,online discussion,system design},
pages = {2138--2139},
title = {Beyond Threaded Conversation},
year = {2005}
}
@article{Agrawal1981,
author = {Agrawal, Rakesh and Rajagopalan, Sridhar and Srikant, Ramakrishnan and Xu, Yirong},
journal = {Network},
keywords = {data mining,group,link analysis,news-,social network,text mining,web mining},
title = {Mining Newsgroups Using Networks Arising From Social Behavior},
year = {1981}
}
@article{Wu2008,
author = {Wu, Fei and Hoffmann, Raphael and Weld, Daniel S},
journal = {Language},
keywords = {information extraction,semantic web,wikipedia},
pages = {731--739},
title = {Information Extraction from Wikipedia: Moving Down the Long Tail},
year = {2008}
}
@article{Wu2007,
author = {Wu, Fei and Weld, Daniel S},
journal = {Architecture},
keywords = {information extraction,semantic web,wikipedia},
pages = {41--50},
title = {Autonomously Semantifying Wikipedia},
year = {2007}
}
@article{Suchanek2007,
author = {Suchanek, Fabian M and Kasneci, Gjergji and Weikum, Gerhard},
journal = {Structure},
pages = {697--706},
title = {YAGO: A Core of Semantic Knowledge Unifying WordNet and Wikipedia},
year = {2007}
}
@article{Milne2007,
author = {Milne, David and Witten, Ian H and Nichols, David M},
journal = {Information Retrieval},
keywords = {data,information retrieval,query expansion,wikipedia},
pages = {445--454},
title = {A Knowledge-Based Search Engine Powered by Wikipedia},
year = {2007}
}
@inproceedings{Cimiano2004,
author = {Cimiano, Philipp and Handschuh, Siegfried and Staab, Steffen},
booktitle = {WWW},
chapter = {5},
keywords = {information extraction,metadata,semantic,semantic annotation,semantic web},
note = {Unsupervised pattern-based approach to categorize instances on the web with respect to an ontology.
 

},
pages = {462--471},
title = {Towards the Self-Annotating Web},
year = {2004}
}
@article{Cheng2005,
author = {Cheng, Alice and Friedman, Eric},
journal = {Industrial Engineering},
keywords = {peer-to-peer,reputation,sybils},
pages = {128--132},
title = {Sybilproof Reputation Mechanisms},
year = {2005}
}
@article{Kekiil,
author = {Kekiil, Jaana and Fin-, Information Studies and Emaih, Tampere Finland},
journal = {Science},
pages = {41--48},
title = {IR evaluation methods for retrieving highly relevant documents}
}
@article{Hu2007,
author = {Hu, Meiqun and Lim, Ee-Peng and Sun, Aixin and Lauw, Hady W and Vuong, Ba-Quy},
chapter = {5},
journal = {CIKM},
keywords = {article quality,author-,collaborative authoring,trust,wikipedia},
note = {Measure article quality in Wikipedia.
 Several methods:
 BASIC: mutual dependency between article quality and author authority.
 PEER REVIEW: Introduces review behaviour into the metric.
 PROBREVIEW: Looks at partial reviewership.
},
pages = {243--252},
title = {Measuring Article Quality in Wikipedia: Models and Evaluation},
year = {2007}
}
@article{Cosley2006,
author = {Cosley, Dan and Frankowski, Dan and Terveen, Loren and Riedl, John},
journal = {Organization},
pages = {1037--1046},
title = {Using Intelligent Task Routing and Contribution Review to Help Communities Build Artifacts of Lasting Value},
year = {2006}
}
@article{Erickson2002,
author = {Erickson, Thomas and Halverson, Christine and Kellogg, Wendy A and Laff, Mark and Wolf, Tracee},
chapter = {5},
journal = {Communications of the ACM},
note = {Allow more social awareness in online applications.
 Example of door which has window to stop you slamming it into someone. Or speaker who can see when listeners are getting bored and fidgeting.
 Provide clues about the presence and activity of others in the current conversation.
 See crowd gathering and dispersing.
 Online visualization of a queue for talking to someone.
 

},
title = {Social translucence: Designing Social Infrastructures that make collection activity visible},
volume = {45},
year = {2002}
}
@article{Waters2007,
author = {Waters, Neil L},
chapter = {5},
journal = {Communications of the ACM},
note = {Editing system risks conflating fact with popular opinion.
Cites cases where Wikipedia contained erroneous information.
Errors are a problem.
},
pages = {15--17},
publisher = {Morgan Kaufmann},
title = {Why You Can’t Cite Wikipedia in My Class},
volume = {50},
year = {2007}
}
@article{Shneiderman2000a,
author = {Shneiderman, Ben},
journal = {Communications of the ACM},
pages = {57--59},
title = {Online Experiences},
volume = {43},
year = {2000}
}
@article{Fogg2003,
author = {Fogg, B J and Lab, Persuasive Technology and Hall, Cordura and Soohoo, Cathy and Danielson, David R and Tauber, Ellen R and Design, Sliced Bread and View, Mountain and Stanford, Julianne and Marable, Leslie and Webwatch, Consumer},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {captology,credibility,design,information,online trust,thinklink,trustworthiness,web site,world wide web},
note = {
},
pages = {1--15},
title = {How Do Users Evaluate the Credibility of Web Sites? A Study with Over 2,500 Participants},
year = {2003}
}
@article{Denning2005,
author = {Denning, Peter and Horning, Jim and Parnas, David and Weinstein, Lauren},
chapter = {5},
journal = {Communications of the ACM},
note = {Wikipedia may not be a reliable source of information.
Risks in using it at a source of knowledge.


},
title = {Wikipedia Risks},
year = {2005}
}
@article{Kittur2008,
author = {Kittur, Aniket and Kraut, Robert E},
chapter = {5},
journal = {CSCW},
note = {Looks at the coordination methods used between wikipedia editors.
},
pages = {37--46},
publisher = {Morgan Kaufmann},
title = {Harnessing the Wisdom of Crowds in Wikipedia: Quality Through Coordination},
year = {2008}
}
@article{Wilkinson2007,
author = {Wilkinson, Dennis and Huberman, Bernardo},
journal = {Distribution},
keywords = {cooperation,wikipedia},
note = {High quality articles have more edits, more editors, and more cooperative behaviour.
Edits beget edits. Topics of high interest attain high quality.
Studied all 50 million edits.
},
pages = {157--163},
title = {Cooperation and Quality in Wikipedia},
year = {2007}
}
@article{Lampe2007,
author = {Lampe, Cliff and Lansing, East},
journal = {Communication Arts},
pages = {1253--1262},
title = {Follow the Reader: Filtering Comments on Slashdot},
year = {2007}
}
@article{Bryant2005,
author = {Bryant, Susan L and Forte, Andrea and Bruckman, Amy},
journal = {Human Factors},
keywords = {1,1 what is wikipedia,activity theory,community,legitimate peripheral,participation,wiki,wikipedia},
pages = {1--10},
title = {Becoming Wikipedian: Transformation of Participation in a Collaborative Online Encyclopedia},
year = {2005}
}
@inproceedings{Kittur2007,
author = {Kittur, Aniket and Suh, Bongwon and Pendleton, Bryan A and Chi, Ed H},
booktitle = {CHI},
pages = {453--462},
title = {He Says, She Says: Conflict and Coordination in Wikipedia +},
year = {2007}
}
@inproceedings{Kriplean2007,
author = {Kriplean, Travis and Beschastnikh, Ivan and McDonald, David W and Golder, Scott A},
booktitle = {GROUP},
keywords = {collaborative authoring,community,policy,power,wikipedia},
pages = {167--176},
title = {Community, Consensus, Coercion, Control: CS*W or How Policy Mediates Mass Participation},
year = {2007}
}
@article{Pentzold2006,
author = {Pentzold, Christian and Seidenglanz, Sebastian},
journal = {Policy},
pages = {59--68},
title = {Christian Pentzold, Sebastian Seidenglanz},
year = {2006}
}
@inproceedings{Wu2008a,
author = {Wu, Fei and Weld, Daniel S},
booktitle = {WWW},
keywords = {35,accu-,algorithms on the infobox,data,example,markov logic networks,ontology,our autonomous kylin system,semantic web,trained machine-learning,wikipedia,yielding extractors which can},
pages = {635--644},
title = {Automatically Refining the Wikipedia Infobox Ontology},
year = {2008}
}
@article{Chatterjee2008a,
author = {Chatterjee, Krishnendu and Alfaro, Luca De and Pye, Ian},
keywords = {reputation,user-generated content,wikipedia},
pages = {33--42},
title = {Robust Content-Driven Reputation ∗},
year = {2008}
}
@article{Vuong2008,
author = {Vuong, Ba-Quy and Lim, Ee-Peng and Sun, Aixin and Le, Minh-tam and Lauw, Hady Wirawan and Chang, Kuiyu},
journal = {Computer Engineering},
keywords = {0031,controversy rank,d,in part by a,online dispute,project number 062 101,r,star public sector,the work was supported,wikipedia},
title = {On Ranking Controversies in Wikipedia: Models and Evaluation ∗},
year = {2008}
}
@article{Priedhorsky2007,
author = {Priedhorsky, Reid and Chen, Jilin and Panciera, Katherine and Terveen, Loren and Riedl, John},
chapter = {5},
journal = {GROUP},
keywords = {collaboration,damage,vandalism,wiki,wikipedia},
note = {Overwhelming majority of viewed words are written by frequent editors and that this majority is increasing.
Probability of a typical article being damaged is small but increasing.

},
pages = {259--268},
publisher = {Morgan Kaufmann},
title = {Creating, Destroying, and Restoring Value in Wikipedia},
year = {2007}
}
@article{Suh2008,
author = {Suh, Bongwon and Chi, Ed H and Kittur, Aniket and Pendleton, Bryan A and Alto, Palo},
pages = {1037--1040},
title = {Lifting the Veil: Improving Accountability and Social Transparency in Wikipedia with WikiDashboard},
year = {2008}
}
@article{Staddon2008,
author = {Staddon, Jessica and Chow, Richard},
journal = {Security},
keywords = {association rule mining,bias,reputation,trust},
pages = {5--9},
title = {Detecting Reviewer Bias through Web-Based Association Mining},
year = {2008}
}
@article{Priedhorsky2008,
author = {Priedhorsky, Reid and Terveen, Loren and Research, Grouplens},
pages = {267--276},
title = {The Computational Geowiki: What, Why, and How},
year = {2008}
}
@article{Kittur2008a,
author = {Kittur, Aniket and Suh, Bongwon and Chi, Ed H},
chapter = {5},
journal = {CSCW},
note = {Examine effect of edit history visualization on people's trust of data in a wiki.
},
pages = {477--480},
publisher = {Morgan Kaufmann},
title = {Can You Ever Trust a Wiki? Impacting Perceived Trustworthiness in Wikipedia },
year = {2008}
}
@article{Resnick2000,
author = {Resnick, Paul and Zeckhauser, Richard and Friedman, Eric and Kuwabara, Ko},
chapter = {5},
journal = {Communications of the ACM},
pages = {45--48},
publisher = {Morgan Kaufmann},
title = {Reputation Systems},
volume = {43},
year = {2000}
}
@article{Guha2004,
author = {Guha, R and Kumar, Ravi and Raghavan, Prabhakar and Tomkins, Andrew},
journal = {New York},
keywords = {and sometimes disinformation,distrust,information,motivation to spread,there is growing economic,through the,to the web,trust propagation,web of trust},
pages = {403--412},
title = {Propagation of Trust and Distrust},
year = {2004}
}
@inproceedings{Viegas2004,
author = {Viegas, Fernanda B and Wattenberg, Martin and Kushal, Dave},
booktitle = {CHI},
pages = {575--582},
title = {Studying Cooperation and Conflict between Authors with History Flow Visualizations},
volume = {6},
year = {2004}
}
@article{Sabel,
author = {Sabel, Mikalai},
chapter = {5},
journal = {WikiSym},
keywords = {algorithms,design,experimentation,revision history,wiki,wikipedia},
note = {Visualize edit history as a tree of versions.
},
pages = {125--129},
publisher = {Morgan Kaufmann},
title = {Structuring Wiki Revision History }
}
@article{Bloch2006,
author = {Bloch, Joshua},
chapter = {5},
journal = {OOPSLA},
note = {API should be self-documenting.
Find requirements and use cases before specifying the API.
Early draft of the API should be one page - keep it simple.
Code the uses cases against the API before you implement it. Use these as examples in the future.
Show the design to as many people as you can.
Names matter - if you can't find good names, the model may be wrong.
Minimizing "conceptual weight" is essential.
Keep things immutable when possible.
Make functions private when possible - if only you need it, only you should have it.
Don't over-subclass.
Don't make the client do anything the library could do.

Only use the same name for something if it really is the same.


},
pages = {506--507},
publisher = {Morgan Kaufmann},
title = {How to Design a Good API and Why it Matters},
year = {2006}
}
@article{Elson,
author = {Elson, Jeremy and Howell, Jon and Douceur, John R and Redmond, Microsoft Research},
journal = {Earth},
keywords = {approximate reprojection,composition,decentralized publishing,geographic coordinate,graphical interactive georeferencing,image tiling,interactive maps,map projections,mashups,systems},
pages = {50--59},
title = {MapCruncher: Integrating the World’s Geographic Information}
}
@article{Sabbouh2007,
author = {Sabbouh, Marwan and Higginson, Jeff and Semy, Salim and Gagne, Danny},
pages = {1305--1306},
title = {Web Mashup Scripting Language},
year = {2007}
}
@article{Zang2008,
author = {Zang, Nan and Rosson, Mary Beth and Nasser, Vincent},
journal = {Methods},
keywords = {data manipulation,design,end-user programming},
pages = {3171--3176},
title = {Mashups: Who? What? Why?},
year = {2008}
}
@article{Ennals,
author = {Ennals, Rob and Garofalakis, Minos},
journal = {Sigmod Record},
keywords = {end-users,mashup,web},
pages = {1116--1118},
title = {MashMaker: Mashups for the Masses}
}
@article{Karlof2007,
author = {Karlof, Chris and Tygar, J D and Wagner, David and Shankar, Umesh},
journal = {New York},
pages = {58--71},
title = {Dynamic Pharming Attacks and Locked Same-origin Policies for Web Browsers},
year = {2007}
}
@article{Hardy,
author = {Hardy, Norm},
pages = {36--38},
title = {The Confused Deputy}
}
@article{Martin2005,
author = {Martin, Michael and Livshits, Benjamin and Lam, Monica S},
journal = {Organization},
keywords = {bug nding,pattern matching,program traces,resource leaks,sql injection,web applications},
pages = {365--383},
title = {Finding Application Errors and Security Flaws Using PQL: a Program Query Language},
year = {2005}
}
@article{Lam2006,
author = {Lam, V T and Antonatos, S and Akritidis, P and Anagnostakis, K G},
chapter = {5},
journal = {CCS},
keywords = {distributed attacks,malicious software,security,web security},
note = {Attackers can create effective DoS by putting malicious scripts on code on web sites.
},
pages = {221--234},
title = {Puppetnets: Misusing Web Browsers as a Distributed Attack Infrastructure},
year = {2006}
}
@article{Dhamija2006,
author = {Dhamija, Rachna},
journal = {Knowledge Creation Diffusion Utilization},
pages = {581--590},
title = {Why Phishing Works},
year = {2006}
}
@article{Hunt,
author = {Hunt, Galen C and Larus, James R},
journal = {Contract},
keywords = {hardware,operating systems,program,program specification,safe programming languages,sealed kernel,sealed process architecture,sips,software-isolated processes,verification},
title = {Singularity: Rethinking the Software Stack}
}
@article{Wang2007,
author = {Wang, Helen J and Fan, Xiaofeng and Howell, Jon and Jackson, Collin},
chapter = {5},
journal = {SOSP},
keywords = {abstractions,browser,communications,curity,multi-principal os,protection,same-origin policy,se-,web},
note = {Allow limited-trust communication between different domains on a web page.
},
pages = {1--15},
title = {Protection and Communication Abstractions for Web Browsers in MashupOS},
year = {2007}
}
@inproceedings{Abiteboul2008,
author = {Abiteboul, Serge and Greenshpan, Ohad and Milo, Tova},
booktitle = {WIDM},
keywords = {data,information,integration,mashups,model,web},
note = {Defines concept of a mashlet.
A mashlet can serve as a component in a more complex mashlet.
Write mashlet in datalog.
Mashlet can query data sources, import other mashlets, and use external web services.
Describe a mashlet in terms of inputs, outputs, mashlets, mashletAPIs and rules.
Mashlet can be visible or invisible.
Inputs of one mashlet can be connected to another.
},
pages = {87--94},
title = {Modeling the Mashup Space},
year = {2008}
}
@article{Crites,
author = {Crites, Steven and Hsu, Francis and Chen, Hao},
journal = {Access},
keywords = {browser,communication,mashup,object abstraction,pro-,same origin policy,security model,tection,web},
pages = {99--107},
title = {OMash: Enabling Secure Web Mashups via Object Abstractions}
}
@article{Livshits2007,
author = {Livshits, Benjamin},
journal = {Context},
keywords = {code injection attacks,same-origin policy,software construction frame-,software security,works},
pages = {95--103},
title = {Using Web Application Construction Frameworks to Protect Against Code Injection Attacks ´},
year = {2007}
}
@article{Somayaji,
author = {Somayaji, Terri Oda Glenn Wurster P C Van Oorschot Anil},
journal = {Security},
keywords = {cross-site request forgery,cross-site scripting,javascript,same origin policy,web security,xsrf,xss},
pages = {89--98},
title = {SOMA: Mutual Approval for Included Content in Web Pages}
}
@inproceedings{Keukelaere2008,
author = {Keukelaere, Frederik De and Bhola, Sumeer and Steiner, Michael and Chari, Suresh and Yoshihama, Sachiko},
booktitle = {WWW},
chapter = {5},
keywords = {browser,component model,mashup,mashups,web 2},
note = {Secure communication abstraction between untrusted components.
Implementation for unmodified browsers.
Component isolation using iframes.Component-mashup communication links.
Add restriction - one frame can't change location of another.
Changing another frame's location can be used for phishing.

Implemented as a javascript library.
Pluggable inter-frame communication library.

Communication mechanism using Java applets.Different pages load instances of the same applet. These applets are then able to talk to each other.

Relates to GooglePubSub.
},
pages = {535--544},
title = {SMash: Secure Component Model for Cross-Domain Mashups on Unmodi ed Browsers},
year = {2008}
}
@article{Guo2008,
author = {Guo, Rui and Zhu, Bin B and Feng, Min and Pan, Aimin and Zhou, Bosheng},
journal = {Communications},
keywords = {browser,component,delayed-binding,encapsulation,interface,isolation,mashup,protection,reuse,same-origin policy,security,web},
pages = {545--554},
title = {CompoWeb: A Component-Oriented Web Architecture},
year = {2008}
}
@article{Jackson2007,
author = {Jackson, Collin and Wang, Helen J},
journal = {Current Practice},
keywords = {access control,same origin policy,trust,web services},
pages = {611--619},
title = {Subspace: Secure Cross-Domain Communication for Web Mashups},
year = {2007}
}
@article{Jackson2006,
author = {Jackson, Collin and Bortz, Andrew and Boneh, Dan and Mitchell, John C},
journal = {Human Factors},
pages = {737--744},
title = {Protecting Browser State from Web Privacy Attacks},
year = {2006}
}
@article{Chang2001,
author = {Chang, Chia-Hui and Lui, Shao-chen},
journal = {WWW},
keywords = {extraction rule,information extraction,multiple string,wrappers},
note = {Automatic wrapper creation without human guidance
},
pages = {681--688},
title = {IEPAD: Information Extraction Based on Pattern Discovery},
year = {2001}
}
@article{Louca2003,
author = {Louca, Loucas and Center, Science Teaching},
journal = {Common Knowledge},
pages = {129--130},
title = {Programming Environments for Young Learners: A Comparison of Their Characteristics and Students’ Use},
year = {2003}
}
@article{Kelleher2007,
author = {Kelleher, Caitlin and Pausch, Randy and Kiesler, Sara},
journal = {Forbes},
pages = {1455--1464},
title = {Storytelling Alice Motivates Middle School Girls to Learn Computer Programming},
year = {2007}
}
@inproceedings{Bannon1983,
author = {Bannon, Liam and Cypher, Allen and Greenspan, Steven and Monty, Melissa L and Diego, San},
booktitle = {CHI},
pages = {54--57},
title = {Evaluation and Analysis of Users' Activity Organizaton},
year = {1983}
}
@article{Stelzner1988,
author = {Stelzner, Marilyn and Cypher, Allen},
journal = {SIGCHI Bulletin},
title = {Graphical Knowledge-Based Structure Editors},
volume = {20},
year = {1988}
}
@article{Myers,
author = {Myers, Brad A and Cypher, Allen and Maulsby, David and Smith, David C and Shneiderman, Ben},
pages = {393--396},
title = {Demonstrational Interfaces: coming soon?}
}
@article{Creativity1995a,
author = {Creativity, O F},
journal = {Creativity},
keywords = {end user programming,gramming by demonstration,graphical rewrite rules,pro-,simulations},
pages = {35--36},
title = {Kidsim: end user programming of simulations},
year = {1995}
}
@article{Smith1996,
author = {Smith, David Canfield and Cypher, Allen and Schmucker, Kurt},
journal = {Interactions},
title = {Making Programming Easier for Children},
year = {1996}
}
@article{Druin1999,
author = {Druin, Allison and Friedman, Batya},
journal = {Human-Computer Interaction},
keywords = {children,education,entertainment,ethics,social actors},
pages = {91--92},
title = {Is ActiMates Barney Ethical? The Potential Good, Bad, and Ugly of Interactive Plush Toys},
year = {1999}
}
@article{Smith2000,
author = {Smith, David Canfield and Cypher, Allen and Tesler, Larry},
journal = {Communications of the ACM},
pages = {75--81},
title = {Novice Programming Comes of Age},
volume = {43},
year = {2000}
}
@article{Souza2008,
author = {Souza, Clarisse Sieckenius De and Cypher, Allen},
journal = {Cognitive Science},
keywords = {end user programming,graphical user interface design,methodology,semiotic engineering,ui design},
pages = {165--172},
title = {Semiotic Engineering in Practice: Redesigning the CoScripter Interface},
year = {2008}
}
@article{Zhao2005,
author = {Zhao, Haixia and Kandogan, Eser and Haber, Eben and Barrett, Rob and Cypher, Allen and Maglio, Paul and Jose, San},
journal = {System},
keywords = {faces,spreadsheets,system management,web-portal user inter-},
title = {A1: End-User Programming for Web-based System Administration},
year = {2005}
}
@article{Levoy1994,
author = {Levoy, Marc},
title = {Spreadsheets for Images},
year = {1994}
}
@inproceedings{Koelma1992,
author = {Koelma, Dennis and Van Balen, Richard and Smeulders, Arnold},
booktitle = {Applied Computing},
chapter = {5},
keywords = {end user programming},
note = {Data flow graphs - like Fabrik.
Mix of visual and textual programming.
Use text when best suited, visual where that works best.
No control structures in visual mode - just in the text mode.
Uses C as textual language.


},
pages = {1188--1198},
title = {SCIL-VP: A multi-purpose visual programming environment},
year = {1992}
}
@article{Hils1991,
author = {Hils, Daniel D},
journal = {Info},
keywords = {end user programming,visual dataflow},
note = {Use visual dataflow model for scientific computing.
Looks awkward to use.
},
pages = {439--448},
title = {DataVis: A Visual Programming Language For Scientific Visualization},
year = {1991}
}
@article{Studio1990,
author = {Studio, The Human Computer Interaction Design},
journal = {Machinery},
pages = {201--207},
title = {IShell: A Visual UNlX Shell},
year = {1990}
}
@article{Zloof,
author = {Zloof, Moshe M},
keywords = {end user programming},
note = {Addresses the problems.
Lists areas where better abstractions are needed:  Database  GUI  Language

},
pages = {30--35},
title = {Selected Ingredients in End-User Programming}
}
@article{Elliott2007,
author = {Elliott, Conal M},
journal = {October},
keywords = {arrows,combinator libraries,end-user programming,ges-,interactive programming,interactive visual-,tural composition},
pages = {59--70},
title = {Tangible Functional Programming},
year = {2007}
}
@article{Hanna,
author = {Hanna, Keith},
journal = {Human Factors},
keywords = {edit,functional,haskell,interactive,live,stylesheet,visual},
pages = {145--156},
title = {Interactive Visual Functional Programming}
}
@inproceedings{Edwards2004,
author = {Edwards, Jonathan},
booktitle = {OOPSLA},
pages = {58113--58113},
title = {Example Centric Programming},
year = {2004}
}
@article{Hashimoto1992,
author = {Hashimoto, Osamu},
journal = {Main},
keywords = {agement system,demonstrational interfaces,direct manipulation,garnet,inferencing,styles,tabs,user ihterface man-,user interface builder},
pages = {117--124},
title = {Graphical Styles for Building User by Demonstration},
year = {1992}
}
@article{Cardelli,
author = {Cardelli, Luca},
journal = {Systems Research},
pages = {152--166},
title = {Building User Interfaces Direct Manipulation}
}
@inproceedings{Ungar1987,
author = {Ungar, David and Smith, Randall B},
booktitle = {OOPSLA},
chapter = {5},
keywords = {programming languages},
note = {Presents the Self programming language.
 Simplified version of Smalltalk. Has no classes or variables. Instead uses prototypes for everything.
 All variables are dealt with using messages to "self".
},
pages = {227--242},
title = {Self: The Power of Simplicity},
year = {1987}
}
@article{Techniques1981,
author = {Techniques, Programming and Structures, Data and Mcllroy, M Douglas and Teitelbaum, Tim and Reps, Thomas},
journal = {Communications of the ACM},
keywords = {and phrases,diagnostic interpreter,program development system,programming environment,source language debug-,syntax-directed editor,template},
title = {The Cornell Program Synthesizer: A Synt.ax- Directed Programming Environment},
volume = {24},
year = {1981}
}
@article{Isn1995,
author = {Isn, Why Looking and Seeing, Always},
journal = {Communications of the ACM},
pages = {33--44},
title = {Readership Skills and Graphical Programming},
volume = {38},
year = {1995}
}
@article{Maloney1995,
author = {Maloney, John H and Computer, Apple and Smith, Randall B and Microsystems, Sun},
journal = {World},
keywords = {user interface frameworks},
pages = {21--28},
title = {Directness and Liveness in the Morphic User Interface Construction Environment},
year = {1995}
}
@inproceedings{Ingaiis1988,
author = {Ingaiis, Dan},
booktitle = {OOPSLA},
chapter = {5},
keywords = {end user programming},
note = {Visual programming language.
Graphically wire components together.
Program is "live" - updates happen immediately.Pins can be bi-directional.
Use to create graphics.
Can have "gateway" pins for input and output for the module.
Simple type checking to make sure things are wired properly.


},
title = {Fabrik A Visual Programming Environment},
year = {1988}
}
@article{Elliott1997,
author = {Elliott, Conal and Research, Microsoft and Group, Graphics and Hudak, Paul},
journal = {Time},
pages = {263--273},
title = {Reactive Animation},
year = {1997}
}
@article{Edwards2005,
author = {Edwards, Jonathan},
journal = {Human Factors},
pages = {505--518},
title = {Subtext: Uncovering the Simplicity of Programming},
year = {2005}
}
@article{Caspi1987,
author = {Caspi, P and Pilaud, D and Plaice, J A and Halbwachs, N},
journal = {Lustre},
pages = {178--188},
title = {LUSTRE: A declarative language for programming synchronous systems*},
year = {1987}
}
@article{Millar2004,
author = {Millar, Richard J},
journal = {ACM Computing Surveys},
pages = {1--34},
title = {Advances in Data ow Programming Languages},
volume = {36},
year = {2004}
}
@article{Leff2007,
author = {Leff, Avraham},
journal = {Language},
keywords = {about a product in,an ecom-,applications,data- ow languagesr,each row shows information,ming languages,relational web-,visual program-,web relational blocks,web-application development,webrb},
pages = {281--300},
title = {WebRB: Evaluating a Visual Domain-Speci c Language For Building Relational Web-Applications},
year = {2007}
}
@article{Pietriga2001,
author = {Pietriga, Emmanuel and Vion-dury, Jean-yves and Quint, Vincent},
journal = {Language},
keywords = {circus,visual programming languages,xml transformations,xslt,zoomable user interfaces},
title = {VXT: A Visual Approach to XML Transformations},
year = {2001}
}
@inproceedings{Mcdirmid,
author = {Mcdirmid, Sean},
booktitle = {OOPSLA},
chapter = {5},
keywords = {end user programming},
note = {Language called SuperGlue - textual live language.
Live languages provide continuous feedback about how a program will behave as the program is edited.
Paper describes a textual live language.
References Fabrik, Quartz Composer.

Similar to Subtext?
},
pages = {623--637},
title = {Living it up with a Live Programming Language}
}
@article{Ennals2007,
author = {Ennals, Rob and Gay, David},
journal = {Design},
keywords = {and wikimapia,at the time of,browser,com,com which combines,com with slashdot,digg,end-user programming,mashup,org,org with google maps,physical locations,programmableweb,to provide information about,web,wikipedia,writing},
pages = {223--233},
title = {User-Friendly Functional Programming for Web Mashups},
year = {2007}
}
@article{Ennals2007a,
author = {Ennals, Rob and Brewer, Eric and Garofalakis, Minos and Shadle, Michael and Gandhi, Prashant},
journal = {Sigmod Record},
pages = {27--34},
title = {Intel Mash Maker: Join the Web},
volume = {36},
year = {2007}
}
@article{Zhao2005a,
author = {Zhao, Hongkun and Meng, Weiyi and Wu, Zonghuan and Raghavan, Vijay and Yu, Clement},
journal = {WWW},
keywords = {from dynamically generated result,information extraction,pages returned,records,search engine,srrs,the issue of how,this paper focuses on,to extract search result,wrapper generation,wrappers},
note = {Fully automatic extraction.
Just for search engine results.
Uses both HTML and visual layout.

},
pages = {66--75},
title = {Fully Automatic Wrapper Generation For Search Engines},
year = {2005}
}
@article{Wang2003,
author = {Wang, Jiying and Lochovsky, Frederick H},
journal = {Science And Technology},
pages = {187--196},
title = {Data Extraction and Label Assignment for Web Databases},
year = {2003}
}
@article{,
title = {No title.}
}
@article{Corporation1997,
author = {Corporation, Digital Equipment and Center, Systems Research and Alto, Palo},
journal = {Systems Research},
keywords = {browserware,desktop assistant,www},
pages = {129--138},
title = {Supporting Cooperative and Personal Surfing with a Desktop Assistant},
year = {1997}
}
@inproceedings{Davison2002,
author = {Davison, Brian D},
booktitle = {HT},
keywords = {ilarity,information retrieval,prediction,prefetching,textual sim-,user modeling,www},
note = {Web prefetching.Tries to predict what you will click on.

},
pages = {159--168},
title = {Predicting Web Actions from HTML Content},
year = {2002}
}
@inproceedings{Wieeha2001,
author = {Wieeha, Charles and Szekely, Pedro},
booktitle = {CHI},
note = {This is a workshop call.
User interface adapts to different kinds of users, different devices, different roles.
},
pages = {483--484},
title = {Transforming the Ul for anyone, anywhere.},
year = {2001}
}
@article{Gustafson1998,
author = {Gustafson, Tara and Schafer, J Ben and Konstan, Joseph},
journal = {Nation},
keywords = {5,agent,daily campus newspaper,of agents by the,online,phases of user testing,production staff of a,two,we studied the acceptance,with and without an},
title = {Agents in their Midst: Evaluating User Adaptation to Agent-Assisted},
year = {1998}
}
@article{Maglio2000,
author = {Maglio, Paul and Barrett, Rob},
journal = {Communications of the ACM},
keywords = {mashups},
note = {Another paper on WBI.
},
title = {Intermediaries Personalize Information Streams},
volume = {43},
year = {2000}
}
@article{Weinreich2008,
author = {Weinreich, Harald and Obendorf, Hartmut and Herder, Eelco and Mayer, Matthias},
journal = {ACM Transactions on the Web},
month = {February},
pages = {1--31},
title = {Not Quite the Average: An Empirical Study of Web Use},
volume = {2},
year = {2008}
}
@article{Olston2003a,
author = {Olston, Christopher and Chi, Ed H},
journal = {ACM Transactions on Computer-Human Interaction},
pages = {177--197},
title = {ScentTrails: Integrating Browsing and Searching on the Web},
volume = {10},
year = {2003}
}
@article{Wong2006,
author = {Wong, Jeffrey and Hong, Jason},
journal = {Interfaces},
keywords = {2,5,acm classification keywords,end-user programming,h,information interfaces and presentation,user,web automation,web browsers},
pages = {1541--1546},
title = {Marmite: End-User Programming for the Web},
year = {2006}
}
@article{Segal1999,
author = {Segal, Richard B and Heights, Yorktown},
journal = {Notes},
pages = {276--282},
title = {MailCat: An Intelligent Assistant for Organizing E-Mail},
year = {1999}
}
@article{Obendorf2007,
author = {Obendorf, Hartmut and Weinreich, Harald and Herder, Eelco and Mayer, Matthias},
journal = {History},
title = {Web Page Revisitation Revisited: Implications of a Long-term Click-stream Study of Browser Usage},
year = {2007}
}
@inproceedings{Heer2002,
author = {Heer, Jeffrey and Chi, Ed H},
booktitle = {CHI},
pages = {243--250},
title = {Separating the Swarm: Categorization Methods for User Sessions on the Web},
year = {2002}
}
@article{Yesilada2007,
author = {Yesilada, Yeliz and Lunn, Darren and Harper, Simon},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {bi-directional linking,hypertext,inbound links,world wide web},
pages = {3--10},
title = {Experiments Toward Reverse Linking on the Web},
year = {2007}
}
@article{Campbell2000,
author = {Campbell, S and Selker, Ted and Christopher, Paul P Maglio Rob Barrett},
journal = {Architecture},
keywords = {attentive systems,intelligent agents,interest tracking,multimodal input,peripheral information,user modeling},
title = {SUITOR: An Attentive Information},
year = {2000}
}
@article{Farrell,
author = {Farrell, Stephen and Buchmann, Volkert and Campbell, Christopher S and Maglio, Paul P},
pages = {190--191},
title = {Information Programming for Personal User Interfaces}
}
@article{Norman1994,
author = {Norman, Donald},
journal = {Communications of the ACM},
title = {How People Might Interact with Agents},
year = {1994}
}
@article{Card1996,
author = {Card, Stuart K and G., George and Alto, Palo},
keywords = {activity,human,in this paper,incorporate it gracefully into,notoriously too slow to,of viewing the,then propose two related,we suggest a way,web and its problems},
pages = {111--117},
title = {The WebBook and the Web Forager: An Information Workspace for the World-Wide Web},
year = {1996}
}
@article{Fertig1996,
author = {Fertig, Scott and Freeman, Eric and Gelernter, David},
journal = {SIGCHI Bulletin},
pages = {66--69},
title = {"Finding and Reminding" Reconsidered},
volume = {28},
year = {1996}
}
@article{Etzioni1994,
author = {Etzioni, Oren},
journal = {Communications of the ACM},
keywords = {mashups},
note = {"Software Robot" that performs web tasks for you using a variety of background services.
},
title = {A Softbot-Based Interface to the Internet},
year = {1994}
}
@inproceedings{Brooks1995,
author = {Brooks, Charles and Mazer, Murray S and Meeks, Scott and Miller, Jim},
booktitle = {WWW},
keywords = {mashups},
note = {available only as a web page  Proxy server that does application-specific modifications to pages to make them better.
},
title = {Application-Specific Proxy Servers as HTTP Stream Transducers},
year = {1995}
}
@article{Hartmann2007,
author = {Hartmann, Bjorn and Wu, Leslie and Collins, Kevin and Klemmer, Scott R},
journal = {UIST},
keywords = {clipping,mashups,programming by example modification,prototyping,web services},
note = {Understands the correspondence between website layout and underlying API.
Generates underlying API calls from UI interactions.
Can also use to rewrite existing web sites, using the same web-scripted programmable HTTP proxy (like WBI).
One advantage of being a proxy on the server is it works nicely with mobile devices that can't run stuff in the browser.





Server-side "active wiki" hosts scrips generated by the proxy.
Shows underlying code to the users if they want it.
Program by demonstrating existing examples (web sites) rather than new examples.

They met with web developers each week for eight weeks, to get an idea of what they wanted.

Largely another scrapbooking/clipping system, but using APIs.

Knowledgable developers contribute code that maps a site to an API recognizer.
Uses Ruby web proxy called the Mouse-Hole[4].

Says that Koala can also rewrite pages - given it is based on Chickenfoot, it probably can...
},
title = {Programming by a Sample: Rapidly Creating Web Applications with d.mix},
year = {2007}
}
@article{Bernstein2008,
author = {Bernstein, Michael and Van Kleek, Max and Karger, David and Schraefel, M. C..},
journal = {ACM Transactions on Information Systems},
month = {September},
pages = {1--46},
title = {Information Scraps: How and Why Information Eludes our Personal Information Management Tools},
volume = {26},
year = {2008}
}
@article{Crescenzi,
author = {Crescenzi, Valter and Mecca, Giansalvatore and Merialdo, Paolo},
keywords = {wrappers},
note = {Generates wrappers automatically by comparing web sites with a common template and seeing what changes.
},
title = {RoadRunner: Towards Automatic Data Extraction from Large Web Sites}
}
@inproceedings{Liu2000,
author = {Liu, Ling and Pu, Calton and Han, Wei},
booktitle = {ICDE},
note = {Extracts data from pages and encodes it in XML.
Generates executable wrapper programs.



},
title = {XWRAP: An XML-enabled Wrapper Construction System for Web Information Sources},
year = {2000}
}
@article{Kushmerick2000,
author = {Kushmerick, Nicholas},
journal = {Science},
note = {Deduces whether a wrapper is working correctly.
Uses simple numeric heuristics about the amount and kind of data that the wrapper is expected to produce.
},
title = {Wrapper Verification},
volume = {World Wide},
year = {2000}
}
@article{Kushmerick1997,
author = {Kushmerick, Nicholas and Weld, Daniel S and Doorenbos, Robert},
journal = {IJCAI},
keywords = {wrappers},
note = {Tool is called WIEN
Call wrapper class HLRT   Can learn wrappers - gets 48% of surveyed sites right.   Uses a learned finite state machine.     Give it examples and it infers the wrapper.   
},
publisher = {ACM},
title = {Wrapper Induction for Information Extraction},
year = {1997}
}
@inproceedings{Nichols2008,
author = {Nichols, Jeffrey and Hua, Zhigang and Barton, John},
booktitle = {UIST},
keywords = {mashups},
note = {Web proxy that modifies a web page for use by a mobile device.
},
title = {Highlight: A System for Creating and Deploying Mobile Web Applications},
year = {2008}
}
@article{Livingston2007,
author = {Livingston, Kevin and Riesbeck, Christopher K},
journal = {Knowledge Acquisition},
keywords = {derstanding,dmap,knowledge acquisition,learning reader,natural language un-,simplified english},
pages = {198--205},
title = {Knowledge Acquisition from Simplified Text},
year = {2007}
}
@article{KONSTAN1997,
author = {KONSTAN, JOSEPH A and MILLER, BRADLEY N and Maltz, David and Herlocker, Jonathan L and Gordon, Lee and Riedl, John},
journal = {Communications of the ACM},
note = {Rate interesting posts and recommends ones you will like.
},
pages = {77--87},
title = {GroupLens: Applying Collaborative Filtering to Usenet News},
volume = {40},
year = {1997}
}
@article{Sebastiani2002,
author = {Sebastiani, Fabrizio},
journal = {ACM Computing Surveys},
pages = {1--47},
title = {Machine Learning in Automated Text Categorization},
volume = {34},
year = {2002}
}
@inproceedings{Cohen1996,
author = {Cohen, William W and Singer, Yoram},
booktitle = {SIGIR},
pages = {307--315},
publisher = {ACM},
title = {Context-sensitive learning methods for text categorization},
year = {1996}
}
@inproceedings{Bar-Yossef2002,
author = {Bar-Yossef, Ziv and Rajogopalan, Sridhar},
booktitle = {WWW},
publisher = {ACM},
title = {Template Detection via Data Mining and its Applications},
year = {2002}
}
@article{Etzioni2004,
author = {Etzioni, Oren and Kok, Stanley and Soderland, Stephen and Cafarella, Michael and Popescu, Ana-Maria and Weld, Daniel S and Downey, Doug and Shaked, Tal and Yates, Alexander},
journal = {New York},
keywords = {information extraction,mutual information,search},
pages = {100--110},
title = {Web-Scale Information Extraction in KnowItAll (Preliminary Results)},
year = {2004}
}
@article{Wu2006a,
author = {Wu, Min and Miller, Robert C and Garfinkel, Simson L and Lab, Artificial Intelligence},
journal = {World Wide Web Internet And Web Information Systems},
pages = {601--610},
title = {Do Security Toolbars Actually Prevent Phishing Attacks?},
year = {2006}
}
@inproceedings{Miller2008,
author = {Miller, Robert C and Chou, Victoria H and Bernstein, Michael and Little, Greg and Kleek, Max Van and Karger, David and Schraefel, M C},
booktitle = {UIST},
keywords = {and command parameters,edu or new york,email or,expressing a command,figure 1,keywords,mashups,may include command names,mit,or,search flights,such as 9 am,such as reserve or,the keywords are matched,vikki},
title = {Inky: A Sloppy Command Line for the Web with Rich Visual Feedback},
year = {2008}
}
@article{Huynh,
author = {Huynh, David F and Miller, Robert C and Karger, David R},
journal = {Artificial Intelligence},
keywords = {drag and drop,end-user programming,faceted browsing,mash up,ontology alignment,rdf,semantic web,simultaneous editing},
title = {Potluck: Data Mash-Up Tool for Casual Users}
}
@article{Lieberman,
author = {Lieberman, Henry and Nardi, Bonnie A and Wright, David},
journal = {New York},
pages = {116--122},
title = {Training Agents to Recognize Text by Example}
}
@article{Churchill2000,
author = {Churchill, Elizabeth F and Trevor, Jonathan and Bly, Sara and Nelson, Les and Cubranid, Davor and Consulting, Sara Bly and Alto, Palo and Plains, North},
keywords = {and groups by,conversations with different individuals,interactions are easily,it is also possible,ongoing and frequent informal,supported,to have multiple simultaneous},
pages = {454--461},
title = {Anchored conversations: chatting in the context of a document},
volume = {2},
year = {2000}
}
@article{Design1993,
author = {Design, The User-centred Iterative and Software, Of Collaborative Writing},
journal = {Writing},
pages = {399--406},
title = {The User-centred Iterative Design Of Collaborative Writing Software},
year = {1993}
}
@article{Zhao,
author = {Zhao, Shubin and Betz, Jonathan},
journal = {New York},
keywords = {bootstrapping,information extraction,web mining},
pages = {995--1003},
title = {Corroborate and Learn Facts from the Web}
}
@article{Morinaga,
author = {Morinaga, Satoshi and Yamanishi, Kenji and Tateishi, Kenji and Fukushima, Toshikazu},
pages = {341--349},
title = {Mining Product Reputations on the Web}
}
@article{Quan2004,
author = {Quan, Dennis and Karger, David R},
journal = {New York},
pages = {255--265},
title = {How to Make a Semantic Web Browser},
year = {2004}
}
@inproceedings{Seo2000,
author = {Seo, Young-Woo and Zhang, Byoung-Tak},
booktitle = {IUI},
keywords = {learning user,reinforcement learning,s preferences,user interface agents,web-based information filtering},
note = {System called WAIR.Learns what web pages you will like.
Learns from your browsing, rather than just from explicit rankings.
Uses reinforcement learning:


},
pages = {248--251},
publisher = {ACM},
title = {A Reinforcement Learning Agent for Personalized Information Filtering},
year = {2000}
}
@article{Rucker1997,
author = {Rucker, James and Polanco, Marcos},
journal = {Communications of the ACM},
note = {Recommends pages based on a users bookmarks.
Uses bookmark as vote in favor. Uses folder groupings as information about semantic coherence.


},
pages = {73--75},
publisher = {ACM},
title = {Siteseer: Personalized Navigation for the Web},
volume = {40},
year = {1997}
}
@inproceedings{Huang2004,
author = {Huang, Chien-chung and Chuang, Shui-lung and Chien, Lee-feng},
booktitle = {WWW},
keywords = {text classi cation,topic hierarchy,web mining},
note = {incomprehensible chinese paper
},
pages = {184--192},
title = {LiveClassier: Creating Hierarchical Text Classiers through Web Corpora},
year = {2004}
}
@article{Kelly2002,
author = {Kelly, Diane and Cool, Colleen},
journal = {Journal of the American Society for Information Science},
keywords = {information seeking behavior,personalization,topic familiarity,user modeling},
pages = {74--75},
title = {The Effects of Topic Familiarity on Information Search Behavior},
year = {2002}
}
@article{Mittal,
author = {Mittal, Vibhu O and Research, Just and Pittsburgh, Street and Berger, L and Ocelot, The and Project, Open Directory and Directory, Open},
journal = {In Practice},
pages = {144--151},
title = {A system for summarizing web pages}
}
@article{Rajaraman,
author = {Rajaraman, Anand and Ullman, Jeffrey D},
journal = {Work},
title = {Querying Websites Using Compact Skeletons}
}
@inproceedings{Mattox1999,
author = {Mattox, David and Seligman, Len and Smith, Ken},
booktitle = {WIDM},
keywords = {discovering structure,information extraction,nlp,semistructured data,web databases,wrapper,wrappers},
note = {Can extract information from web pages that is encoded inside sentences of natural language text.


},
pages = {6--11},
title = {Rapper: A Wrapper Generator with Linguistic Knowledge},
year = {1999}
}
@article{Liu2001,
author = {Liu, Bing and Yu, Philip S and Heights, Yorktown},
journal = {Sites The Journal Of 20Th Century Contemporary French Studies},
pages = {144--153},
title = {Discovering Unexpected Information from Your Competitors' Web Sites},
year = {2001}
}
@article{Computer1991,
author = {Computer, Allen Cypher Advanced Apple Technology and Inc, C A Group},
journal = {Info},
keywords = {adap-,by example,demonstrational,intelligent interfaces,interfaces,programming,user programming},
pages = {33--39},
title = {Eager: programming repetitive tasks by example},
year = {1991}
}
@article{Gruhl2006,
author = {Gruhl, Daniel and Meredith, Daniel N and Pieper, Jan H},
pages = {183--192},
title = {The Web Beyond Popularity},
year = {2006}
}
@inproceedings{Borkar2001,
author = {Borkar, Vinayak and Deshmukh, Kaustubh and Sarawagi, Sunita},
booktitle = {SIGMOD},
note = {For plain text, not HTML.
},
title = {Automatic segmentation of text into structured records},
year = {2001}
}
@article{Agichtein,
author = {Agichtein, Eugene and Ganti, Venkatesh},
journal = {Work},
keywords = {data cleaning,extraction,information,machine learning,text management,text segmentation},
pages = {20--29},
title = {Mining Reference Tables for Automatic Text Segmentation}
}
@article{Liua,
author = {Liu, Bing and Hu, Minqing and Cheng, Junsheng},
journal = {Human Factors},
keywords = {extraction,information,opinion analysis,sentiment analysis,visualization},
pages = {342--351},
title = {Opinion Observer: Analyzing and Comparing Opinions on the Web}
}
@inproceedings{Hu2005,
author = {Hu, Yunhua and Xin, Guomao and Song, Ruihua and Hu, Guoping and Shi, Shuming and CAO, Yunbo and Li, Hang},
booktitle = {SIGIR},
keywords = {thinklink,wrappers},
note = {Use supervised machine learning to find titles.
 Use info such as font-size, position, and font weight.
 
 Baseline is using the text in the largest font size as the title. New method improves by 20-30%.
 Uses TREC Web Track data.
 Font size is the most important factor when looking for a title.
 -- TREC stats --
 33.5% of documents have a bad title.5.8% - no title0.8% - "untitled" as the title27.9% - duplicated title - one title for many pages
 The big issue is pages that use a duplicated title.
 
 -- my simple approach --
 Look at the official title of the page.Factor out any text that is commonly repeated between web pages on the same site - the standard prefix/suffix.
 Thus:
 * Gather a collection of title strings pulled from web pages.
 If the problem is "duplicated title" then just stripping bits of crap from the title string won't help. They already consider that to be a good title. They are attacking a harder problem.
 
 BUT: A similar approach could be used.Gather the following text:   - title   - biggest text   - second biggest non-repeated text
 Look for duplicates in the corpus. Strip things out that are duplicated a lot.
 

},
title = {Title Extraction from Bodies of HTML Documents and its Application to Web Page Retrieval},
year = {2005}
}
@inproceedings{Gupta2003,
author = {Gupta, Suhit and Kaiser, Gail and Neistadt, David and Grimm, Peter},
booktitle = {WWW},
note = {Want to extract the core content from a page. Strip out borders, ads, fluff, etc.
Look at ratio of links to words. If too many links then it is border content. (best ratio is five words per link)This is the same kind of thing I need to do for Think Link.
Key insight is to work with DOM trees, rather than HTML.
Previous: webwiper, junkbusters  all use hard-coded rules






Finn[1] seems like it could be good. READTokenise page into words and tags. Then break page into three continuous regions - with content being in the middle.
McKeown[8][15] detects the largest body of text on a web page and classifies it as content.


},
pages = {207--214},
title = {DOM-based Content Extraction of HTML Documents},
year = {2003}
}
@inproceedings{Chidlovskii2001,
author = {Chidlovskii, Boris},
booktitle = {WIDM},
keywords = {wrapper repair,wrappers},
note = {Creates two views of the extracted data, which it compares. When one gets out of sync the other is updated.
Uses information extracted from previous versions of the page to train an information extraction algorithm that is then used to update the wrapper.

File doesn't print and last few pages don't even preview.
},
title = {Automatic Repairing of Web Wrappers},
year = {2001}
}
@article{Domingue2004,
author = {Domingue, John and Dzbor, Martin and Motta, Enrico},
journal = {Human Factors},
pages = {191--197},
title = {Magpie: Supporting Browsing and Navigation on the Semantic Web},
year = {2004}
}
@article{Gupta,
author = {Gupta, Anoop and Grudin, Jonathan and Research, Microsoft and Group, Multimedia and Way, One Microsoft},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {as noted below,available,built,have been proposed and,have only recently become,systems with similar capabilities,the literature contains,widely used commercial systems},
title = {Using Web Annotations for Asynchronous Collaboration Around Documents}
}
@article{Cai2008,
author = {Cai, Rui and Yang, Jiang-ming and Lai, Wei and Wang, Yida and Zhang, Lei},
journal = {Work},
pages = {447--456},
title = {iRobot: An Intelligent Crawler for Web Forums},
year = {2008}
}
@article{Crescenzia,
author = {Crescenzi, Valter and Mecca, Giansalvatore and Merialdo, Paolo},
journal = {Grammars},
pages = {1108--1112},
title = {Wrapping-Oriented Classification of Web Pages}
}
@inproceedings{Teevan2005,
author = {Teevan, Jaime and Dumais, Susan T and Horvitz, Eric},
booktitle = {SIGIR},
keywords = {adaptive interfaces,personalized search,web search tools},
note = {Rerank search results based on a model of what the user is interested in and is doing.


},
pages = {449--456},
title = {Personalizing Search via Automated Analysis of Interests and Activities},
year = {2005}
}
@article{Kelly2003,
author = {Kelly, Diane and Teevan, Jaime},
journal = {SIGIR Forum},
note = {A variety of implicit system used to monitor what you like and are doing. Used to retrieve, filter, and recommend.



},
title = {Implicit Feedback for Inferring User Preference: A Bibliography},
year = {2003}
}
@article{Buyukkokten2001,
author = {Buyukkokten, Orkut and Garcia-Molina, Hector and Paepcke, Andreas},
journal = {Methods},
keywords = {actions,and,and number of pen,and single-sentence summaries provides,as,compared to other schemes,employed after a user,has searched and navigated,improvements in access times,significant,the web},
pages = {652--662},
title = {Seeing the Whole in Parts: Text Summarization for Web Browsing on Handheld Devices},
year = {2001}
}
@inproceedings{Meng2003,
author = {Meng, Xiaofeng and Hu, Dongdong and Li, Chen},
booktitle = {WIDM},
keywords = {extraction,maintenance,schema,web,wrapper,wrapper repair},
note = {Many patterns are preserved by structure change:   syntactic patterns, annotations, and hyperlinks Assume that schema hasn't changed, and look for data that looks like the data you had extracted before.
  Cites a lot of stuff about wrapper generation.   
},
pages = {1--8},
title = {Schema-Guided Wrapper Maintenance for Web-Data Extraction},
year = {2003}
}
@article{Crescenzi2004,
author = {Crescenzi, Valter and Mecca, Giansalvatore},
journal = {Journal of the ACM},
note = {Try to fully automate the wrapper generation process - with no human input.
Describes a system called ROADRUNNER.


},
pages = {731--779},
title = {Automatic Information Extraction from Large Websites},
volume = {51},
year = {2004}
}
@article{Cowie1996,
author = {Cowie, Jim and Lehnert, Wendy},
journal = {Communications of the ACM},
title = {Information Extraction},
volume = {39},
year = {1996}
}
@article{Atzeni1997,
author = {Atzeni, Paolo and Mecca, Giansalvatore},
journal = {PODS},
note = {Use cut and paste to edit a structured document such as a web site.
Seems fairly unexciting.
},
title = {Cut and Paste},
year = {1997}
}
@article{Davulcu2003,
author = {Davulcu, H and Koduri, S and Nagarajan, S},
journal = {New York},
keywords = {web annotation,web data,web data extraction},
pages = {9--14},
title = {DataRover: A Taxonomy Based Crawler for Automated Data Extraction from Data-Intensive Websites},
year = {2003}
}
@article{Cohen2002,
author = {Cohen, William W and Hurst, Matthew and Jensen, Lee S},
journal = {ReCALL},
keywords = {canopy,learning,record linkage,reference matching},
pages = {232--241},
title = {A Flexible Learning System for Wrapping Tables and Lists in HTML Documents},
year = {2002}
}
@article{Chang2001a,
author = {Chang, Chia-Hui and Lui, Shao-chen},
journal = {Construction},
keywords = {extraction rule,information extraction,multiple string,pat tree},
pages = {681--688},
title = {IEPAD: Information Extraction Based on Pattern Discovery},
year = {2001}
}
@article{Ashish1997,
author = {Ashish, Naveen and Knoblock, Craig A},
journal = {Geography},
keywords = {wrappers},
note = {Semi-automatic technique to generate wrappers.
User provides guidence, but largely automatic by inferring structure of data on the page.
},
pages = {8--15},
title = {Wrapper Generation for Semi - structured Internet Sources},
year = {1997}
}
@inproceedings{Little2007,
author = {Little, Greg and Lau, Tessa and Cypher, Allen and Lin, James and Haber, Eben M and Kandogan, Eser},
booktitle = {CHI},
keywords = {mashups},
note = {Now called Co-Scripter
Program by demonstration.Record scripts.
Works in Mozilla.
Uses sloppy programming - users give roughly formatted commands.
Derived from chickenfoot, as developed by students of Rob Miller during an internship.
User gives examples, and it infers a chickenfoot-style script.
Uses a wiki to share scripts.
},
pages = {943--946},
title = {Koala: Capture, Share, Automate, Personalize Business Processes on the Web},
year = {2007}
}
@article{Lieberman1999,
author = {Lieberman, Henry and Dyke, Neil W Van and Vivacqua, Adriana S and Laboratory, Media},
journal = {Learning},
pages = {65--68},
title = {Let’s Browse: A Collaborative Web Browsing Agent},
year = {1999}
}
@inproceedings{Gibson2005,
author = {Gibson, David and Punera, Kunal and Tomkins, Andrew},
booktitle = {WWW},
keywords = {algo-,data cleaning,data mining,still-reading,templates,web mining},
note = {40-50% of content on the web is template content.
},
pages = {830--839},
title = {The Volume and Evolution of Web Page Templates},
year = {2005}
}
@article{Ramaswamy,
author = {Ramaswamy, Lakshmish and Iyengar, Arun and Liu, Ling and Douglis, Fred and Tech, Georgia and Heights, Yorktown},
journal = {New York},
keywords = {dynamic content caching,fragment de-,fragment-based caching,l-p fragments,shared fragments,tection},
pages = {443--454},
title = {Automatic Detection of Fragments in Dynamically Generated Web Pages}
}
@article{Liub,
author = {Liu, Bing and Grossman, Robert and Zhai, Yanhong},
journal = {Building},
keywords = {web data records,web information integration,web mining},
pages = {601--606},
title = {Mining Data Records in Web Pages}
}
@inproceedings{Muslea1999,
author = {Muslea, Ion and Minton, Steve and Knoblock, Craig},
booktitle = {Autonomous Agents},
note = {Algorithm is called Stalker
Develops extraction rules from user-supplied training data.   
},
pages = {190--197},
title = {A Hierarchical Approach to Wrapper Induction},
year = {1999}
}
@article{Karger2003,
author = {Karger, David R and Katz, Boris and Lin, Jimmy and Quan, Dennis},
journal = {Human Factors},
pages = {254--256},
title = {Sticky Notes for the Semantic Web},
year = {2003}
}
@article{Koivunen2001,
author = {Koivunen, Marja-riitta and Swick, Ralph R},
journal = {Design},
keywords = {å ø ø,åä,èó òø ö,ê,ë ñ òø,ïóöð ¹ï ï,òòóø ø óò},
title = {Annotea: An Open RDF Infrastructure for Shared Web Annotations},
year = {2001}
}
@article{Scaffidi,
author = {Scaffidi, Chris and Cypher, Allen and Elbaum, Sebastian and Koesnandar, Andhy and Lin, James and Myers, Brad and Shaw, Mary},
journal = {Transformation},
pages = {11--15},
title = {Using Topes to Validate and Reformat Data in End-User Programming Tools 1}
}
@article{Benyon1993,
author = {Benyon, David and Murray, Dianne},
journal = {IUI},
keywords = {adaphve interfaces,individual,user models},
pages = {115--121},
title = {Developing Adaptive Systems to Fit Individual Aptitudes},
year = {1993}
}
@article{Barreau1995,
author = {Barreau, Deborah and Nardi, Bonnie A},
journal = {SIGCHI Bulletin},
note = {File organization on the desktop
},
pages = {39--43},
title = {Finding and Reminding: File Organization on the Desktop},
volume = {27},
year = {1995}
}
@inproceedings{Lieberman2005,
author = {Lieberman, Henry and Faaborg, Alexander and Daher, Waseem},
booktitle = {IUI},
keywords = {knowledge gathering,open mind common sense,predictive interfaces,speech},
note = {How to recognize speech using commons sense.
 Uses commonsense info to predict how plausible an interpretation of text is.
 Previous work used frequency of n-grams - given we have this word, how probable is this other word.
},
pages = {278--280},
title = {How to Wreck a Nice Beach You Sing Calm Incense},
year = {2005}
}
@article{Hsu2006,
author = {Hsu, Ming-hung and Chen, Hsin-Hsi},
journal = {Communications of the ACM},
keywords = {commonsense knowledge,concept expansion,conceptnet},
pages = {651--652},
title = {Information Retrieval with Commonsense Knowledge},
year = {2006}
}
@article{Stocky2004,
author = {Stocky, Tom and Faaborg, Alexander and Lieberman, Henry},
journal = {Evaluation},
pages = {1163--1166},
title = {A Commonsense Approach to Predictive Text Entry},
year = {2004}
}
@article{Lenat1995,
author = {Lenat, Douglas B},
journal = {Communications of the ACM},
title = {CYC: A large Investment in Knowledge Infrastructure},
volume = {38},
year = {1995}
}
@inproceedings{Arasu2003,
author = {Arasu, Arvind and Garcia-Molina, Hector},
booktitle = {SIGMOD},
note = {Does not use any learning examples or human input.
Takes a set of pages as input and infers the schema and data to extract.
RoadRunner and IEPad are also automatic extraction.


},
pages = {337--348},
title = {Extracting Structured Data from Web Pages},
year = {2003}
}
@article{Zheng2007,
author = {Zheng, Shuyi and Wu, Di and Song, Ruihua and WEN, JI-RONG},
journal = {KDD},
keywords = {wrappers},
note = {Hard to distinguish page by its URL. Instead distinguish by its template.
Uses similarity between pages to detect templates.
Given examples of pages that work, it uses a clustering algorithm.
},
pages = {894--902},
title = {Joint Optimization of Wrapper Generation and Template Detection},
year = {2007}
}
@article{Zhao2007,
author = {Zhao, Hongkun and Meng, Weiyi and Yu, Clement},
journal = {New York},
keywords = {information extraction,search engine,wrapper generation},
pages = {884--893},
title = {Mining Templates from Search Result Records of Search Engines},
year = {2007}
}
@article{Simon2005,
author = {Simon, Kai and Lausen, Georg},
journal = {CIKM},
keywords = {data extraction,data record alignment,visual features,wrappers},
note = {Fully automatic, with no human interaction.
Rank patterns with respect to a users visual perception of the page, rather than just DOM structure.
Looks for repeated elements that are visually similar to each other.

References interesting fully automatic tools:IEPad, DeLa, MDR, ViNTS, DEPTA.4,16,13,14,19
And summarizes each well.

},
pages = {381--388},
title = {ViPER: Augmenting Automatic Information Extraction with Visual Perceptions},
year = {2005}
}
@article{Zhang,
author = {Zhang, Ruth Yuee and Lakshmanan, Laks V S and Zamar, Ruben H},
journal = {SIGKDD Explorations},
keywords = {coverage estimation,du-,information extraction,pattern},
pages = {5--13},
title = {Extracting Relational Data from HTML Repositories},
volume = {6}
}
@article{Fazzinga2008,
author = {Fazzinga, Bettina and Tagarelli, Andrea and Garruzzo, Salvatore and Masciari, Elio},
journal = {System},
pages = {442--446},
title = {A Wrapper Generation System for PDF Documents},
year = {2008}
}
@article{Gregg2006,
author = {Gregg, Dawn G and Walczak, Steven},
journal = {Communications of the ACM},
title = {Adaptive Web Information Extraction},
volume = {49},
year = {2006}
}
@article{Gasparetti2007,
author = {Gasparetti, Fabio and Micarelli, Alessandro},
journal = {IUI},
keywords = {recommending},
note = {Uses browser history to predict needs.Uses the text of the pages.Is smart about which page text to consider.
Uses a clustering algorithm to find text similar to the title, or to text that has already been put in the cluster. Thus avoids links, and other such crap.
},
pages = {325--328},
title = {Exploiting Web Browsing Histories to Identify User Needs},
year = {2007}
}
@article{Gibson2007,
author = {Gibson, John and Wellner, Ben and Lubar, Susan},
journal = {Language},
pages = {105--112},
title = {Adaptive Web-page Content Identification},
year = {2007}
}
@article{Yamada,
author = {Yamada, Yasuhiro and Craswell, Nick and Nakatoh, Tetsuya and Hirokawa, Sachio},
journal = {World Wide Web Internet And Web Information Systems},
title = {Testbed for Information Extraction from Deep Web}
}
@inproceedings{Raposo2005,
author = {Raposo, Juan and Pan, Alberto and Alvarez, Manuel and Vina, Angel},
booktitle = {SAC},
keywords = {examples,extraction,maintenance,web,wrapper,wrapper repair,wrappers},
note = {Collect query results during wrapper operation and use this to infer a wrapper when the document changes.
},
pages = {654--659},
title = {Automatic Wrapper Maintenance for Semi-Structured Web Sources Using Results from Previous Queries 1},
year = {2005}
}
@article{Zheng2008,
author = {Zheng, Shuyi and Scott, Matthew R and Song, Ruihua and WEN, JI-RONG},
journal = {KDD},
keywords = {information extraction,labeling cost,pictor,wrapper,wrapper assisted labeling,wrappers},
note = {"Wrapper Induction" is the general technique of inferring a wrapper from examples.
Blends automatic extraction with guided extraction.
"Wrapper-assisted labelling"
Use previously generated wrappers to assist in the generation of future wrappers.

Rather cool.

Refers to:  Vertical Search Engines

},
pages = {1097--1100},
title = {Pictor: An Interactive System for Importing Data from a Website},
year = {2008}
}
@article{Sugibuchi2005,
author = {Sugibuchi, Tsuyoshi and Tanaka, Yuzuru},
journal = {WWW},
keywords = {information extraction,user interfaces,web,wrappers},
note = {User guides with examples.
Dynamically updates extractor preview based on actions.
Doesn't seem that exciting - wasn't this done before?
},
pages = {968--969},
title = {Interactive Web-Wrapper Construction for Extracting Relational Information from Web documents},
year = {2005}
}
@article{Ribeiro-neto1999,
author = {Ribeiro-neto, Berthier and Laender, Alberto H F and Da Silva, Altigran S},
journal = {CIKM},
keywords = {wrappers},
title = {Extracting Semi-Structured Data Through Examples},
year = {1999}
}
@article{Golgher2001,
author = {Golgher, Paula B and Ribeiro-neto, Berthier},
journal = {Framework},
pages = {0--7},
title = {Bootstrapping for Example-Based Data Extraction*},
year = {2001}
}
@article{Florescu1998,
author = {Florescu, Daniela and Levy, Alon and Mendelzon, Alberto},
journal = {Sigmod Record},
pages = {59--74},
title = {Database Techniques for the World-Wide Web: A Survey},
volume = {27},
year = {1998}
}
@inproceedings{Embley1999,
author = {Embley, D W and Jiang, Y},
booktitle = {SIGMOD},
keywords = {wrappers},
note = {Chunking web pages into records.
},
pages = {467--478},
title = {Record Boundary Discovery in Web Documents},
year = {1999}
}
@article{Adelberg1998,
author = {Adelberg, Brad},
journal = {Text},
pages = {283--294},
title = {NoDoSE - A Tool for Semi-Automatically Extracting Structured and Semistructured Data from Text Documents.},
year = {1998}
}
@inproceedings{Irmak2006,
author = {Irmak, Utku and Suel, Torsten},
booktitle = {WWW},
keywords = {active learning,data extraction,wrapper generation},
note = {Semi-automatic wrapper generation.  All interaction in the browser using the mouse. Often only one example is needed to create a wrapper.  Rank various hypothesis about how to match based on how they perform on examples.  Active learning based on a few examples.  Also see 4,5,16,22
},
pages = {553--563},
title = {Interactive Wrapper Generation with Minimal User Effort},
year = {2006}
}
@inproceedings{Kindberg,
author = {Kindberg, Tim and Barton, John},
booktitle = {SIGOPS},
note = {CoolTown.
 Web presence for people places and things.

},
pages = {1--6},
title = {Towards a real-world wide web}
}
@article{Freire2001,
author = {Freire, Juliana and Kumar, Bharat and Lieuwen, Daniel},
journal = {System},
title = {WebViews: Accessing Personalized Web Content and Services},
year = {2001}
}
@article{Bigham2008,
author = {Bigham, Jeffrey P and Cavender, Anna C and Kaminsky, Ryan S and Prince, Craig M and Robison, Tyler S},
journal = {Engineering},
pages = {169--178},
title = {Transcendence: Enabling a Personal View of the Deep Web},
year = {2008}
}
@article{Huynh2007,
author = {Huynh, David F and Karger, David R and Miller, Robert C},
journal = {Human Factors},
pages = {737--746},
title = {Exhibit: Lightweight Structured Data Publishing},
year = {2007}
}
@article{Hoffmann2007a,
author = {Hoffmann, Raphael and FOGARTY, JAMES and Weld, Daniel S and Science, Computer},
journal = {Engineering},
keywords = {a,an appropriate api for,apis,application programming interfaces,engine show many examples,including,of queries related to,queries attempting to identify},
title = {Assieme: Finding and Leveraging Implicit References in a Web Search Interface for Programmers},
year = {2007}
}
@article{Patel2008,
author = {Patel, Kayur and FOGARTY, JAMES and Landay, James A and Harrison, Beverly and Science, Computer and Seattle, Intel Research},
journal = {Training},
pages = {667--676},
title = {Investigating Statistical Machine Learning as a Tool for Software Development},
year = {2008}
}
@article{Nakamura2007,
author = {Nakamura, Satoshi and Yamamoto, Takehiro and Tanaka, Katsumi},
journal = {Human Factors},
keywords = {by the way,computer application is,editable web browser,filtering,for example,in a file,no matter what the,people frequently edit things,reranking,user interface,users trash a file,web},
pages = {73--80},
title = {Toward Editable Web Browser: Edit-and-Propagate Operation for Web Browsing},
year = {2007}
}
@article{Golbeck2007,
author = {Golbeck, Jennifer and Wasser, Michael M},
journal = {Social Networks},
keywords = {acm classification keywords,e,g,h5,information interfaces and presentation,m,social networks,user support,web browsing},
pages = {2381--2386},
title = {SocialBrowsing: Integrating Social Networks and Web Browsing},
year = {2007}
}
@article{Zhai,
author = {Zhai, Yanhong and Liu, Bing},
journal = {Idea},
keywords = {data extraction,data record extraction,wrapper},
pages = {76--85},
title = {Web Data Extraction Based on Partial Tree Alignment}
}
@article{Yee2003,
author = {Yee, Ka-Ping and Swearingen, Kirsten and Division, Computer Science and Li, Kevin and Hearst, Marti},
journal = {New Horizons},
keywords = {faceted metadata,image search interfaces},
pages = {401--408},
title = {Faceted Metadata for Image Search and Browsing},
year = {2003}
}
@article{Reisa,
author = {Reis, Davi De Castro and Golgher, Paulo B and Laender, Alberto H F},
journal = {New York},
keywords = {data extraction,edit distance,electronic news,schema,trees},
title = {Automatic Web News Extraction Using Tree Edit Distance}
}
@article{Lerman2004,
author = {Lerman, Kristina and Getoor, Lise and Minton, Steven and Knoblock, Craig and Beach, Manhattan},
journal = {World Wide Web Internet And Web Information Systems},
title = {Using the Structure of Web Sites for Automatic Segmentation of Tables},
year = {2004}
}
@article{Hogue2005,
author = {Hogue, Andrew and Karger, David},
journal = {Human Factors},
keywords = {haystack,rdf,semantic web,tree edit,wrapper induction},
pages = {86--95},
title = {Thresher: Automating the Unwrapping of Semantic Content from the World Wide Web},
year = {2005}
}
@article{Pandit1997,
author = {Pandit, Milind S and Kalbag, Sameer},
journal = {IUI},
pages = {47--52},
title = {The Selection Recognition Agent: Instant Access to Relevant Information and Operations},
year = {1997}
}
@article{Nardi2001,
author = {Nardi, Bonnie A and Miller, James R and Wright, David J},
journal = {Communications of the ACM},
title = {Collaborative, Programmable Intelligent Agents},
year = {2001}
}
@inproceedings{Lingam2007,
author = {Lingam, Sandeep and Elbaum, Sebastian},
booktitle = {WWW},
keywords = {clipping},
note = {Provide support for users to clip content from one site to insert into another.   Basic web clips? What's new here?
},
pages = {953--962},
title = {Supporting End-Users in the Creation of Dependable Web Clips},
year = {2007}
}
@article{Sugiura1998,
author = {Sugiura, Atsushi and Koseki, Yoshiyuki},
journal = {UIST '98: Proceedings of the 11th annual ACM symposium on User interface software and technology},
keywords = {clipping,end-user programming,example,mashups,programming by,programming by demonstration,web browsing,world wide web},
note = {Create clippings of stuff from other web sites.

},
title = {Internet Scrapbook: Automating Web Browsing Tasks by Demonstration},
year = {1998}
}
@article{Laender2002,
author = {Laender, Alberto H F and Ribeiro-neto, Berthier and Da Silva, Altigran S and Teixeira, Juliana S},
journal = {Sigmod Record},
keywords = {wrappers},
pages = {84--93},
title = {A Brief Survey of Web Data Extraction Toolst},
volume = {31},
year = {2002}
}
@article{Kelleher2005,
author = {Kelleher, Caitlin and Pausch, Randy},
chapter = {5},
journal = {ACM Computing Surveys},
keywords = {end user programming,survey},
note = {Survey of techniques used for end-user programming.
Breaks into three key techniques:  Simplify the language  Prevent Syntax Errors  Construct using graphical or physical objects  Create programs using interface actions  Provide multiple methods for creating programs
Further breakdown:  Side by side  Networked Interaction  Give a motivating context (e.g. robots)  Demonstrate Actions in the Interface  Demonstrate conditions and actions  Specify Actions  Make the language more understandable  Improve interaction with the language  Integration with Environment  Entertainment  Education


Cornell Program Synthesizer + GNOME: Structured program editor that stopped people making mistakes. Can still use arrow keys and text to edit, but constrained in actions and has auto-complete.
People had trouble modifying code due to the requirement to maintain correctness - couldn't go through intermediate invalid states.
Later worked help guide people to write correct code, without constraining textual edits.

LogoBlocks:   Glue blocks together to assemble a program. Kind of like a structure editor.


BlueJ:  IDE for Java that makes it easier to test individual classes.
ToonTalk:   Use a physical model for program execution.
Mondrian:   Programming by demonstration.
Forms/3:  Based on spreadsheet.
},
pages = {83--137},
title = {Lowering the Barriers to Programming: A Taxonomy of Programming Environments and Languages for Novice Programmers},
volume = {37},
year = {2005}
}
@inproceedings{Barrett1997,
author = {Barrett, Rob and Maglio, Paul P and Kellem, Daniel C},
booktitle = {Proceedings of CHI},
keywords = {agents,mashups,thinklink,user models,world wide web},
note = {Personalise the web.  Tool called WBI - Web Browser Intelligence  Agents sit between the browser and the web itself. Each agent can learn something about the user and modify the web in a useful way.   Three types of agent: Monitor, Editor, Generator  Monitor: monitors the stream, but doesn't alter it Editor: edits the incoming communication stream Request: modifies requests  Rather like Greasemonkey?   Each agent registers itself with WBI and says when it should be activated.  Implemented as a proxy server.   References: [3], 
},
title = {How to Personalize the Web},
year = {1997}
}
@article{Myers2004,
author = {Myers, Brad A and Ko, Andy},
journal = {Communications of the ACM},
keywords = {end user programming},
note = {Performed studies about how people think about programming tasks.
 Own tools looked kind of lame, but important to raise the questions.
},
pages = {47--52},
title = {Natural programming languages and environments},
volume = {47},
year = {2004}
}
@article{Adar,
author = {Adar, Eytan and Dontcheva, Mira and FOGARTY, JAMES and Weld, Daniel S and Labs, Advanced Technology and Science, Computer and Systems, Adobe and Francisco, San},
journal = {Interfaces},
keywords = {temporal informatics,web,web extraction},
pages = {239--248},
title = {Zoetrope: Interacting with the Ephemeral Web}
}
@inproceedings{Wong2007,
author = {Wong, Jeffrey and Hong, Jason I},
booktitle = {CHI},
keywords = {mashups},
pages = {1435--1444},
title = {Making Mashups with Marmite: Towards End-User Programming for the Web},
year = {2007}
}
@article{Ko2004,
author = {Ko, Andrew J and Myers, Brad A},
journal = {Focus},
keywords = {alice,debugging,program slicing},
pages = {151--158},
title = {Designing the Whyline: A Debugging Interface for Asking Questions about Program Behavior},
volume = {6},
year = {2004}
}
@article{Huynh2006,
author = {Huynh, David F and Miller, Robert C and Karger, David R},
journal = {Human Factors},
keywords = {augment,browser an opportunity to,browser gives the web,data transfer from web,dom,dy-,faceted browsing,html,lter,namic query,repurpose,retaining structure in the,site to web,sort,tree alignment,web},
pages = {125--134},
title = {Enabling Web Browsers to Augment Web Sites’ Filtering and Sorting Functionalities},
year = {2006}
}
@article{Baumgartner2001,
author = {Baumgartner, Robert and Flesca, Sergio and Gottlob, Georg},
journal = {VLDB},
keywords = {wrappers},
note = {Tool for writing web scrapers.   Uses a declarative logic language called elog.   User creates a pattern by clicking on an example on the page.
Shows user all targets matching inferred pattern.Can refine by specifying something that must appear before the item.


Most literature uses the word "wrapper" rather than "scraper"
Is only a poster.
},
title = {Supervised Wrapper Generation with Lixto},
year = {2001}
}
@inproceedings{Dontcheva2007,
author = {Dontcheva, Mira and Drucker, Steven M and Salesin, David and Cohen, Michael F},
booktitle = {WWW},
keywords = {data extraction,per induction,structural analysis,templates,webpage evolution,wrap-},
note = {Studied 12k web pages from 20 different sites. Over a period of 5 months.   Structure of web pages from lower-volume sites changes very little.   Structure of web pages from high-volume sites changes in mostly minor ways.   Some sites go through drastic structural changes, but only on order of every couple of months.     Gibson found that 40% of the web uses templates.

Pages change infrequently enough that a wrapper should expect to work for at least a few months, but frequently enough that it is important to be able to update a wrapper.
Uses the Levenschtein string matching algorithm to correct wrappers.
74% of the web sites they tested had at least one minor change in the 5 month period.
},
title = {Changes in Webpage Structure over Time},
year = {2007}
}
@article{Dontcheva2006,
author = {Dontcheva, Mira and Drucker, Steven M and Wade, Geraldine and Systems, Adobe and Science, Computer and Salesin, David and Cohen, Michael F and Research, Microsoft and Way, One Microsoft},
keywords = {information management,patterns,template-based summarization,webpage extraction},
title = {Summarizing Personal Web Browsing Sessions},
year = {2006}
}
@inproceedings{Brandt,
author = {Brandt, Joel and Wu, Leslie and Klemmer, Scott R},
booktitle = {CHI},
title = {Remixing The Web: Enhancing Tailoring Using Programmable Proxies}
}
@article{Schrier2008,
author = {Schrier, Evan and Dontcheva, Mira and Jacobs, Charles and Wade, Geraldine and Salesin, David},
journal = {New York},
title = {Adaptive Layout for Dynamically Aggregated Documents},
year = {2008}
}
@inproceedings{Dontcheva2007a,
author = {Dontcheva, Mira and Drucker, Steven M and Salesin, David and Cohen, Michael F},
booktitle = {UIST},
keywords = {personalized web search,sentation,template-based repre-,view and layout editing,web content extraction},
note = {Search templates say what kind of thing to try to find on Google.
 

},
title = {Relations, Cards, and Search Templates: User-Guided Web Data Integration and Layout},
year = {2007}
}
@article{Dontcheva,
author = {Dontcheva, Mira and Lin, Sharon and Drucker, Steven M and Salesin, David and Cohen, Michael F},
journal = {Engineering},
title = {Experiences with Content Extraction from the Web}
}
@article{Guha,
author = {Guha, R and Mccool, Rob},
journal = {Knowledge Creation Diffusion Utilization},
title = {TAP: A Semantic Web Platform}
}
@article{Information2000,
author = {Information, Trainable},
pages = {87--114},
title = {Trainable Information Agents for the Web},
year = {2000}
}
@article{Schraefel2002,
author = {Schraefel, M C and Zhu, Yuxiang},
chapter = {5},
journal = {CHI},
keywords = {clipping},
note = {Scrapbook for assembling clips of stuff.
},
pages = {498--499},
title = {Hunter Gatherer: A Collection Making Tool for the Web},
year = {2002}
}
@inproceedings{Schraefel2002a,
address = {New York, NY, USA},
author = {Schraefel, M C and Zhu, Yuxiang and Modjeska, David and Wigdor, Daniel and Zhao, Shengdong},
booktitle = {WWW},
keywords = {clipping},
note = {For maintaining collections of content clipped from web sites.  Studies claim that people want to organize elements smaller than a web page.  
},
pages = {172--181},
title = {Hunter Gatherer: Interaction Support for the Creation and Management of Within-Web-Page Collections},
year = {2002}
}
@inproceedings{Fujima2004,
author = {Fujima, Jun and Lunzer, Aran and Hornb\aek, Kasper and Tanaka, Yuzuru},
booktitle = {UIST '04: Proceedings of the 17th annual ACM symposium on User interface software and technology},
note = {Clip input and result elements from web sites to from a spreadsheet.Use formulas in the spreadsheet to glue things together.
Tool called C3W
E.g. turn currency converter on CNN Money into a spreadsheet element (mapping input cells to output cells). Clone this so we can make multiple requests.


},
title = {Clip, Connect, Clone: Combining Application Elements to Build Custom Interfaces for Information Access},
year = {2004}
}
@article{Bolin2005,
author = {Bolin, Michael and Webber, Matthew and Rha, Philip and Wilson, Tom and Miller, Robert C},
journal = {UIST},
keywords = {- graphical user interfaces,2,acm classification,component from the user,h5,information interfaces and,matching algorithm that identifies,presentation,s name,the desired,user interfaces},
title = {Automation and Customization of Rendered Web Pages},
year = {2005}
}
@article{Gelernter1989,
author = {Gelernter, David},
journal = {Communications of the ACM},
title = {Linda in context},
volume = {32},
year = {1989}
}
@article{Liu2004a,
author = {Liu, Hugo and Singh, Push},
journal = {BT Technology Journal},
keywords = {knowledge gathering},
note = {250,000 elements of commonsense knowledge from 13,000 contributers.
 Inspired by CYC.
 Like WordNet, constructed as a simple, easy to use semantic network.
 Can use for similar things as WordNet: query expansion etc.
 Common sense knowledge with links like "is used for", "is part of", "has effect", etc.
 All in terms of triples.
 Build using volunteers from the public.
 Seeded with OMCS corpus (Open Mind Common Sense).
},
title = {ConceptNet: A Practical Commonsense Reasoning Toolkit},
year = {2004}
}
@article{Miller1997,
author = {Miller, Robert C and Myers, Brad A},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {mashups,scraping},
note = {Create dynamically updated web pages. Scrap-book style? E.g. custom newspaper that shows you the content you want. Execute script by demonstration. Uses a pattern matcher to find the right portions of an HTML document. 
Uses placeholders such as "something matching X after something matching Y". Similar to Kapow? 
Several domains: * Composite page scripts extract information from one or more dynamic sources to produce a page of HTML. * Assistants: run a standard script action * Filters: Convert from one format to another * Form processors: Use a form to access information


},
title = {Creating Dynamic World Wide Web Pages By Demonstration},
year = {1997}
}
@inproceedings{Bauer2000,
author = {Bauer, Mathias and Dengler, Dietmar and Paul, Gabriele},
booktitle = {IUI},
keywords = {information agents,programming by demonstration,wrapper induction},
pages = {21--28},
title = {lnstructible Information Agents for Web Mining},
year = {2000}
}
@inproceedings{dontcheva-relations,
author = {Dontcheva, Mira and Drucker, Steven M and Salesin, David and Cohen, Michael F},
booktitle = {Proceedings of the 20th annual ACM symposium on User Interface Software and Technology (UIST'07)},
title = {Relations, Cards, and Search Templates: User-Guided Web Data Integration and Layout},
year = {2007}
}
@inproceedings{participatory,
author = {Ennals, Rob and Trushkowsky, Beth},
booktitle = {Workshop on Tinkering Tailoring and Mashing, at CSCW},
title = {Participatory Mashups: Using Users to Make Data Mashable},
year = {2008}
}
@inproceedings{dbpedia,
author = {Auer, S and Bizer, C and Lehmann, J and Kobilarov, G and Cyganiak, R and Ives, Z},
booktitle = {Proceedings of the 7th International Semantic Web Conference},
title = {{DBPedia:} A Nucleus for a Web of Open Data},
year = {2007}
}
@inproceedings{coscripter,
author = {Leshed, Gilly and Haber, Eben M and Matthews, Tara and Lau, Tessa},
booktitle = {{CHI Letters: Human Factors in Computing Systems, CHI 2008}},
title = {CoScripter: Automating and Sharing How-To Knowledge in the Enterprise},
year = {2008}
}
@misc{mashmainstream,
author = {Schofield, Jack},
title = {Will mashups ever be mass market?},
year = {2007}
}
@inproceedings{chickenfoot,
author = {Bolin, Michael and Webber, Matthew and Rha, Philip and Wilson, Tom and Miller, Robert C},
booktitle = {ACM Conference on User Interface Software and Technology (UIST)},
title = {Automation and Customization of Rendered Web Pages},
year = {2005}
}
@inproceedings{mashupos,
author = {Howell, Jon and Jackson, Collin and Wang, Helen J and Fan, Xiaofeng},
booktitle = {Proceedings of the 11th {USENIX} workshop on Hot Topics in Operating Systems},
title = {{MashupOS}: Operating System Abstractions for Client Mashups},
year = {2007}
}
@misc{mashmaker-www,
author = {Ennals, Rob and Brewer, Eric and Shadle, Michael and Gandhy, Prashint},
title = {{Intel Mash Maker: Mash as you Browse}}
}
@inproceedings{tabulator,
author = {Berners-Lee, Tim and Chen, Yuhsin and Chilton, Lydia and Connolly, Dan and Dhanaraj, Ruth and Hollenbach, James and Lerer, Adam and Sheets, David},
booktitle = {Proceedings of the 3rd International Semantic Web User Interaction Workshop},
title = {Tabulator: Exploring and Analysing linked data on the Semantic Web},
year = {2006}
}
@inproceedings{ontowiki,
author = {Hepp, Martin and Bachlechner, Daniel and Siorpaes, Katharina},
booktitle = {WikiSym '06: Proceedings of the 2006 international symposium on Wikis},
title = {OntoWiki: community-driven ontology engineering and ontology usage based on Wikis},
year = {2006}
}
@inproceedings{piggybank,
author = {Huynh, David and Mazzocchi, Stefano and Karger, David},
booktitle = {Proceedings of the 4th International Semantic Web Conference},
title = {Piggy Bank: Experience the Semantic Web Inside Your Browser},
year = {2005}
}
@misc{linkeddata,
author = {Berners-Lee, Tim},
title = {Linked Data},
year = {2006}
}
@inproceedings{mashmakericfp,
address = {New York, NY, USA},
author = {Ennals, Rob and Gay, David},
booktitle = {ICFP '07: Proceedings of the 2007 ACM SIGPLAN international conference on Functional programming},
isbn = {978-1-59593-815-2},
pages = {223--234},
title = {User-friendly functional programming for web mashups},
year = {2007}
}
@inproceedings{treecalc,
author = {Takeichi, Masato and Hu, Zhenjiang and Kakehi, Kazuhiko and Hayashi, Yashushi and Mu, Shin-Cheng and Nakano, Keisuke},
booktitle = {Japan Society for Software Science and Technology},
title = {{TreeCalc:} Towards Programmable Structured Documents},
year = {2003}
}
@inproceedings{treecalc-bidir,
address = {New York, NY, USA},
author = {Hu, Zhenjiang and Mu, Shin-Cheng and Takeichi, Masato},
booktitle = {PEPM '04: Proceedings of the 2004 ACM SIGPLAN symposium on Partial evaluation and semantics-based program manipulation},
isbn = {1-58113-835-0},
pages = {178--189},
title = {A programmable editor for developing structured documents based on bidirectional transformations},
year = {2004}
}
@inproceedings{treecalc-exprs,
address = {New York, NY, USA},
author = {Liu, Dongxi and Hu, Zhenjiang and Takeichi, Masato},
booktitle = {DocEng '05: Proceedings of the 2005 ACM symposium on Document engineering},
isbn = {1-59593-240-2},
pages = {42--51},
title = {An environment for maintaining computation dependency in {XML} documents},
year = {2005}
}
@inproceedings{excel-functions,
address = {New York, NY, USA},
author = {Peyton Jones, Simon and Blackwell, Alan and Burnett, Margaret},
booktitle = {ICFP '03: Proceedings of the eighth ACM SIGPLAN international conference on Functional programming},
isbn = {1-58113-756-7},
pages = {165--176},
title = {A user-centred approach to functions in {Excel}},
year = {2003}
}
@article{alexasued,
author = {Arrington, Michael},
journal = {TechCrunch},
month = {March},
title = {Amazon's War on Statsaholic},
year = {2007}
}
@inproceedings{sifter,
author = {Huynh, David and Miller, Robert and Karger, David},
booktitle = {ACM Conference on User Interface Software and Technology (UIST)},
title = {Enabling Web Browsers to Augment Web Sites' Filtering and Sorting Functionality},
year = {2006}
}
@article{listpic,
author = {Lowesohn, Josh},
journal = {CNet News},
month = {June},
title = {Craigslist cuts off Listpic, cites bandwidth issues, TOS violations},
year = {2007}
}
@phdthesis{treesheet,
author = {Leonard, Thomas},
title = {Tree-Sheets and Structured Documents},
year = {2004}
}
@inproceedings{goalbrowse,
address = {New York, NY, USA},
author = {Faaborg, Alexander and Lieberman, Henry},
booktitle = {CHI '06: Proceedings of the SIGCHI conference on Human Factors in computing systems},
isbn = {1-59593-372-7},
pages = {751--760},
title = {A goal-oriented web browser},
year = {2006}
}
@inproceedings{dataspaces,
author = {Franklin, Michael and Halevy, Alan and Maier, David},
booktitle = {{SIGMOD} Record},
title = {From Databases to Dataspaces: A New Abstraction for Information Management},
year = {2005}
}
@inproceedings{cohera,
author = {Stonebraker, Michael and Hellerstein, Joseph M},
booktitle = {Proceedings of the 2001 ACM SIGMOD international conference on Management of data},
title = {Content Integration for E-Business},
year = {2001}
}
@inproceedings{semex,
address = {New York, NY, USA},
author = {Cai, Yuhan and Dong, Xin Luna and Halevy, Alon and Liu, Jing Michelle and Madhavan, Jayant},
booktitle = {Proceedings of the 2005 ACM SIGMOD international conference on Management of data},
isbn = {1-59593-060-4},
pages = {921--923},
title = {Personal information management with {SEMEX}},
year = {2005}
}
@inproceedings{jungloids,
address = {New York, NY, USA},
author = {Mandelin, David and Xu, Lin and Bodik, Rastislav and Kimelman, Doug},
booktitle = {PLDI '05: Proceedings of the 2005 ACM SIGPLAN conference on Programming language design and implementation},
isbn = {1-59593-056-6},
pages = {48--61},
title = {Jungloid mining: helping to navigate the {API} jungle},
year = {2005}
}
@book{democratize,
author = {von Hippel, Eric},
isbn = {026720477},
title = {Democratizing Innovation},
year = {2006}
}
@book{scraping,
author = {Schrenk, Michael},
title = {Webbots, Spiders, and Screen Scrapers},
year = {2007}
}
@article{penguins,
address = {New York, NY, USA},
author = {HUDSON, SCOTT E},
journal = {ACM Trans. Graph.},
pages = {209--239},
title = {User interface specification using an enhanced spreadsheet model},
volume = {13},
year = {1994}
}
@article{forms3,
address = {New York, NY, USA},
author = {Burnett, Margaret and Atwood, John and Djang, Rebecca Walpole and Reichwein, James and Gottfried, Herkimer and Yang, Sherry},
journal = {J. Funct. Program.},
pages = {155--206},
title = {Forms/3: A first-order visual language to explore the boundaries of the spreadsheet paradigm},
volume = {11},
year = {2001}
}
@inproceedings{jda,
address = {New York, NY, USA},
author = {Lim, Seung Chan Slim and Lucas, Peter},
booktitle = {OOPSLA '06: Companion to the 21st ACM SIGPLAN conference on Object-oriented programming systems, languages, and applications},
isbn = {1-59593-491-X},
pages = {586--601},
title = {JDA: a step towards large-scale reuse on the web},
year = {2006}
}
@inproceedings{marmite,
address = {New York, NY, USA},
author = {Wong, Jeffrey and Hong, Jason},
booktitle = {CHI '06: CHI '06 extended abstracts on Human factors in computing systems},
isbn = {1-59593-298-4},
pages = {1541--1546},
title = {Marmite: end-user programming for the web},
year = {2006}
}
@book{progdemo,
address = {Cambridge, MA, USA},
author = {Cypher, Allen},
booktitle = {CHI},
chapter = {5},
isbn = {0-262-03213-9},
keywords = {end user programming},
publisher = {MIT Press},
title = {Watch what I do: programming by demonstration},
year = {1993}
}
@book{progexample,
address = {San Francisco, CA, USA},
author = {Lieberman, Henry},
booktitle = {ACM Computing Surveys},
chapter = {5},
isbn = {1-55860-688-2},
keywords = {end user programming},
publisher = {Morgan Kaufmann},
title = {Your wish is my command: programming by example},
volume = {37},
year = {2001}
}
@article{lowerbarriers,
address = {New York, NY, USA},
author = {Kelleher, Caitlin and Pausch, Randy},
journal = {ACM Comput. Surv.},
pages = {83--137},
title = {Lowering the barriers to programming: A taxonomy of programming environments and languages for novice programmers},
volume = {37},
year = {2005}
}
@inproceedings{c3w,
address = {New York, NY, USA},
author = {Fujima, Jun and Lunzer, Aran and Hornb\aek, Kasper and Tanaka, Yuzuru},
booktitle = {UIST '04: Proceedings of the 17th annual ACM symposium on User interface software and technology},
isbn = {1-58113-957-8},
pages = {175--184},
title = {Clip, connect, clone: combining application elements to build custom interfaces for information access},
year = {2004}
}
@inproceedings{huntergatherer,
address = {New York, NY, USA},
author = {Schraefel, M C and Wigdor, Daniel and Zhu, Yuxiang and Modjeska, David},
booktitle = {CHI '02: CHI '02 extended abstracts on Human factors in computing systems},
isbn = {1-58113-454-1},
pages = {826--827},
title = {Hunter gatherer: within-web-page collection making},
year = {2002}
}
@inproceedings{internetscrapbook,
address = {New York, NY, USA},
author = {Sugiura, Atsushi and Koseki, Yoshiyuki},
booktitle = {UIST '98: Proceedings of the 11th annual ACM symposium on User interface software and technology},
isbn = {1-58113-034-1},
pages = {9--18},
title = {Internet scrapbook: automating Web browsing tasks by demonstration},
year = {1998}
}
@inproceedings{wmsl,
author = {Sabbouh, Marwan and Higginson, Jeff and Gagne, Danny and Semy, Salim},
booktitle = {16th International World Wide Web Conference},
title = {Web Mashup Scripting Language (Poster)},
year = {2007}
}
@inproceedings{mash-sigmod,
author = {Ennals, Robert and Garofalakis, Minos},
booktitle = {Proceedings of the 2007 ACM SIGMOD International Conference on Management of Data (SIGMOD'2007)},
title = {{MashMaker} : Mashups for the Masses (Demo Paper)},
year = {2007}
}
@article{mash-record,
author = {Ennals, Robert and Brewer, Eric and Garofalakis, Minos and Shadle, Michale and Gandhi, Prashant},
journal = {{SIGMOD Record}},
title = {{Intel Mash Maker: Join the Web}},
volume = {36},
year = {2007}
}
@book{haskell98,
booktitle = {Journal of Functional Programming},
title = {Haskell 98 Language and Libraries: the Revised Report},
year = {2003}
}
@inproceedings{hairshirt,
author = {Peyton Jones, Simon},
booktitle = {ACM SIGPLAN Conferenge on Principles of Programming Languages (POPL'03)},
title = {Wearing the hair shirt: a retrospective on {Haskell} (invited talk)},
year = {2003}
}
@inproceedings{cognitive-dimensions,
address = {London, UK},
author = {Blackwell, Alan F and Britton, Carol and Cox, Anna Louise and Green, Thomas R G and Gurr, Corin A and Kadoda, Gada F and Kutar, Maria and Loomes, Martin and Nehaniv, Chrystopher L and Petre, Marian and Roast, Chris and Roe, Chris and Wong, Allan and Young, Richard M},
booktitle = {CT '01: Proceedings of the 4th International Conference on Cognitive Technology},
isbn = {3-540-42406-7},
pages = {325--341},
title = {Cognitive Dimensions of Notations: Design Tools for Cognitive Technology},
year = {2001}
}
@inbook{Bauer2001,
author = {Bauer, Mathias and Dengler, Dietmar and Paul, Gabriele},
booktitle = {Human Factors},
chapter = {5},
publisher = {Morgan Kaufmann},
title = {Trainable Information Agents for the Web},
year = {2001}
}
@inproceedings{Faaborg2006,
author = {Faaborg, Alexander and Lieberman, Henry},
booktitle = {CHI '06: Proceedings of the SIGCHI conference on Human Factors in computing systems},
note = {Miro: Data Detector Creo: Programming by Example 
Miro: Uses ConceptNet and Stanford TAP ConceptNet is part of MIT OpenMind.
 OpenMind is a database of user-entered tuples about concepts in the world. Users prompted to enter this information using fun games. TAP is scraped information from web sites telling us things about particular instances. E.g. "Yo-Yo Ma is a Cellist", or "Venus Williams is a Tennis Player". 
Modify web pages by adding links to other things of interest. Lots of prior work on data detectors.
},
title = {A Goal-Oriented Web Browser},
year = {2006}
}
@inproceedings{Mihalcea2007,
author = {Mihalcea, Rada and Csomai, Andras},
booktitle = {CIKM},
keywords = {keyword extraction,wikipedia,word sense disambiguation},
pages = {233--241},
title = {Wikify! Linking Documents to Encyclopedic Knowledge},
year = {2007}
}
@article{Wang2008,
author = {Wang, Yang},
pages = {25--28},
title = {“Human-Currency Interaction”: Learning from Virtual Currency Use in China},
year = {2008}
}
@inproceedings{Duggan2008,
author = {Duggan, Geoffrey B},
booktitle = {CHI},
note = {Peoples' background knowledge about a topic helps them search for it.
 People were tested on ability to answer questions in a topic with and without web search. Those who knew something were able to perform better at search.
 no great surprise.
},
pages = {39--48},
publisher = {ACM},
title = {Knowledge in the Head and on the Web: Using Topic Expertise to Aid Search},
year = {2008}
}
@article{Terry2008,
address = {New York, NY, USA},
author = {Terry, Michael and Kay, Matthew and Vugt, Brad Van and Slack, Brandon and Park, Terry},
journal = {CHI},
pages = {607--616},
title = {ingimp: Introducing Instrumentation to an End-User Open Source Application},
year = {2008}
}
@inproceedings{Wyche2008,
author = {Wyche, Susan P and Aoki, Paul M and Grinter, Rebecca E},
booktitle = {CHI},
pages = {11--20},
title = {Re-Placing Faith: Reconsidering the Secular-Religious Use Divide in the United States and Kenya},
year = {2008}
}
@inproceedings{Kittur2008b,
author = {Kittur, Aniket and Chi, Ed H and Suh, Bongwon},
booktitle = {CHI},
note = {Refers to various useful tools:  surveymonkey.com  vividence.com   Vividence, now called KeyNote:    Research panel with 160k users.   WebEffective tool for online usability testing.    Asks them to perform tasks.     If fail, asks them why they gave up.    Tracks user interactions with the page. (clickstream analysis)   Using Mechanical Turk:    Important to have low participation costs.  -- Experiment 1 -- Paid Turker 5 cents to rate a wikipedia article for quality on several axes.
Got responses within minutes.
Many of the users seemed to be gaming the system. Only very weak correlation with expert responses.48% of all responses were semantically empty.   - copying and pasting. Entering useless data. etc
64 ratings took less than one minute - which is not possible.58% of ratings flagged as potentially invalid due to duration.
-- Experiment 2 --
Make doing the task badly as much work as gaming the system.
This made things a lot more effective.
Part of the task is verified, and this takes most of the effort.Important to design the task as a game at which users have to get things right to a certain extent in order to progress.
-- Turk Features --
Can exclude users from future tasks based on responses.Can have a screening pre-test.
Can use Turk as just a recruitment device, and use one's own software to get the actual input. But this requires more programming work.


},
pages = {453--456},
publisher = {ACM},
title = {Crowdsourcing User Studies With Mechanical Turk},
year = {2008}
}
@article{Mainwaring2008,
author = {Mainwaring, Scott D and March, Wendy and Group, Practices Research and Research, Intel},
journal = {Computers and Society},
pages = {21--24},
title = {Lessons for digital money design from Japan},
year = {2008}
}
@inproceedings{Mark2008,
author = {Mark, Gloria},
booktitle = {CHI},
note = {People compensate for interruptions by working faster.This comes at the cost of more stress, frustration, and effort.
 People manage interruptions in different ways.
},
pages = {107--110},
publisher = {ACM},
title = {The Cost of Interrupted Work: More Speed and Stress},
year = {2008}
}
@inproceedings{Woodruff2008,
author = {Woodruff, Allison and Hasbrouck, Jay and Augustin, Sally},
booktitle = {CHI},
note = {Qualitative survey of 35 US households who have tried to be more environmental.
 Goal to inform the design of future green technologies.
 

},
pages = {313--322},
publisher = {ACM},
title = {A Bright Green Perspective on Sustainable Choices},
year = {2008}
}
@inproceedings{Greenberg2008,
author = {Greenberg, Saul},
booktitle = {CHI},
keywords = {user studies},
note = {Bill Buxton and Saul Greenberg.
 CHI has wrongheaded groupthink about usability testing.
 Usability testing at an early stage can mute creative ideas.
 CHI pushes for any design to be validated with real users.
 CHI is dominated by quantitive usability evaluations (70%).
 Rigorous science would include replication - which never happens in CHI.
 quote:                            For many people, the newer theidea and the less familiar they are with it, the more likelythey are to see other’s explorations into its variations,details and nuances as the same thing.

},
pages = {111--120},
title = {Usability Evaluation Considered Harmful (Some of the Time)},
year = {2008}
}
